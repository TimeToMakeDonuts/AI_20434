{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a552ad-5c6d-4cd0-aeec-3913757ed0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import socket\n",
    "from requests.exceptions import ConnectionError\n",
    "from requests.exceptions import MissingSchema\n",
    "from requests.exceptions import InvalidSchema\n",
    "from urllib3.exceptions import MaxRetryError, NameResolutionError\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ac4ce3-f70f-4380-8df6-79ceca279089",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "MODEL='deepseek-r1:8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f33753-1160-40b6-906f-253f3fb124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Moilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/573.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72823b21-59e0-449c-98b8-2e983b0f2059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nvidia/parakeet-tdt-0.6b-v2',\n",
       " '/Wan-AI/Wan2.1-VACE-14B',\n",
       " '/nari-labs/Dia-1.6B',\n",
       " '/multimodalart/isometric-skeumorphic-3d-bnb',\n",
       " '/lodestones/Chroma',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/Lightricks/ltx-video-distilled',\n",
       " '/spaces/smolagents/computer-agent',\n",
       " '/spaces/ByteDance/DreamO',\n",
       " '/spaces/NihalGazi/FLUX-Pro-Unlimited',\n",
       " '/spaces',\n",
       " '/datasets/openbmb/Ultra-FineWeb',\n",
       " '/datasets/PrimeIntellect/INTELLECT-2-RL-Dataset',\n",
       " '/datasets/nvidia/OpenCodeReasoning',\n",
       " '/datasets/nvidia/OpenMathReasoning',\n",
       " '/datasets/DMindAI/DMind_Benchmark',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = Website(\"https://huggingface.co\")\n",
    "page.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02995b79-069d-4e58-a530-6e94bdf4e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in \\\n",
    "a brochure about the company, such as links to an About page, or a Company page, \\\n",
    "or Careers/Jobs pages. \\n\"\n",
    "link_system_prompt += \"You should respond only in JSON, without text,<think> tag and its content, object as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "        ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7f3861-1266-4861-a363-1cd944d54935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages. \n",
      "You should respond only in JSON, without text,<think> tag and its content, object as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
      "        ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6bfc19c-8c6e-401e-b4df-36c596a236be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for \\\n",
    "    a brochure about the company, respond with the full https URL in clean JSON format \\\n",
    "    without text json on the begginning of the response. \\\n",
    "    Do not include your <think> tags in repsonse \\\n",
    "    Do not include Terms of Service, Privacy, email links.\\\n",
    "    Do not include any comments inside it\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca1bfe0-6e36-400f-bfe3-649fa38d350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://huggingface.co - please decide which of these are relevant web links for     a brochure about the company, respond with the full https URL in clean JSON format     without text json on the begginning of the response.     Do not include your <think> tags in repsonse     Do not include Terms of Service, Privacy, email links.    Do not include any comments inside it\n",
      "Links (some might be relative links):\n",
      "/\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/posts\n",
      "/docs\n",
      "/enterprise\n",
      "/pricing\n",
      "/login\n",
      "/join\n",
      "/spaces\n",
      "/models\n",
      "/nvidia/parakeet-tdt-0.6b-v2\n",
      "/Wan-AI/Wan2.1-VACE-14B\n",
      "/nari-labs/Dia-1.6B\n",
      "/multimodalart/isometric-skeumorphic-3d-bnb\n",
      "/lodestones/Chroma\n",
      "/models\n",
      "/spaces/enzostvs/deepsite\n",
      "/spaces/Lightricks/ltx-video-distilled\n",
      "/spaces/smolagents/computer-agent\n",
      "/spaces/ByteDance/DreamO\n",
      "/spaces/NihalGazi/FLUX-Pro-Unlimited\n",
      "/spaces\n",
      "/datasets/openbmb/Ultra-FineWeb\n",
      "/datasets/PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "/datasets/nvidia/OpenCodeReasoning\n",
      "/datasets/nvidia/OpenMathReasoning\n",
      "/datasets/DMindAI/DMind_Benchmark\n",
      "/datasets\n",
      "/join\n",
      "/pricing#endpoints\n",
      "/pricing#spaces\n",
      "/pricing\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/allenai\n",
      "/facebook\n",
      "/amazon\n",
      "/google\n",
      "/Intel\n",
      "/microsoft\n",
      "/grammarly\n",
      "/Writer\n",
      "/docs/transformers\n",
      "/docs/diffusers\n",
      "/docs/safetensors\n",
      "/docs/huggingface_hub\n",
      "/docs/tokenizers\n",
      "/docs/trl\n",
      "/docs/transformers.js\n",
      "/docs/smolagents\n",
      "/docs/peft\n",
      "/docs/datasets\n",
      "/docs/text-generation-inference\n",
      "/docs/accelerate\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/tasks\n",
      "https://endpoints.huggingface.co\n",
      "/chat\n",
      "/huggingface\n",
      "/brand\n",
      "/terms-of-service\n",
      "/privacy\n",
      "https://apply.workable.com/huggingface/\n",
      "mailto:press@huggingface.co\n",
      "/learn\n",
      "/docs\n",
      "/blog\n",
      "https://discuss.huggingface.co\n",
      "https://status.huggingface.co/\n",
      "https://github.com/huggingface\n",
      "https://twitter.com/huggingface\n",
      "https://www.linkedin.com/company/huggingface/\n",
      "/join/discord\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1a046c-0124-4e7b-95e3-246d804e26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "    ],\n",
    "        options={\"format\": \"json\"}\n",
    "    )\n",
    "    result = response['message']['content']\n",
    "    result = re.sub(r\"<think>.*?</think>\", \"\", result, flags=re.S).strip()\n",
    "    result = re.sub(r\"```(?:json)?\\s*|```\", \"\", result, flags=re.I).strip()\n",
    "    json_str = result[result.find(\"{\"): result.rfind(\"}\") + 1]\n",
    "    print(result)\n",
    "    try:\n",
    "        content_json = json.loads(result)\n",
    "        return content_json\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Odpowiedź nie jest poprawnym JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd9acafa-830a-4c9c-a4ad-83b47bd7198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nvidia/parakeet-tdt-0.6b-v2',\n",
       " '/Wan-AI/Wan2.1-VACE-14B',\n",
       " '/nari-labs/Dia-1.6B',\n",
       " '/multimodalart/isometric-skeumorphic-3d-bnb',\n",
       " '/lodestones/Chroma',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/Lightricks/ltx-video-distilled',\n",
       " '/spaces/smolagents/computer-agent',\n",
       " '/spaces/ByteDance/DreamO',\n",
       " '/spaces/NihalGazi/FLUX-Pro-Unlimited',\n",
       " '/spaces',\n",
       " '/datasets/openbmb/Ultra-FineWeb',\n",
       " '/datasets/PrimeIntellect/INTELLECT-2-RL-Dataset',\n",
       " '/datasets/nvidia/OpenCodeReasoning',\n",
       " '/datasets/nvidia/OpenMathReasoning',\n",
       " '/datasets/DMindAI/DMind_Benchmark',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d4f7ba-b754-452b-b5a7-87544ec860cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://huggingface.co/brand\"},\n",
      "        {\"type\": \"company information\", \"url\": \"https://huggingface.co/huggingface\"},\n",
      "        {\"type\": \"models\", \"url\": \"https://huggingface.co/models\"},\n",
      "        {\"type\": \"datasets\", \"url\": \"https://huggingface.co/datasets\"},\n",
      "        {\"type\": \"spaces\", \"url\": \"https://huggingface.co/spaces\"},\n",
      "        {\"type\": \"documentation transformers\", \"url\": \"https://huggingface.co/docs/transformers\"},\n",
      "        {\"type\": \"documentation diffusers\", \"url\": \"https://huggingface.co/docs/diffusers\"},\n",
      "        {\"type\": \"social media twitter\", \"url\": \"https://twitter.com/huggingface\"},\n",
      "        {\"type\": \"social media linkedin\", \"url\": \"https://www.linkedin.com/company/huggingface/\"},\n",
      "        {\"type\": \"enterprise solutions\", \"url\": \"https://huggingface.co/enterprise\"},\n",
      "        {\"type\": \"pricing\", \"url\": \"https://huggingface.co/pricing\"}\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/brand'},\n",
       "  {'type': 'company information', 'url': 'https://huggingface.co/huggingface'},\n",
       "  {'type': 'models', 'url': 'https://huggingface.co/models'},\n",
       "  {'type': 'datasets', 'url': 'https://huggingface.co/datasets'},\n",
       "  {'type': 'spaces', 'url': 'https://huggingface.co/spaces'},\n",
       "  {'type': 'documentation transformers',\n",
       "   'url': 'https://huggingface.co/docs/transformers'},\n",
       "  {'type': 'documentation diffusers',\n",
       "   'url': 'https://huggingface.co/docs/diffusers'},\n",
       "  {'type': 'social media twitter', 'url': 'https://twitter.com/huggingface'},\n",
       "  {'type': 'social media linkedin',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'},\n",
       "  {'type': 'enterprise solutions', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing', 'url': 'https://huggingface.co/pricing'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "599c0ef6-4505-4bf8-8686-6e58f944f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page: \\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    for link in links[\"links\"]:\n",
    "        try:\n",
    "            result += f\"\\n\\n{link['type']}\\n\"\n",
    "            result += Website(link[\"url\"]).get_contents()\n",
    "        except socket.gaierror as e:\n",
    "            print(f\"DNS resolution failed: {e}\")\n",
    "        except NameResolutionError as e:\n",
    "            print(f\"Name resolution error: {e}\")\n",
    "        except MaxRetryError as e:\n",
    "            print(f\"Max retries exceeded: {e}\")\n",
    "        except ConnectionError as e:\n",
    "            print(f\"Connection error: {e}\")\n",
    "        except MissingSchema as e:\n",
    "            print(f\"Invalid URL schema: {e}\")\n",
    "        except InvalidSchema as e:\n",
    "            print(f\"Omitted unsupported URL (InvalidSchema): {e}\")\n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d3b14fe-eabc-461b-be38-3bff525a2951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"models\", \"url\": \"https://huggingface.co/models\"},\n",
      "        {\"type\": \"datasets\", \"url\": \"https://huggingface.co/datasets\"},\n",
      "        {\"type\": \"spaces\", \"url\": \"https://huggingface.co/spaces\"},\n",
      "        {\"type\": \"about page\", \"url\": \"https://huggingface.co/brand\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://huggingface.co/join/discord\"},\n",
      "        {\"type\": \"enterprise solutions\", \"url\": \"https://huggingface.co/enterprise\"},\n",
      "        {\"type\": \"pricing\", \"url\": \"https://huggingface.co/pricing\"},\n",
      "        {\"type\": \"learn\", \"url\": \"https://huggingface.co/learn\"},\n",
      "        {\"type\": \"documentation transformers\", \"url\": \"https://docs.huggingface.co/transformers\"},\n",
      "        {\"type\": \"diffusers documentation\", \"url\": \"https://docs.huggingface.co/diffusers\"},\n",
      "        {\"type\": \"safetensors documentation\", \"url\": \"https://docs.huggingface.co/safetensors\"},\n",
      "        {\"type\": \"huggingface hub docs\", \"url\": \"https://docs.huggingface.co/huggingface_hub\"},\n",
      "        {\"type\": \"text generation docs\", \"url\": \"https://docs.huggingface.co/text-generation-inference\"},\n",
      "        {\"type\": \"accelerate documentation\", \"url\": \"https://docs.huggingface.co/accelerate\"},\n",
      "        {\"type\": \"smolagents docs\", \"url\": \"https://docs.huggingface.co/smolagents\"},\n",
      "        {\"type\": \"peft docs\", \"url\": \"https://docs.huggingface.co/peft\"},\n",
      "        {\"type\": \"text generation inference\", \"url\": \"https://huggingface.co/docs/text-generation-inference\"},\n",
      "        {\"type\": \"tasks\", \"url\": \"https://huggingface.co/tasks\"},\n",
      "        {\"type\": \"GitHub repository\", \"url\": \"https://github.com/huggingface\"},\n",
      "        {\"type\": \"Twitter profile\", \"url\": \"https://twitter.com/huggingface\"},\n",
      "        {\"type\": \"LinkedIn company page\", \"url\": \"https://www.linkedin.com/company/huggingface/\"},\n",
      "        {\"type\": \"discuss Hugging Face\", \"url\": \"https://discuss.huggingface.co\"},\n",
      "        {\"type\": \"status updates\", \"url\": \"https://status.huggingface.co/\"},\n",
      "        {\"type\": \"NVIDIA Parakeet TDT model\", \"url\": \"https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2\"},\n",
      "        {\"type\": \"NVIDIA OpenCode Reasoning\", \"url\": \"https://huggingface.co/datasets/nvidia/OpenCodeReasoning\"},\n",
      "        {\"type\": \"Intellect-2 RL Dataset\", \"url\": \"https://huggingface.co/datasets/PrimeIntellect/INTELLECT-2-RL-Dataset\"},\n",
      "        {\"type\": \"Hugging Face blog\", \"url\": \"https://blog.huggingface.com\"}\n",
      "    ]\n",
      "}\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /transformers (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513C8D26D0>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /diffusers (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA24C50>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA268D0>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /huggingface_hub (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA30410>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /text-generation-inference (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA259D0>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /accelerate (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA26550>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /smolagents (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513CA247D0>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='docs.huggingface.co', port=443): Max retries exceeded with url: /peft (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513C9DE950>: Failed to resolve 'docs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Connection error: HTTPSConnectionPool(host='blog.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002513C832650>: Failed to resolve 'blog.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Landing page: \n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "56.6k\n",
      "•\n",
      "983\n",
      "Wan-AI/Wan2.1-VACE-14B\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "8.8k\n",
      "•\n",
      "200\n",
      "nari-labs/Dia-1.6B\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "143k\n",
      "•\n",
      "2.27k\n",
      "multimodalart/isometric-skeumorphic-3d-bnb\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "550\n",
      "•\n",
      "194\n",
      "lodestones/Chroma\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "620\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "6.8k\n",
      "6.8k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "265\n",
      "265\n",
      "LTX Video Fast\n",
      "🎥\n",
      "ultra-fast video model, LTX 0.9.7 13B distilled\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "708\n",
      "708\n",
      "Computer Agent\n",
      "🖥\n",
      "Interact with an AI agent to perform web tasks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "437\n",
      "437\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "Running\n",
      "478\n",
      "478\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "8.64k\n",
      "•\n",
      "92\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "856\n",
      "•\n",
      "53\n",
      "nvidia/OpenCodeReasoning\n",
      "Updated\n",
      "15 days ago\n",
      "•\n",
      "14k\n",
      "•\n",
      "425\n",
      "nvidia/OpenMathReasoning\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "43.5k\n",
      "•\n",
      "243\n",
      "DMindAI/DMind_Benchmark\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "2.82k\n",
      "•\n",
      "75\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "757 models\n",
      "•\n",
      "3.29k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.13k models\n",
      "•\n",
      "6.03k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.17k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "991 models\n",
      "•\n",
      "13.4k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "221 models\n",
      "•\n",
      "2.55k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "374 models\n",
      "•\n",
      "12.4k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "144,554\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "29,034\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,272\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,606\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,687\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "13,814\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,626\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "18,869\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,450\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,139\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,138\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,729\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "models\n",
      "Webpage Title:\n",
      "Models - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Models filters\n",
      "Tasks\n",
      "Libraries\n",
      "Datasets\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Multimodal\n",
      "Audio-Text-to-Text\n",
      "Image-Text-to-Text\n",
      "Visual Question Answering\n",
      "Document Question Answering\n",
      "Video-Text-to-Text\n",
      "Visual Document Retrieval\n",
      "Any-to-Any\n",
      "Computer Vision\n",
      "Depth Estimation\n",
      "Image Classification\n",
      "Object Detection\n",
      "Image Segmentation\n",
      "Text-to-Image\n",
      "Image-to-Text\n",
      "Image-to-Image\n",
      "Image-to-Video\n",
      "Unconditional Image Generation\n",
      "Video Classification\n",
      "Text-to-Video\n",
      "Zero-Shot Image Classification\n",
      "Mask Generation\n",
      "Zero-Shot Object Detection\n",
      "Text-to-3D\n",
      "Image-to-3D\n",
      "Image Feature Extraction\n",
      "Keypoint Detection\n",
      "Natural Language Processing\n",
      "Text Classification\n",
      "Token Classification\n",
      "Table Question Answering\n",
      "Question Answering\n",
      "Zero-Shot Classification\n",
      "Translation\n",
      "Summarization\n",
      "Feature Extraction\n",
      "Text Generation\n",
      "Text2Text Generation\n",
      "Fill-Mask\n",
      "Sentence Similarity\n",
      "Text Ranking\n",
      "Audio\n",
      "Text-to-Speech\n",
      "Text-to-Audio\n",
      "Automatic Speech Recognition\n",
      "Audio-to-Audio\n",
      "Audio Classification\n",
      "Voice Activity Detection\n",
      "Tabular\n",
      "Tabular Classification\n",
      "Tabular Regression\n",
      "Time Series Forecasting\n",
      "Reinforcement Learning\n",
      "Reinforcement Learning\n",
      "Robotics\n",
      "Other\n",
      "Graph Machine Learning\n",
      "Apply filters\n",
      "Models\n",
      "Full-text search\n",
      "Add filters\n",
      "Sort: \n",
      "\t\tTrending\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "56.6k\n",
      "•\n",
      "983\n",
      "Wan-AI/Wan2.1-VACE-14B\n",
      "Image-to-Video\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "8.8k\n",
      "•\n",
      "200\n",
      "nari-labs/Dia-1.6B\n",
      "Text-to-Speech\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "143k\n",
      "•\n",
      "•\n",
      "2.27k\n",
      "multimodalart/isometric-skeumorphic-3d-bnb\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "550\n",
      "•\n",
      "•\n",
      "194\n",
      "lodestones/Chroma\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "620\n",
      "stabilityai/stable-audio-open-small\n",
      "Text-to-Audio\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "1.17k\n",
      "•\n",
      "154\n",
      "a-m-team/AM-Thinking-v1\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.38k\n",
      "•\n",
      "•\n",
      "162\n",
      "Lightricks/LTX-Video\n",
      "Text-to-Video\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "132k\n",
      "•\n",
      "•\n",
      "1.55k\n",
      "Intelligent-Internet/II-Medical-8B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "735\n",
      "•\n",
      "•\n",
      "100\n",
      "IndexTeam/Index-anisora\n",
      "Updated\n",
      "about 16 hours ago\n",
      "•\n",
      "14\n",
      "•\n",
      "98\n",
      "openbmb/AgentCPM-GUI\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "541\n",
      "•\n",
      "98\n",
      "black-forest-labs/FLUX.1-dev\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "Aug 16, 2024\n",
      "•\n",
      "1.74M\n",
      "•\n",
      "•\n",
      "10.2k\n",
      "ACE-Step/ACE-Step-v1-3.5B\n",
      "Text-to-Audio\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "448\n",
      "PrimeIntellect/INTELLECT-2\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "632\n",
      "•\n",
      "179\n",
      "Qwen/Qwen3-235B-A22B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 24 hours ago\n",
      "•\n",
      "73.6k\n",
      "•\n",
      "•\n",
      "857\n",
      "hexgrad/Kokoro-82M\n",
      "Text-to-Speech\n",
      "•\n",
      "Updated\n",
      "Apr 10\n",
      "•\n",
      "1.19M\n",
      "•\n",
      "•\n",
      "4.36k\n",
      "BLIP3o/BLIP3o-Model\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "4.35k\n",
      "•\n",
      "66\n",
      "deepseek-ai/DeepSeek-R1\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 27\n",
      "•\n",
      "562k\n",
      "•\n",
      "•\n",
      "12.2k\n",
      "facebook/OMol25\n",
      "Updated\n",
      "about 14 hours ago\n",
      "•\n",
      "63\n",
      "stepfun-ai/Step1X-3D\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "64\n",
      "facebook/KernelLLM\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 4 hours ago\n",
      "•\n",
      "52\n",
      "•\n",
      "57\n",
      "microsoft/bitnet-b1.58-2B-4T\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "19 days ago\n",
      "•\n",
      "78.1k\n",
      "•\n",
      "1.03k\n",
      "Kijai/WanVideo_comfy\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "549\n",
      "TEN-framework/ten-vad\n",
      "Voice Activity Detection\n",
      "•\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "16\n",
      "•\n",
      "53\n",
      "OuteAI/OuteTTS-1.0-0.6B\n",
      "Text-to-Speech\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "52\n",
      "fancyfeast/llama-joycaption-beta-one-hf-llava\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "7.8k\n",
      "•\n",
      "66\n",
      "tencent/HunyuanCustom\n",
      "Image-to-Video\n",
      "•\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "151\n",
      "ZuluVision/MoviiGen1.1\n",
      "Text-to-Video\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "5.17k\n",
      "•\n",
      "49\n",
      "Wan-AI/Wan2.1-VACE-1.3B\n",
      "Image-to-Video\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "1.52k\n",
      "•\n",
      "48\n",
      "Qwen/Qwen3-30B-A3B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 24 hours ago\n",
      "•\n",
      "132k\n",
      "•\n",
      "•\n",
      "573\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "datasets\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Datasets filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Modalities\n",
      "3D\n",
      "Audio\n",
      "Geospatial\n",
      "Image\n",
      "Tabular\n",
      "Text\n",
      "Time-series\n",
      "Video\n",
      "Size\n",
      "\t\t\t(rows)\n",
      "Reset Size\n",
      "< 1K\n",
      "> 1T\n",
      "Format\n",
      "json\n",
      "csv\n",
      "parquet\n",
      "imagefolder\n",
      "soundfolder\n",
      "webdataset\n",
      "text\n",
      "arrow\n",
      "Apply filters\n",
      "Datasets\n",
      "397,142\n",
      "Full-text search\n",
      "Add filters\n",
      "Sort: \n",
      "\t\tTrending\n",
      "openbmb/Ultra-FineWeb\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "8.64k\n",
      "•\n",
      "92\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "285k\n",
      "•\n",
      "856\n",
      "•\n",
      "53\n",
      "nvidia/OpenCodeReasoning\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "15 days ago\n",
      "•\n",
      "753k\n",
      "•\n",
      "14k\n",
      "•\n",
      "425\n",
      "nvidia/OpenMathReasoning\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "5.47M\n",
      "•\n",
      "43.5k\n",
      "•\n",
      "243\n",
      "DMindAI/DMind_Benchmark\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "1.87k\n",
      "•\n",
      "2.82k\n",
      "•\n",
      "75\n",
      "disco-eth/EuroSpeech\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "8.42M\n",
      "•\n",
      "16.8k\n",
      "•\n",
      "18\n",
      "BLIP3o/BLIP3o-60k\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "7.1k\n",
      "•\n",
      "1.73k\n",
      "•\n",
      "18\n",
      "Salesforce/APIGen-MT-5k\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "5k\n",
      "•\n",
      "908\n",
      "•\n",
      "32\n",
      "Rapidata/Hidream_t2i_human_preference\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "13k\n",
      "•\n",
      "211\n",
      "•\n",
      "17\n",
      "xzx34/SocialMaze\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "200k\n",
      "•\n",
      "376\n",
      "•\n",
      "16\n",
      "BLIP3o/BLIP3o-Pretrain-Long-Caption\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "20.1M\n",
      "•\n",
      "3.63k\n",
      "•\n",
      "13\n",
      "gaia-benchmark/GAIA\n",
      "Updated\n",
      "Feb 13\n",
      "•\n",
      "13.4k\n",
      "•\n",
      "332\n",
      "HuggingFaceFW/fineweb\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 31\n",
      "•\n",
      "25B\n",
      "•\n",
      "511k\n",
      "•\n",
      "2.16k\n",
      "FreedomIntelligence/medical-o1-reasoning-SFT\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "90.1k\n",
      "•\n",
      "11.2k\n",
      "•\n",
      "710\n",
      "LEXam-Benchmark/LEXam\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "4.89k\n",
      "•\n",
      "124\n",
      "•\n",
      "12\n",
      "openai/gsm8k\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 4, 2024\n",
      "•\n",
      "17.6k\n",
      "•\n",
      "575k\n",
      "•\n",
      "732\n",
      "Qwen/PolyMath\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "9k\n",
      "•\n",
      "3.25k\n",
      "•\n",
      "26\n",
      "nvidia/Nemotron-CrossThink\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "19 days ago\n",
      "•\n",
      "16.4k\n",
      "•\n",
      "100\n",
      "PatronusAI/TRAIL\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "148\n",
      "•\n",
      "49\n",
      "•\n",
      "11\n",
      "nvidia/dynpose-100k\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "3.06k\n",
      "•\n",
      "34\n",
      "fka/awesome-chatgpt-prompts\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "203\n",
      "•\n",
      "16.6k\n",
      "•\n",
      "7.79k\n",
      "gretelai/synthetic_text_to_sql\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 10, 2024\n",
      "•\n",
      "106k\n",
      "•\n",
      "3.8k\n",
      "•\n",
      "547\n",
      "HuggingFaceM4/the_cauldron\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "1.88M\n",
      "•\n",
      "309k\n",
      "•\n",
      "434\n",
      "tokyotech-llm/swallow-code\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "145M\n",
      "•\n",
      "5.37k\n",
      "•\n",
      "39\n",
      "twinkle-ai/tw-leetcode\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 7 hours ago\n",
      "•\n",
      "142\n",
      "•\n",
      "102\n",
      "•\n",
      "9\n",
      "ByteDance/WildDoc\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "35.8k\n",
      "•\n",
      "170\n",
      "•\n",
      "9\n",
      "roneneldan/TinyStories\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Aug 12, 2024\n",
      "•\n",
      "2.14M\n",
      "•\n",
      "30.8k\n",
      "•\n",
      "659\n",
      "mozilla-foundation/common_voice_17_0\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jun 16, 2024\n",
      "•\n",
      "13M\n",
      "•\n",
      "39.3k\n",
      "•\n",
      "283\n",
      "linxy/LaTeX_OCR\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Dec 29, 2024\n",
      "•\n",
      "269k\n",
      "•\n",
      "914\n",
      "•\n",
      "83\n",
      "MiniMaxAI/TTS-Multilingual-Test-Set\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "48\n",
      "•\n",
      "430\n",
      "•\n",
      "9\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "100\n",
      "Next\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "spaces\n",
      "Webpage Title:\n",
      "Spaces - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Spaces\n",
      "·\n",
      "The AI App Directory\n",
      "New Space\n",
      "What is Spaces?\n",
      "Image Generation\n",
      "Video Generation\n",
      "Text Generation\n",
      "Language Translation\n",
      "Speech Synthesis\n",
      "3D Modeling\n",
      "Object Detection\n",
      "Text Analysis\n",
      "Image Editing\n",
      "Code Generation\n",
      "Question Answering\n",
      "Data Visualization\n",
      "Voice Cloning\n",
      "Background Removal\n",
      "Image Upscaling\n",
      "OCR\n",
      "Document Analysis\n",
      "Visual QA\n",
      "Image Captioning\n",
      "Chatbots\n",
      "Sentiment Analysis\n",
      "Text Summarization\n",
      "Music Generation\n",
      "Medical Imaging\n",
      "Financial Analysis\n",
      "Game AI\n",
      "Model Benchmarking\n",
      "Fine Tuning Tools\n",
      "Dataset Creation\n",
      "Pose Estimation\n",
      "Face Recognition\n",
      "Anomaly Detection\n",
      "Recommendation Systems\n",
      "Character Animation\n",
      "Style Transfer\n",
      "Image\n",
      "Spaces of the week\n",
      "19 May 2025\n",
      "Sort: \n",
      "\t\tRelevance\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "265\n",
      "LTX Video Fast\n",
      "🎥\n",
      "ultra-fast video model, LTX 0.9.7 13B distilled\n",
      "Lightricks\n",
      "2 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "147\n",
      "Joy Caption Beta One\n",
      "🖼\n",
      "Generate descriptive captions for images based on various styles\n",
      "fancyfeast\n",
      "8 days ago\n",
      "Running\n",
      "94\n",
      "SmolVLM realtime WebGPU\n",
      "⚡\n",
      "Generate descriptions based on camera input\n",
      "webml-community\n",
      "6 days ago\n",
      "Running\n",
      "82\n",
      "Seed1.5 VL\n",
      "🚀\n",
      "Seed1.5-VL API Demo\n",
      "ByteDance-Seed\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "128\n",
      "Step1X 3D\n",
      "🐨\n",
      "image2mesh\n",
      "stepfun-ai\n",
      "6 days ago\n",
      "Running\n",
      "19\n",
      "DiffVox\n",
      "🦀\n",
      "Enhance vocals with EQ, compressor, delay, and reverb effects\n",
      "yoyolicoris\n",
      "3 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "26\n",
      "Daily Paper Podcast\n",
      "🎙\n",
      "Generates a podcast about today's top trending paper.\n",
      "fdaudens\n",
      "about 18 hours ago\n",
      "Running\n",
      "15\n",
      "Surf Spot Finder\n",
      "🏄\n",
      "Find a surf spot near you\n",
      "mozilla-ai\n",
      "5 days ago\n",
      "All running apps, trending first\n",
      "Running\n",
      "6.8k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "enzostvs\n",
      "10 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "265\n",
      "LTX Video Fast\n",
      "🎥\n",
      "ultra-fast video model, LTX 0.9.7 13B distilled\n",
      "Lightricks\n",
      "2 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "708\n",
      "Computer Agent\n",
      "🖥\n",
      "Interact with an AI agent to perform web tasks\n",
      "smolagents\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "437\n",
      "DreamO\n",
      "🐨\n",
      "A Unified Framework for Image Customization\n",
      "ByteDance\n",
      "9 days ago\n",
      "Running\n",
      "478\n",
      "FLUX Pro Unlimited\n",
      "🔥\n",
      "Use the FLUX-Pro model as much as you want.\n",
      "NihalGazi\n",
      "4 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "411\n",
      "ACE Step\n",
      "😻\n",
      "A Step Towards Music Generation Foundation Model\n",
      "ACE-Step\n",
      "4 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "147\n",
      "Joy Caption Beta One\n",
      "🖼\n",
      "Generate descriptive captions for images based on various styles\n",
      "fancyfeast\n",
      "8 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "128\n",
      "Step1X 3D\n",
      "🐨\n",
      "image2mesh\n",
      "stepfun-ai\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "158\n",
      "FramePack F1\n",
      "📹\n",
      "fast video generation from images & text\n",
      "linoyts\n",
      "7 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "334\n",
      "Parakeet-TDT-0.6b-V2\n",
      "Transcribe audio files to text with timestamps\n",
      "nvidia\n",
      "4 days ago\n",
      "Running\n",
      "94\n",
      "SmolVLM realtime WebGPU\n",
      "⚡\n",
      "Generate descriptions based on camera input\n",
      "webml-community\n",
      "6 days ago\n",
      "Running\n",
      "82\n",
      "Seed1.5 VL\n",
      "🚀\n",
      "Seed1.5-VL API Demo\n",
      "ByteDance-Seed\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "1.38k\n",
      "Dia 1.6B\n",
      "👯\n",
      "Generate realistic dialogue from a script, using Dia!\n",
      "nari-labs\n",
      "15 days ago\n",
      "Running\n",
      "80\n",
      "MiniMax Speech Tech Report\n",
      "🎙\n",
      "Generate high-quality speech from text with voice cloning\n",
      "MiniMaxAI\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "8.78k\n",
      "Kolors Virtual Try-On\n",
      "👕\n",
      "Try on clothes by uploading images\n",
      "Kwai-Kolors\n",
      "Sep 18, 2024\n",
      "Running\n",
      "107\n",
      "Realistic Text To Speech Unlimited\n",
      "🔥\n",
      "Free Text-To-Speech generator with Emotion control (OpenAI)\n",
      "NihalGazi\n",
      "about 22 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "565\n",
      "ICEdit\n",
      "🖼\n",
      "Universal Image Editing is worth a single LoRA\n",
      "RiverZ\n",
      "12 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "2.66k\n",
      "Hunyuan3D-2.0\n",
      "🌍\n",
      "Text-to-3D and Image-to-3D Generation\n",
      "tencent\n",
      "25 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "10.2k\n",
      "AI Comic Factory\n",
      "👩\n",
      "Create your own AI comic with a single prompt\n",
      "jbilcke-hf\n",
      "Oct 15, 2024\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "8.33k\n",
      "FLUX.1 [dev]\n",
      "🖥\n",
      "Generate images from text prompts\n",
      "black-forest-labs\n",
      "Apr 16\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "58\n",
      "DreamO Video\n",
      "🐨\n",
      "A Unified Framework for Custom Image and Video generation\n",
      "openfree\n",
      "about 7 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "312\n",
      "NSFW Uncensored image to video\n",
      "🎬\n",
      "MAX ~60sec Video - AI Limits\n",
      "Heartsync\n",
      "about 16 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "1.84k\n",
      "Background Removal\n",
      "🌘\n",
      "Remove backgrounds from images using URLs, file uploads, or image sliders\n",
      "not-lain\n",
      "15 days ago\n",
      "Running\n",
      "on\n",
      "A100\n",
      "82\n",
      "LegoGPT-Demo\n",
      "🧱\n",
      "Generate stable LEGO structures from text prompts.\n",
      "cmu-gil\n",
      "3 days ago\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "100\n",
      "Next\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "Brand assets - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face · Brand assets\n",
      "HF Logos\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      "HF Colors\n",
      "#FFD21E\n",
      "#FF9D00\n",
      "#6B7280\n",
      "HF Bio\n",
      "Hugging Face is the collaboration platform for the machine learning community.\n",
      "\n",
      "The Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\n",
      "\n",
      "With the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolution.\n",
      "Copy to clipboard\n",
      "HF Universe\n",
      "Find other assets available for use from the Hugging Face brand universe\n",
      "here\n",
      ".\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "enterprise solutions\n",
      "Webpage Title:\n",
      "Enterprise Hub - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Enterprise Hub\n",
      "Enterprise-ready version of the world’s leading AI platform\n",
      "Subscribe to\n",
      "Enterprise Hub\n",
      "for $20/user/month with your Hub organization\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Extra Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Enterprise Hub\n",
      "or\n",
      "Talk to sales\n",
      "NVIDIA\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "364 models\n",
      "•\n",
      "26.3k followers\n",
      "Shopify\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "455 followers\n",
      "AMD\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "141 models\n",
      "•\n",
      "1.54k followers\n",
      "Together\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "29 models\n",
      "•\n",
      "598 followers\n",
      "Qwen\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "280 models\n",
      "•\n",
      "31.4k followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "267 followers\n",
      "Fidelity Investments\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "144 followers\n",
      "Nutanix\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "261 models\n",
      "•\n",
      "98 followers\n",
      "creditkarma\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "66 followers\n",
      "Technology Innovation Institute\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "71 models\n",
      "•\n",
      "1.35k followers\n",
      "HiddenLayer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "72 followers\n",
      "Skywork\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "40 models\n",
      "•\n",
      "692 followers\n",
      "Liquid AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "192 followers\n",
      "Lightricks\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "13 models\n",
      "•\n",
      "931 followers\n",
      "Infosys Limited\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2 models\n",
      "•\n",
      "833 followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.13k models\n",
      "•\n",
      "6.03k followers\n",
      "Snowflake\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "515 followers\n",
      "Arm\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "197 followers\n",
      "LiveRAG by AIIR\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "130 followers\n",
      "ServiceNow-AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "3 models\n",
      "•\n",
      "277 followers\n",
      "Deutsche Telekom AG\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "146 followers\n",
      "Jusbrasil\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "98 followers\n",
      "H2O.ai\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "71 models\n",
      "•\n",
      "426 followers\n",
      "Chegg Inc\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "86 followers\n",
      "Johnson & Johnson\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "62 followers\n",
      "MiniMax\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2 models\n",
      "•\n",
      "679 followers\n",
      "Mistral AI_\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "26 models\n",
      "•\n",
      "8.37k followers\n",
      "Stability AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "106 models\n",
      "•\n",
      "23.4k followers\n",
      "Meta Llama\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "70 models\n",
      "•\n",
      "44k followers\n",
      "Nerdy Face\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "300 followers\n",
      "Orange\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "223 followers\n",
      "ServiceNow\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "505 followers\n",
      "Xsolla\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "137 followers\n",
      "Toyota Research Institute\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "115 followers\n",
      "Mercedes-Benz AG\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "165 followers\n",
      "IBM Granite\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "117 models\n",
      "•\n",
      "1.75k followers\n",
      "Aledade Inc\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "71 followers\n",
      "HyperCLOVA X\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "3 models\n",
      "•\n",
      "301 followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "160 followers\n",
      "Widn AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "48 followers\n",
      "BCG X\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "40 followers\n",
      "Twelve Labs\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "44 followers\n",
      "Compliance & Certifications\n",
      "GDPR Compliant\n",
      "SOC 2 Type 2\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "pricing\n",
      "Webpage Title:\n",
      "Hugging Face – Pricing\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Users and organizations already use the Hub as a collaboration platform,\n",
      "we’re making it easy to seamlessly and scalably launch ML compute directly from the Hub.\n",
      "HF Hub\n",
      "Collaborate on Machine Learning\n",
      "Host unlimited public models, datasets\n",
      "Create unlimited orgs with no member limits\n",
      "Access the latest ML tools and open source\n",
      "Community support\n",
      "Forever\n",
      "Free\n",
      "PRO\n",
      "Pro Account\n",
      "Unlock advanced HF features\n",
      "ZeroGPU and Dev Mode for Spaces\n",
      "Free credits across all Inference Providers\n",
      "Get early access to upcoming features\n",
      "Show your support with a Pro badge\n",
      "Subscribe for\n",
      "$9\n",
      "/month\n",
      "Enterprise Hub\n",
      "Accelerate your AI roadmap\n",
      "SSO and SAML support\n",
      "Select data location with Storage Regions\n",
      "Precise actions reviews with Audit logs\n",
      "Granular access control with Resource groups\n",
      "Centralized token control and approval\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "5x more ZeroGPU quota for all org members\n",
      "Deploy Inference on your own Infra\n",
      "Managed billing with yearly commits\n",
      "Priority support\n",
      "Starting at\n",
      "$20\n",
      "per user per month\n",
      "Spaces Hardware\n",
      "Upgrade your Space compute\n",
      "Free CPUs\n",
      "Build more advanced Spaces\n",
      "7 optimized hardware available\n",
      "From CPU to GPU to Accelerators\n",
      "Starting at\n",
      "$0\n",
      "/hour\n",
      "Inference Endpoints\n",
      "Deploy models on fully managed infrastructure\n",
      "Deploy dedicated Endpoints in seconds\n",
      "Keep your costs low\n",
      "Fully-managed autoscaling\n",
      "Enterprise security\n",
      "Starting at\n",
      "$0.032\n",
      "/hour\n",
      "Need support to accelerate AI in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "→\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $0\n",
      "Spaces are one of the most popular ways to share ML applications and demos with the world.\n",
      "Upgrade your Spaces with our selection of custom on-demand hardware:\n",
      "→\n",
      "Get started with Spaces\n",
      "Name\n",
      "CPU\n",
      "Memory\n",
      "Accelerator\n",
      "VRAM\n",
      "Hourly price\n",
      "CPU Basic\n",
      "2 vCPU\n",
      "16 GB\n",
      "-\n",
      "-\n",
      "FREE\n",
      "CPU Upgrade\n",
      "8 vCPU\n",
      "32 GB\n",
      "-\n",
      "-\n",
      "$0.03\n",
      "Nvidia T4 - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.40\n",
      "Nvidia T4 - medium\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.60\n",
      "1x Nvidia L4\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia L4\n",
      "24 GB\n",
      "$0.80\n",
      "4x Nvidia L4\n",
      "48 vCPU\n",
      "186 GB\n",
      "Nvidia L4\n",
      "96 GB\n",
      "$3.80\n",
      "1x Nvidia L40S\n",
      "8 vCPU\n",
      "62 GB\n",
      "Nvidia L4\n",
      "48 GB\n",
      "$1.80\n",
      "4x Nvidia L40S\n",
      "48 vCPU\n",
      "382 GB\n",
      "Nvidia L4\n",
      "192 GB\n",
      "$8.30\n",
      "8x Nvidia L40S\n",
      "192 vCPU\n",
      "1534 GB\n",
      "Nvidia L4\n",
      "384 GB\n",
      "$23.50\n",
      "Nvidia A10G - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.00\n",
      "Nvidia A10G - large\n",
      "12 vCPU\n",
      "46 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.50\n",
      "2x Nvidia A10G - large\n",
      "24 vCPU\n",
      "92 GB\n",
      "Nvidia A10G\n",
      "48 GB\n",
      "$3.00\n",
      "4x Nvidia A10G - large\n",
      "48 vCPU\n",
      "184 GB\n",
      "Nvidia A10G\n",
      "96 GB\n",
      "$5.00\n",
      "Nvidia A100 - large\n",
      "12 vCPU\n",
      "142 GB\n",
      "Nvidia A100\n",
      "80 GB\n",
      "$4.00\n",
      "Custom\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "Spaces Persistent Storage\n",
      "All Spaces get ephemeral storage for free but you can upgrade and add persistent storage at any time.\n",
      "Name\n",
      "Storage\n",
      "Monthly price\n",
      "Small\n",
      "20 GB\n",
      "$5\n",
      "Medium\n",
      "150 GB\n",
      "$25\n",
      "Large\n",
      "1 TB\n",
      "$100\n",
      "Building something cool as a side project? We also offer community GPU grants.\n",
      "Inference Endpoints\n",
      "Starting at $0.033/hour\n",
      "Inference Endpoints (dedicated) offers a secure production solution to easily deploy any ML model on dedicated\n",
      "\t\t\t\t\tand autoscaling infrastructure, right from the HF Hub.\n",
      "→\n",
      "Learn more\n",
      "CPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "vCPUs\n",
      "Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.03\n",
      "2\n",
      "4GB\n",
      "$0.07\n",
      "4\n",
      "8GB\n",
      "$0.13\n",
      "8\n",
      "16GB\n",
      "$0.27\n",
      "16\n",
      "32GB\n",
      "$0.54\n",
      "azure\n",
      "Intel Xeon\n",
      "1\n",
      "2GB\n",
      "$0.06\n",
      "2\n",
      "4GB\n",
      "$0.12\n",
      "4\n",
      "8GB\n",
      "$0.24\n",
      "8\n",
      "16GB\n",
      "$0.48\n",
      "gcp\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.05\n",
      "2\n",
      "4GB\n",
      "$0.10\n",
      "4\n",
      "8GB\n",
      "$0.20\n",
      "8\n",
      "16GB\n",
      "$0.40\n",
      "Accelerator\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "Topology\n",
      "Accelerator Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Inf2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNeuron\n",
      "x1\n",
      "14.5GB\n",
      "$0.75\n",
      "x12\n",
      "760GB\n",
      "$12.00\n",
      "gcp\n",
      "TPU\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tv5e\n",
      "1x1\n",
      "16GB\n",
      "$1.20\n",
      "2x2\n",
      "64GB\n",
      "$4.75\n",
      "2x4\n",
      "128GB\n",
      "$9.50\n",
      "GPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "GPUs\n",
      "GPU Memory\n",
      "Hourly rate\n",
      "aws\n",
      "NVIDIA T4\n",
      "1\n",
      "14GB\n",
      "$0.50\n",
      "4\n",
      "56GB\n",
      "$3.00\n",
      "aws\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.80\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "aws\n",
      "NVIDIA L40S\n",
      "1\n",
      "48GB\n",
      "$1.80\n",
      "4\n",
      "192GB\n",
      "$8.30\n",
      "8\n",
      "384GB\n",
      "$23.50\n",
      "aws\n",
      "NVIDIA A10G\n",
      "1\n",
      "24GB\n",
      "$1.00\n",
      "4\n",
      "96GB\n",
      "$5.00\n",
      "aws\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$4.00\n",
      "2\n",
      "160GB\n",
      "$8.00\n",
      "4\n",
      "320GB\n",
      "$16.00\n",
      "8\n",
      "640GB\n",
      "$32.00\n",
      "aws\n",
      "NVIDIA H200\n",
      "1\n",
      "141GB\n",
      "$5.00\n",
      "2\n",
      "282GB\n",
      "$10.00\n",
      "4\n",
      "564GB\n",
      "$20.00\n",
      "8\n",
      "1128GB\n",
      "$40.00\n",
      "gcp\n",
      "NVIDIA T4\n",
      "1\n",
      "16GB\n",
      "$0.50\n",
      "gcp\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.70\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "gcp\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$3.60\n",
      "2\n",
      "160GB\n",
      "$7.20\n",
      "4\n",
      "320GB\n",
      "$14.40\n",
      "8\n",
      "640GB\n",
      "$28.80\n",
      "gcp\n",
      "NVIDIA H100\n",
      "1\n",
      "80GB\n",
      "$10.00\n",
      "2\n",
      "160GB\n",
      "$20.00\n",
      "4\n",
      "320GB\n",
      "$40.00\n",
      "8\n",
      "640GB\n",
      "$80.00\n",
      "Pro Account\n",
      "PRO\n",
      "A monthly subscription to access powerful features.\n",
      "→\n",
      "Get Pro\n",
      "($9/month)\n",
      "ZeroGPU\n",
      ": Get 5x usage quota and highest GPU queue priority\n",
      "Spaces Hosting\n",
      ": Create ZeroGPU Spaces with H200 hardware\n",
      "Spaces Dev Mode\n",
      ": Fast iterations via SSH/VS Code for Spaces\n",
      "Inference Providers\n",
      ": Get $2 included credits across all Inference Providers\n",
      "Dataset Viewer\n",
      ": Activate it on private datasets\n",
      "Blog Articles\n",
      ": Publish articles to the Hugging Face blog\n",
      "Social Posts\n",
      ": Share short updates with the community\n",
      "Features Preview\n",
      ": Get early access to upcoming\n",
      "\t\t\t\t\t\t\t\t\t\tfeatures\n",
      "PRO\n",
      "Badge\n",
      ":\n",
      "\t\t\t\t\t\t\t\t\t\tShow your support on your profile\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "learn\n",
      "Webpage Title:\n",
      "Hugging Face - Learn\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Learn\n",
      "LLM Course\n",
      "This course will teach you about large language models using libraries from the HF ecosystem\n",
      "MCP Course\n",
      "This course will teach you about Model Context Protocol\n",
      "Agents Course\n",
      "Learn to build and deploy your own AI agents\n",
      "Deep RL Course\n",
      "This course will teach you about deep reinforcement learning using libraries from the HF ecosystem\n",
      "Community Computer Vision Course\n",
      "This course will teach you about computer vision ML using libraries and models from the HF ecosystem\n",
      "Audio Course\n",
      "Learn to apply transformers to audio data using libraries from the HF ecosystem\n",
      "Open-Source AI Cookbook\n",
      "A collection of open-source-powered notebooks by AI builders, for AI builders\n",
      "ML for Games Course\n",
      "This course will teach you about integrating AI models your game and using AI tools in your game development workflow\n",
      "Diffusion Course\n",
      "Learn about diffusion models & how to use them with diffusers\n",
      "ML for 3D Course\n",
      "Learn about 3D ML with libraries from the HF ecosystem\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "documentation transformers\n",
      "\n",
      "\n",
      "diffusers documentation\n",
      "\n",
      "\n",
      "safetensors documentation\n",
      "\n",
      "\n",
      "huggingface hub docs\n",
      "\n",
      "\n",
      "text generation docs\n",
      "\n",
      "\n",
      "accelerate documentation\n",
      "\n",
      "\n",
      "smolagents docs\n",
      "\n",
      "\n",
      "peft docs\n",
      "\n",
      "\n",
      "text generation inference\n",
      "Webpage Title:\n",
      "Text Generation Inference\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "text-generation-inference documentation\n",
      "Text Generation Inference\n",
      "text-generation-inference\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "EN\n",
      "Getting started\n",
      "Text Generation Inference\n",
      "Quick Tour\n",
      "Supported Models\n",
      "Using TGI with Nvidia GPUs\n",
      "Using TGI with AMD GPUs\n",
      "Using TGI with Intel Gaudi\n",
      "Using TGI with AWS Trainium and Inferentia\n",
      "Using TGI with Google TPUs\n",
      "Using TGI with Intel GPUs\n",
      "Installation from source\n",
      "Multi-backend support\n",
      "Internal Architecture\n",
      "Usage Statistics\n",
      "Tutorials\n",
      "Consuming TGI\n",
      "Preparing Model for Serving\n",
      "Serving Private & Gated Models\n",
      "Using TGI CLI\n",
      "Non-core Model Serving\n",
      "Safety\n",
      "Using Guidance, JSON, tools\n",
      "Visual Language Models\n",
      "Monitoring TGI with Prometheus and Grafana\n",
      "Train Medusa\n",
      "Backends\n",
      "Neuron\n",
      "Gaudi\n",
      "TensorRT-LLM\n",
      "Llamacpp\n",
      "Reference\n",
      "All TGI CLI options\n",
      "Exported Metrics\n",
      "API Reference\n",
      "Conceptual Guides\n",
      "V3 update, caching and chunking\n",
      "Streaming\n",
      "Quantization\n",
      "Tensor Parallelism\n",
      "PagedAttention\n",
      "Safetensors\n",
      "Flash Attention\n",
      "Speculation (Medusa, ngram)\n",
      "How Guidance Works (via outlines)\n",
      "LoRA (Low-Rank Adaptation)\n",
      "External Resources\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Text Generation Inference\n",
      "Text Generation Inference (TGI) is a toolkit for deploying and serving Large Language Models (LLMs). TGI enables high-performance text generation for the most popular open-source LLMs, including Llama, Falcon, StarCoder, BLOOM, GPT-NeoX, and T5.\n",
      "Text Generation Inference implements many optimizations and features, such as:\n",
      "Simple launcher to serve most popular LLMs\n",
      "Production ready (distributed tracing with Open Telemetry, Prometheus metrics)\n",
      "Tensor Parallelism for faster inference on multiple GPUs\n",
      "Token streaming using Server-Sent Events (SSE)\n",
      "Continuous batching of incoming requests for increased total throughput\n",
      "Optimized transformers code for inference using\n",
      "Flash Attention\n",
      "and\n",
      "Paged Attention\n",
      "on the most popular architectures\n",
      "Quantization with\n",
      "bitsandbytes\n",
      "and\n",
      "GPT-Q\n",
      "Safetensors\n",
      "weight loading\n",
      "Watermarking with\n",
      "A Watermark for Large Language Models\n",
      "Logits warper (temperature scaling, top-p, top-k, repetition penalty)\n",
      "Stop sequences\n",
      "Log probabilities\n",
      "Fine-tuning Support: Utilize fine-tuned models for specific tasks to achieve higher accuracy and performance.\n",
      "Guidance\n",
      ": Enable function calling and tool-use by forcing the model to generate structured outputs based on your own predefined output schemas.\n",
      "Text Generation Inference is used in production by multiple projects, such as:\n",
      "Hugging Chat\n",
      ", an open-source interface for open-access models, such as Open Assistant and Llama\n",
      "OpenAssistant\n",
      ", an open-source community effort to train LLMs in the open\n",
      "nat.dev\n",
      ", a playground to explore and compare LLMs.\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Quick Tour\n",
      "→\n",
      "Text\n",
      "Generation\n",
      "Inference\n",
      "\n",
      "\n",
      "\n",
      "tasks\n",
      "Webpage Title:\n",
      "Tasks - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Tasks\n",
      "Hugging Face is the home for all Machine Learning tasks. Here you can find what you need to get started with a\n",
      "\t\t\t\ttask: demos, use cases, models, datasets, and more!\n",
      "Multimodal\n",
      "Any-to-Any\n",
      "6,924 models\n",
      "Audio-Text-to-Text\n",
      "68 models\n",
      "Contribute\n",
      "Document Question Answering\n",
      "227 models\n",
      "Visual Document Retrieval\n",
      "53 models\n",
      "Image-Text-to-Text\n",
      "9,457 models\n",
      "Video-Text-to-Text\n",
      "132 models\n",
      "Visual Question Answering\n",
      "535 models\n",
      "Natural Language Processing\n",
      "Feature Extraction\n",
      "14,497 models\n",
      "Fill-Mask\n",
      "14,731 models\n",
      "Question Answering\n",
      "13,351 models\n",
      "Sentence Similarity\n",
      "11,121 models\n",
      "Summarization\n",
      "2,323 models\n",
      "Table Question Answering\n",
      "155 models\n",
      "Text Classification\n",
      "94,016 models\n",
      "Text Generation\n",
      "230,705 models\n",
      "Text Ranking\n",
      "340 models\n",
      "Token Classification\n",
      "22,471 models\n",
      "Translation\n",
      "5,790 models\n",
      "Zero-Shot Classification\n",
      "398 models\n",
      "Computer Vision\n",
      "Depth Estimation\n",
      "200 models\n",
      "Image Classification\n",
      "17,074 models\n",
      "Image Feature Extraction\n",
      "701 models\n",
      "Image Segmentation\n",
      "1,380 models\n",
      "Image-to-Image\n",
      "1,135 models\n",
      "Image-to-Text\n",
      "814 models\n",
      "Keypoint Detection\n",
      "57 models\n",
      "Mask Generation\n",
      "64 models\n",
      "Object Detection\n",
      "3,484 models\n",
      "Video Classification\n",
      "1,521 models\n",
      "Text-to-Image\n",
      "75,006 models\n",
      "Text-to-Video\n",
      "517 models\n",
      "Unconditional Image Generation\n",
      "2,007 models\n",
      "Zero-Shot Image Classification\n",
      "851 models\n",
      "Zero-Shot Object Detection\n",
      "57 models\n",
      "Text-to-3D\n",
      "71 models\n",
      "Image-to-3D\n",
      "233 models\n",
      "Audio\n",
      "Audio Classification\n",
      "3,220 models\n",
      "Audio-to-Audio\n",
      "3,926 models\n",
      "Automatic Speech Recognition\n",
      "24,102 models\n",
      "Text-to-Speech\n",
      "2,995 models\n",
      "Tabular\n",
      "Tabular Classification\n",
      "296 models\n",
      "Tabular Regression\n",
      "166 models\n",
      "Reinforcement Learning\n",
      "Reinforcement Learning\n",
      "59,112 models\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "GitHub repository\n",
      "Webpage Title:\n",
      "Hugging Face · GitHub\n",
      "Webpage Contents:\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "huggingface\n",
      "Product\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Models\n",
      "New\n",
      "Manage and compare prompts\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "Discussions\n",
      "Collaborate outside of code\n",
      "Code Search\n",
      "Find more, search less\n",
      "Explore\n",
      "Why GitHub\n",
      "All features\n",
      "Documentation\n",
      "GitHub Skills\n",
      "Blog\n",
      "Solutions\n",
      "By company size\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "By use case\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "By industry\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "Topics\n",
      "AI\n",
      "DevOps\n",
      "Security\n",
      "Software Development\n",
      "View all\n",
      "Explore\n",
      "Learning Pathways\n",
      "Events & Webinars\n",
      "Ebooks & Whitepapers\n",
      "Customer Stories\n",
      "Partners\n",
      "Executive Insights\n",
      "Open Source\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "The ReadME Project\n",
      "GitHub community articles\n",
      "Repositories\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "Available add-ons\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more quickly\n",
      "Cancel\n",
      "Create saved search\n",
      "Sign in\n",
      "Sign up\n",
      "Appearance settings\n",
      "Reseting focus\n",
      "You signed in with another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You signed out in another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You switched accounts on another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "Dismiss alert\n",
      "Hugging Face\n",
      "The AI community building the future.\n",
      "Verified\n",
      "We've verified that the organization\n",
      "huggingface\n",
      "controls the domain:\n",
      "huggingface.co\n",
      "Learn more about verified organizations\n",
      "49.1k\n",
      "followers\n",
      "NYC + Paris\n",
      "https://huggingface.co/\n",
      "X\n",
      "@huggingface\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "0\n",
      "More\n",
      "Overview\n",
      "Repositories\n",
      "Projects\n",
      "Packages\n",
      "People\n",
      "Sponsoring\n",
      "Pinned\n",
      "Loading\n",
      "transformers\n",
      "transformers\n",
      "Public\n",
      "🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "Python\n",
      "145k\n",
      "29k\n",
      "diffusers\n",
      "diffusers\n",
      "Public\n",
      "🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n",
      "Python\n",
      "29k\n",
      "6k\n",
      "datasets\n",
      "datasets\n",
      "Public\n",
      "🤗 The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools\n",
      "Python\n",
      "20.1k\n",
      "2.8k\n",
      "peft\n",
      "peft\n",
      "Public\n",
      "🤗 PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.\n",
      "Python\n",
      "18.5k\n",
      "1.9k\n",
      "accelerate\n",
      "accelerate\n",
      "Public\n",
      "🚀 A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support\n",
      "Python\n",
      "8.7k\n",
      "1.1k\n",
      "optimum\n",
      "optimum\n",
      "Public\n",
      "🚀 Accelerate inference and training of 🤗 Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\n",
      "Python\n",
      "2.9k\n",
      "536\n",
      "Repositories\n",
      "Loading\n",
      "Type\n",
      "Select type\n",
      "Forks\n",
      "Archived\n",
      "Mirrors\n",
      "Templates\n",
      "Language\n",
      "Select language\n",
      "All\n",
      "C\n",
      "C#\n",
      "C++\n",
      "Cuda\n",
      "Dockerfile\n",
      "Go\n",
      "Handlebars\n",
      "HTML\n",
      "Java\n",
      "JavaScript\n",
      "Jupyter Notebook\n",
      "Kotlin\n",
      "Lua\n",
      "MDX\n",
      "Mustache\n",
      "Nix\n",
      "Python\n",
      "Rust\n",
      "Shell\n",
      "Smarty\n",
      "Svelte\n",
      "Swift\n",
      "TypeScript\n",
      "Sort\n",
      "Select order\n",
      "Last updated\n",
      "Name\n",
      "Stars\n",
      "Showing 10 of 316 repositories\n",
      "diffusers\n",
      "Public\n",
      "🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\n",
      "huggingface/diffusers’s past year of commit activity\n",
      "Python\n",
      "29,034\n",
      "Apache-2.0\n",
      "5,968\n",
      "497\n",
      "(11 issues need help)\n",
      "188\n",
      "Updated\n",
      "May 20, 2025\n",
      "optimum-habana\n",
      "Public\n",
      "Easy and lightning fast training of 🤗 Transformers on Habana Gaudi processor (HPU)\n",
      "huggingface/optimum-habana’s past year of commit activity\n",
      "Python\n",
      "186\n",
      "Apache-2.0\n",
      "258\n",
      "18\n",
      "(1 issue needs help)\n",
      "33\n",
      "Updated\n",
      "May 20, 2025\n",
      "open-r1\n",
      "Public\n",
      "Fully open reproduction of DeepSeek-R1\n",
      "huggingface/open-r1’s past year of commit activity\n",
      "Python\n",
      "24,468\n",
      "Apache-2.0\n",
      "2,253\n",
      "261\n",
      "36\n",
      "Updated\n",
      "May 20, 2025\n",
      "optimum\n",
      "Public\n",
      "🚀 Accelerate inference and training of 🤗 Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\n",
      "huggingface/optimum’s past year of commit activity\n",
      "Python\n",
      "2,904\n",
      "Apache-2.0\n",
      "536\n",
      "291\n",
      "(2 issues need help)\n",
      "59\n",
      "Updated\n",
      "May 20, 2025\n",
      "transformers\n",
      "Public\n",
      "🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "huggingface/transformers’s past year of commit activity\n",
      "Python\n",
      "144,554\n",
      "Apache-2.0\n",
      "29,000\n",
      "1,047\n",
      "(2 issues need help)\n",
      "748\n",
      "Updated\n",
      "May 20, 2025\n",
      "blog\n",
      "Public\n",
      "Public repo for HF blog posts\n",
      "huggingface/blog’s past year of commit activity\n",
      "Jupyter Notebook\n",
      "2,935\n",
      "867\n",
      "153\n",
      "(1 issue needs help)\n",
      "58\n",
      "Updated\n",
      "May 20, 2025\n",
      "hub-docs\n",
      "Public\n",
      "Docs of the Hugging Face Hub\n",
      "huggingface/hub-docs’s past year of commit activity\n",
      "Handlebars\n",
      "388\n",
      "Apache-2.0\n",
      "305\n",
      "103\n",
      "25\n",
      "Updated\n",
      "May 20, 2025\n",
      "transformers.js\n",
      "Public\n",
      "State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser, with no need for a server!\n",
      "huggingface/transformers.js’s past year of commit activity\n",
      "JavaScript\n",
      "13,626\n",
      "Apache-2.0\n",
      "919\n",
      "336\n",
      "(3 issues need help)\n",
      "58\n",
      "Updated\n",
      "May 20, 2025\n",
      "trl\n",
      "Public\n",
      "Train transformer language models with reinforcement learning.\n",
      "huggingface/trl’s past year of commit activity\n",
      "Python\n",
      "13,814\n",
      "Apache-2.0\n",
      "1,892\n",
      "394\n",
      "73\n",
      "Updated\n",
      "May 20, 2025\n",
      "inference-playground\n",
      "Public\n",
      "huggingface/inference-playground’s past year of commit activity\n",
      "Svelte\n",
      "39\n",
      "MIT\n",
      "3\n",
      "1\n",
      "2\n",
      "Updated\n",
      "May 19, 2025\n",
      "View all repositories\n",
      "People\n",
      "View all\n",
      "Top languages\n",
      "Python\n",
      "Jupyter Notebook\n",
      "Rust\n",
      "TypeScript\n",
      "JavaScript\n",
      "Most used topics\n",
      "pytorch\n",
      "machine-learning\n",
      "nlp\n",
      "transformers\n",
      "deep-learning\n",
      "Footer\n",
      "© 2025 GitHub, Inc.\n",
      "Footer navigation\n",
      "Terms\n",
      "Privacy\n",
      "Security\n",
      "Status\n",
      "Docs\n",
      "Contact\n",
      "Manage cookies\n",
      "Do not share my personal information\n",
      "You can’t perform that action at this time.\n",
      "\n",
      "\n",
      "\n",
      "Twitter profile\n",
      "Webpage Title:\n",
      "No title found\n",
      "Webpage Contents:\n",
      "JavaScript is not available.\n",
      "We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n",
      "Help Center\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Imprint\n",
      "Ads info\n",
      "© 2025 X Corp.\n",
      "Something went wrong, but don’t fret — let’s give it another shot.\n",
      "Try again\n",
      "Some privacy related extensions may cause issues on x.com. Please disable them and try again.\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn company page\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including\n",
      "professional and job ads\n",
      ") on and off LinkedIn. Learn more in our\n",
      "Cookie Policy\n",
      ".\n",
      "Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your\n",
      "settings\n",
      ".\n",
      "Accept\n",
      "Reject\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Articles\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 542 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "We’re on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Tech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\n",
      "Jeff Boudier\n",
      "Product + Growth at Hugging Face\n",
      "Terrence Rohan\n",
      "Seed Investor\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Lysandre Debut\n",
      "COSO - Chief Open Source Officer at Hugging Face\n",
      "13h\n",
      "Report this post\n",
      "Since the initial Attention is All you Need, 300 architectures have been contributed to Transformers.\n",
      "\n",
      "See the rise and fall of these architectures over time; crazy to see how BERT remains on top, but Llama is catching up fast! \n",
      "\n",
      "As we strive to standardize model definitions, it's important to see which models continue being used.\n",
      "\n",
      "We see that the ones to win the most usage (BERT, Llama, CLIP) are the ones compatible with the entire ecosystem\n",
      "\n",
      "Read about how we aim to help:\n",
      "https://lnkd.in/eQjmcWxF\n",
      "Very nice visualization made possible by Flourish\n",
      "…more\n",
      "319\n",
      "14 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Ben Burtenshaw\n",
      "Machine Learning @ 🤗 Hugging Face\n",
      "17h\n",
      "Report this post\n",
      "MCP Course starts from fundamentals and works up to real-world application. Unit 1 is all about when and why to use MCP in your applications.\n",
      "\n",
      "🔗 join in here:\n",
      "https://lnkd.in/eTuSr-Uh\n",
      "🚫 without MCP: you build or learn an interface for each tool, prompt, or data integration. As soon as you do this more than once it becomes a burden.\n",
      "\n",
      "✅ with MCP: your application integrates with servers for a relevant context exposed as tools, resources, and prompts. You can reuse MCP servers across applications and from the community.\n",
      "\n",
      "These Unit 1 diagrams show how an MCP based system compares to a basic implementation.\n",
      "206\n",
      "4 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Sayak Paul\n",
      "ML @ Hugging Face 🤗\n",
      "20h\n",
      "Report this post\n",
      "Despite the emergence of combining LLM and DiT architectures for T2I synthesis, its design remains severely understudied.\n",
      "\n",
      "We explore several architectural choices that affect this design. We provide an open & reproducible training recipe that works at scale.\n",
      "\n",
      "Works like Playground v3 have already explored a deep fusion between an LLM and a DiT, sharing their representations through layerwise attention. They exhibit excellent performance on T2I.\n",
      "\n",
      "Despite its compelling results and other performance virtues, it remains unexplored, which is what we want to improve in our work. Specifically, we take a pre-trained LLM (Gemma-2B) and trainable DiT, and set out to explore what makes a \"good deep fusion\" between the two for T2I.\n",
      "\n",
      "We explore several key questions in the work, such as:\n",
      "\n",
      "Q1: How should we do attention? We considered several alternatives. PixArt-Alpha like attention (cross-attention) is very promising. \n",
      "Q2: Should we incorporate additional text modulation?\n",
      "Q3: Can we eliminate timestep conditioning? \n",
      "Q4: How do we do positional encodings?\n",
      "Q5: Do instruction-tuned LLMs help deep fusion?\n",
      "Q6: Would using a decoder LLM from a multimodal model be helpful?\n",
      "Q7: Does using a better variant of Gemma help?\n",
      "\n",
      "Based on the above findings, we arrive at FuseDiT with the following components on top of the base architecture from the findings of our experiments.\n",
      "\n",
      "* No AdaLN-Zero modules\n",
      "* 1D + 2D-RoPE\n",
      "* Gemma 2 2B, adjusting DiT configurations accordingly\n",
      "\n",
      "We trained FuseDiT on a mixture from CC12M, JourneyDB, & SA (~26M image-text pairs) for 800 steps. While not the best model, it's encouraging to develop something in a guided manner using open datasets.\n",
      "\n",
      "To know more (code, models, all are available), please check out the paper:\n",
      "https://lnkd.in/gg6qyqZX\n",
      ". Tagging the co-authors who are on the platform:\n",
      "Saining Xie\n",
      ",\n",
      "Xichen Pan\n",
      ",\n",
      "Bingda Tang\n",
      ", and\n",
      "Boyang Zheng\n",
      ".\n",
      "\n",
      "This was done long ago and got into\n",
      "#CVPR25\n",
      "-- super excited to finally share it now, along with the data and code ♥️\n",
      "107\n",
      "6 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "open-sourceress at 🤗 | Google Developer Expert in Machine Learning, MSc Candidate in Data Science\n",
      "19h\n",
      "Report this post\n",
      "It was the week of video generation at @huggingface, on top of many new LLMs, VLMs and more! \n",
      "Let’s have a wrap 🌯\n",
      "\n",
      "LLMs 💬\n",
      "> Alibaba Qwen released WorldPM-72B, new World Preference Model trained with 15M preference samples (OS)\n",
      "> II-Medical-8B, new LLM for medical reasoning that comes in 8B by Intelligent-Internet\n",
      "> TRAIL is a new dataset by Patronus for trace error reasoning for agents (OS)\n",
      "\n",
      "Multimodal 🖼️💬\n",
      "> Salesforce Research released BLIP3o, a new any-to-any model with image-text input and image-text output 💬it’s based on an image encoder, a text decoder and a DiT, and comes in 8B\n",
      "> They also released pre-training and fine-tuning datasets\n",
      "> MMMG is a multimodal generation benchmark for image, audio, text (interleaved)\n",
      "\n",
      "Image Generation ⏯️\n",
      "> Alibaba Wan-AI released Wan2.1-VACE, video foundation model for image and text to video, video-to-audio and more tasks, comes in 1.3B and 14B (OS)\n",
      "> ZuluVision released MoviiGen1.1, new cinematic video generation model based on Wan 2.1 14B (OS)\n",
      "> multimodalart released isometric-skeumorphic-3d-bnb, an isometric 3D asset generator (like AirBnB assets) based on Flux\n",
      "> LTX-Video-0.9.7-distilled is a new real-time video generation (text and image to video) model by Lightricks\n",
      "> Hidream_t2i_human_preference is a new text-to-image preference dataset by Rapidata with 195k human responses from 38k annotators\n",
      "\n",
      "Audio 🗣️\n",
      "> stabilityai released stable-audio-open-small new text-to-audio model\n",
      "> TEN-framework released ten-vad, voice activity detection model (OS)\n",
      "…more\n",
      "113\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "962,036 followers\n",
      "18h\n",
      "Report this post\n",
      "adding to our nicest hub screenshots collection ✅\n",
      "Julien Chaumond\n",
      "CTO at Hugging Face\n",
      "19h\n",
      "Thanks Jensen for the shout-out! Nice Hub screenshot 😍\n",
      "\n",
      "From\n",
      "NVIDIA\n",
      "keynote at Computex.\n",
      "61\n",
      "2 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "63,971 followers\n",
      "1d\n",
      "Edited\n",
      "Report this post\n",
      "Trending:\n",
      "StepFun\n",
      "'s Step1X-3D for generating high-fidelity 3D assets with versatile textures! Apache-2.0 🔥🔥 \n",
      "\n",
      "Exceptional results in terms of geometry and texture mapping.\n",
      "Available on\n",
      "Hugging Face\n",
      "👉 \n",
      "🤩 Gradio App:\n",
      "https://lnkd.in/gJJeQyv3\n",
      "😎 Model:\n",
      "https://lnkd.in/gXJvT3mC\n",
      "…more\n",
      "346\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "63,971 followers\n",
      "1d\n",
      "Edited\n",
      "Report this post\n",
      "🔥 KEEP - New sota for video face super-resolution\n",
      "\n",
      "This is the official app for KEEP. It stands for Kalman-Inspired Feature Propagation for Video Face Super-Resolution and was submitted at ECCV 2024.\n",
      "\n",
      "Play with the app here on\n",
      "Hugging Face\n",
      ":\n",
      "https://lnkd.in/gNSi7SP5\n",
      "…more\n",
      "654\n",
      "16 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Joseph Spisak\n",
      "Product Director, Generative AI @Meta | Ex: Google, Amazon\n",
      "1w\n",
      "Edited\n",
      "Report this post\n",
      "The Open Language of AI..\n",
      "\n",
      "My journey in AI started over 10 years ago when I met\n",
      "Soumith\n",
      ",\n",
      "Yangqing\n",
      ",\n",
      "Dmytro\n",
      ",\n",
      "Andrew\n",
      "and\n",
      "Pieter\n",
      "- folks that I am proud to this day to call friends and colleagues. It’s hard to believe it’s been that long and honestly hard to believe I’ve spent 7 of those years helping to build PyTorch what it is today - an amazing and inspirational project that is foundational to ChatGPT, Llama, DeepSeek, Stable Diffusion and so many other breakthroughs. \n",
      "\n",
      "In this next phase we have a much bigger and broader vision and as part of that we are bringing in vLLM and DeepSpeed under our umbrella foundation laying the groundwork for PyTorch to continue its growth trajectory with additional high caliber projects on the way. \n",
      "\n",
      "For more on how we see the future check out the vision blog that\n",
      "Luca\n",
      "and coauthored.\n",
      "https://lnkd.in/gZRmv2e9\n",
      "I’m excited to work with this community to realize our expanded vision of being the open language of AI. \n",
      "\n",
      "Thank you to everyone who made this next step possible including a few key folks -\n",
      "Ion Stoica\n",
      ",\n",
      "Aparna Ramani\n",
      ",\n",
      "Soumith Chintala\n",
      ",\n",
      "Matt W.\n",
      ",\n",
      "Simon Mo\n",
      "and\n",
      "Woosuk Kwon\n",
      "and many others.. \n",
      "\n",
      "And thank you to all of the members:\n",
      "AMD\n",
      ",\n",
      "Arm\n",
      ",\n",
      "Amazon Web Services (AWS)\n",
      ",\n",
      "Google\n",
      ",\n",
      "Huawei\n",
      ",\n",
      "Hugging Face\n",
      ",\n",
      "IBM\n",
      ",\n",
      "Intel Corporation\n",
      ",\n",
      "Lightning AI\n",
      ",\n",
      "NVIDIA\n",
      ", and\n",
      "Snowflake\n",
      ".\n",
      "\n",
      "Cheers to what's next!\n",
      "\n",
      "\n",
      "\n",
      "Details:\n",
      "\n",
      "Vision post:\n",
      "https://lnkd.in/gZRmv2e9\n",
      "Press Release -\n",
      "https://lnkd.in/gBzYkyaJ\n",
      "vLLM Announcement -\n",
      "https://lnkd.in/gCEwbq3p\n",
      "DeepSpeed Announcement -\n",
      "https://lnkd.in/gXAWTNnt\n",
      "529\n",
      "10 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Clem Delangue 🤗\n",
      "Clem Delangue 🤗 is an Influencer\n",
      "Co-founder & CEO at Hugging Face\n",
      "3d\n",
      "Report this post\n",
      "3,000+ students for the\n",
      "Hugging Face\n",
      "MCP class already!\n",
      "325\n",
      "20 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "open-sourceress at 🤗 | Google Developer Expert in Machine Learning, MSc Candidate in Data Science\n",
      "3d\n",
      "Report this post\n",
      "New sota open-source depth estimation: Marigold IID 🌼\n",
      "\n",
      "> normal maps, depth maps of scenes & faces\n",
      "> get albedo (true color) and BRDF (texture) maps of scenes, they even release a depth-to-3D printer format demo 😮\n",
      "links to all models and demos in comments 🤗\n",
      "…more\n",
      "298\n",
      "7 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Generative AI\n",
      "Technology, Information and Internet\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Palo Alto, California\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "LlamaIndex\n",
      "Technology, Information and Internet\n",
      "San Francisco, California\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      "© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "العربية (Arabic)\n",
      "বাংলা (Bangla)\n",
      "Čeština (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "Ελληνικά (Greek)\n",
      "English (English)\n",
      "Español (Spanish)\n",
      "فارسی (Persian)\n",
      "Suomi (Finnish)\n",
      "Français (French)\n",
      "हिंदी (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "עברית (Hebrew)\n",
      "日本語 (Japanese)\n",
      "한국어 (Korean)\n",
      "मराठी (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "ਪੰਜਾਬੀ (Punjabi)\n",
      "Polski (Polish)\n",
      "Português (Portuguese)\n",
      "Română (Romanian)\n",
      "Русский (Russian)\n",
      "Svenska (Swedish)\n",
      "తెలుగు (Telugu)\n",
      "ภาษาไทย (Thai)\n",
      "Tagalog (Tagalog)\n",
      "Türkçe (Turkish)\n",
      "Українська (Ukrainian)\n",
      "Tiếng Việt (Vietnamese)\n",
      "简体中文 (Chinese (Simplified))\n",
      "正體中文 (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Don’t have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n",
      "\n",
      "discuss Hugging Face\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "Rejected Endpoint\n",
      "Inference Endpoints on the Hub\n",
      "1\n",
      "6\n",
      "May 20, 2025\n",
      "Why are spaces showing Error: Task aborted?\n",
      "Spaces\n",
      "0\n",
      "11\n",
      "May 20, 2025\n",
      "Is payment required to run the below code?\n",
      "Beginners\n",
      "5\n",
      "20\n",
      "May 20, 2025\n",
      "TokenClassificationPipeline produce entities with \"##\" characters\n",
      "🤗Transformers\n",
      "6\n",
      "14\n",
      "May 19, 2025\n",
      "After llama fine tuning, model merging fails\n",
      "Beginners\n",
      "1\n",
      "9\n",
      "May 20, 2025\n",
      "Slow Loading of Diffusers\n",
      "🧨 Diffusers\n",
      "1\n",
      "15\n",
      "May 19, 2025\n",
      "How do I load a trained checkpoint model?\n",
      "🤗Transformers\n",
      "1\n",
      "7\n",
      "May 20, 2025\n",
      "Issue \"got multiple values for keyword argument\" for Wav2Vec2 tokenizer\n",
      "Beginners\n",
      "1\n",
      "5\n",
      "May 20, 2025\n",
      "Serverless Inference API credits\n",
      "Beginners\n",
      "2\n",
      "23\n",
      "May 19, 2025\n",
      "Fine-Tuning LLMs on Large Proprietary Codebases\n",
      "Models\n",
      "5\n",
      "24\n",
      "May 19, 2025\n",
      "GRPO or PPO or some RL\n",
      "Research\n",
      "1\n",
      "7\n",
      "May 19, 2025\n",
      "Beyond Prompting: A Narrative-Centric Framework for Simulated Consciousness in LLMs\n",
      "Research\n",
      "0\n",
      "11\n",
      "May 19, 2025\n",
      "Highest Model of Intel CPU is Intel Core Ultra 7 265KF?\n",
      "Site Feedback\n",
      "1\n",
      "9\n",
      "May 19, 2025\n",
      "Pip install on Google Collab\n",
      "Beginners\n",
      "2\n",
      "18\n",
      "May 19, 2025\n",
      "Xet Storage Not Deduplicating for Even Simple Binary Files\n",
      "🤗Datasets\n",
      "8\n",
      "16\n",
      "May 19, 2025\n",
      "429 for Kokoro-82M model\n",
      "Intermediate\n",
      "1\n",
      "17\n",
      "May 19, 2025\n",
      "Fine tuning on qwen3\n",
      "🤗Transformers\n",
      "2\n",
      "40\n",
      "May 19, 2025\n",
      "InferenceClient running very slow\n",
      "Beginners\n",
      "1\n",
      "16\n",
      "May 19, 2025\n",
      "Help this newbie\n",
      "Beginners\n",
      "6\n",
      "90\n",
      "May 15, 2025\n",
      "Best model to extract text from old Church records written in cursive?\n",
      "Models\n",
      "2\n",
      "25\n",
      "May 18, 2025\n",
      "Has inference API stopped returning text embeddings?\n",
      "Inference Endpoints on the Hub\n",
      "1\n",
      "29\n",
      "May 17, 2025\n",
      "Huggingface trl GRPO loss is always zero\n",
      "Beginners\n",
      "5\n",
      "30\n",
      "May 18, 2025\n",
      "Higher importance to new tokens\n",
      "Beginners\n",
      "1\n",
      "26\n",
      "May 16, 2025\n",
      "Which model select?\n",
      "Beginners\n",
      "1\n",
      "35\n",
      "May 18, 2025\n",
      "Persistent 404 Not Found Errors with Public Inference API\n",
      "Inference Endpoints on the Hub\n",
      "8\n",
      "249\n",
      "May 15, 2025\n",
      "PPO Training does not improve SFT model outputs (Metrics identical before and after PPO)\n",
      "🤗Transformers\n",
      "1\n",
      "18\n",
      "May 19, 2025\n",
      "“Use this model”->Ollama: can't pull model with Q4\n",
      "🤗Hub\n",
      "4\n",
      "48\n",
      "May 15, 2025\n",
      "AI Memory : The Simplest System That Beats Every Complex Solution\n",
      "Research\n",
      "6\n",
      "67\n",
      "May 18, 2025\n",
      "Dedicated endpoint getting 429 errors\n",
      "Intermediate\n",
      "2\n",
      "23\n",
      "May 18, 2025\n",
      "Getting Not Found for model google/flan-t5-small (and others)\n",
      "Beginners\n",
      "8\n",
      "99\n",
      "May 16, 2025\n",
      "next page →\n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "status updates\n",
      "Webpage Title:\n",
      "\n",
      "Hugging Face status\n",
      "\n",
      "Webpage Contents:\n",
      "Status\n",
      "Maintenance\n",
      "Previous incidents\n",
      "Get updates\n",
      "Get status updates\n",
      "Get e-mail notifications whenever Hugging Face creates, updates or resolves an incident.\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "HF Inference\n",
      "HF Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "All services are online\n",
      "Last updated on May 20 at 03:33am EDT\n",
      "Current status by service\n",
      "Operational\n",
      "Huggingface Hub\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Git Hosting and Serving\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "HF Inference\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "HF Endpoints\n",
      "Operational\n",
      "Inference Endpoints UI\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints API\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Spaces\n",
      "Operational\n",
      "Spaces Proxy\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Powered by\n",
      "Better Stack\n",
      "\n",
      "\n",
      "\n",
      "NVIDIA Parakeet TDT model\n",
      "Webpage Title:\n",
      "nvidia/parakeet-tdt-0.6b-v2 · Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "nvidia\n",
      "/\n",
      "parakeet-tdt-0.6b-v2\n",
      "like\n",
      "983\n",
      "Follow\n",
      "NVIDIA\n",
      "26.3k\n",
      "Automatic Speech Recognition\n",
      "NeMo\n",
      "PyTorch\n",
      "8 datasets\n",
      "English\n",
      "speech\n",
      "audio\n",
      "Transducer\n",
      "TDT\n",
      "FastConformer\n",
      "Conformer\n",
      "NeMo\n",
      "hf-asr-leaderboard\n",
      "Eval Results\n",
      "arxiv:\n",
      "4 papers\n",
      "License:\n",
      "cc-by-4.0\n",
      "Model card\n",
      "Files\n",
      "Files and versions\n",
      "xet\n",
      "Community\n",
      "34\n",
      "Use this model\n",
      "Parakeet TDT 0.6B V2 (En)\n",
      "Description:\n",
      "License/Terms of Use:\n",
      "Deployment Geography:\n",
      "Use Case:\n",
      "Release Date:\n",
      "Model Architecture:\n",
      "Input:\n",
      "Output:\n",
      "How to Use this Model:\n",
      "Software Integration:\n",
      "Training and Evaluation Datasets:\n",
      "Training\n",
      "Training Dataset\n",
      "Performance\n",
      "Base Performance\n",
      "Noise Robustness\n",
      "Telephony Audio Performance\n",
      "References\n",
      "Inference:\n",
      "Ethical Considerations:\n",
      "Bias:\n",
      "Explainability:\n",
      "Privacy:\n",
      "Safety:\n",
      "Parakeet TDT 0.6B V2 (En)\n",
      "|\n",
      "|\n",
      "Description:\n",
      "parakeet-tdt-0.6b-v2\n",
      "is a 600-million-parameter automatic speech recognition (ASR) model designed for high-quality English transcription, featuring support for punctuation, capitalization, and accurate timestamp prediction. Try Demo here:\n",
      "https://huggingface.co/spaces/nvidia/parakeet-tdt-0.6b-v2\n",
      "This XL variant of the FastConformer [1] architecture integrates the TDT [2] decoder and is trained with full attention, enabling efficient transcription of audio segments up to 24 minutes in a single pass. The model achieves an RTFx of 3380 on the HF-Open-ASR leaderboard with a batch size of 128. Note:\n",
      "RTFx Performance may vary depending on dataset audio duration and batch size.\n",
      "Key Features\n",
      "Accurate word-level timestamp predictions\n",
      "Automatic punctuation and capitalization\n",
      "Robust performance on spoken numbers, and song lyrics transcription\n",
      "For more information, refer to the\n",
      "Model Architecture\n",
      "section and the\n",
      "NeMo documentation\n",
      ".\n",
      "This model is ready for commercial/non-commercial use.\n",
      "License/Terms of Use:\n",
      "GOVERNING TERMS: Use of this model is governed by the\n",
      "CC-BY-4.0\n",
      "license.\n",
      "Deployment Geography:\n",
      "Global\n",
      "Use Case:\n",
      "This model serves developers, researchers, academics, and industries building applications that require speech-to-text capabilities, including but not limited to: conversational AI, voice assistants, transcription services, subtitle generation, and voice analytics platforms.\n",
      "Release Date:\n",
      "05/01/2025\n",
      "Model Architecture:\n",
      "Architecture Type\n",
      ":\n",
      "FastConformer-TDT\n",
      "Network Architecture\n",
      ":\n",
      "This model was developed based on\n",
      "FastConformer encoder\n",
      "architecture[1] and TDT decoder[2]\n",
      "This model has 600 million model parameters.\n",
      "Input:\n",
      "Input Type(s):\n",
      "16kHz Audio\n",
      "Input Format(s):\n",
      ".wav\n",
      "and\n",
      ".flac\n",
      "audio formats\n",
      "Input Parameters:\n",
      "1D (audio signal)\n",
      "Other Properties Related to Input:\n",
      "Monochannel audio\n",
      "Output:\n",
      "Output Type(s):\n",
      "Text\n",
      "Output Format:\n",
      "String\n",
      "Output Parameters:\n",
      "1D (text)\n",
      "Other Properties Related to Output:\n",
      "Punctuations and Capitalizations included.\n",
      "Our AI models are designed and/or optimized to run on NVIDIA GPU-accelerated systems. By leveraging NVIDIA's hardware (e.g. GPU cores) and software frameworks (e.g., CUDA libraries), the model achieves faster training and inference times compared to CPU-only solutions.\n",
      "How to Use this Model:\n",
      "To train, fine-tune or play with the model you will need to install\n",
      "NVIDIA NeMo\n",
      ". We recommend you install it after you've installed latest PyTorch version.\n",
      "pip install -U nemo_toolkit[\n",
      "\"asr\"\n",
      "]\n",
      "The model is available for use in the NeMo toolkit [3], and can be used as a pre-trained checkpoint for inference or for fine-tuning on another dataset.\n",
      "Automatically instantiate the model\n",
      "import\n",
      "nemo.collections.asr\n",
      "as\n",
      "nemo_asr\n",
      "asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\n",
      "\"nvidia/parakeet-tdt-0.6b-v2\"\n",
      ")\n",
      "Transcribing using Python\n",
      "First, let's get a sample\n",
      "wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\n",
      "Then simply do:\n",
      "output = asr_model.transcribe([\n",
      "'2086-149220-0033.wav'\n",
      "])\n",
      "print\n",
      "(output[\n",
      "0\n",
      "].text)\n",
      "Transcribing with timestamps\n",
      "To transcribe with timestamps:\n",
      "output = asr_model.transcribe([\n",
      "'2086-149220-0033.wav'\n",
      "], timestamps=\n",
      "True\n",
      ")\n",
      "# by default, timestamps are enabled for char, word and segment level\n",
      "word_timestamps = output[\n",
      "0\n",
      "].timestamp[\n",
      "'word'\n",
      "]\n",
      "# word level timestamps for first sample\n",
      "segment_timestamps = output[\n",
      "0\n",
      "].timestamp[\n",
      "'segment'\n",
      "]\n",
      "# segment level timestamps\n",
      "char_timestamps = output[\n",
      "0\n",
      "].timestamp[\n",
      "'char'\n",
      "]\n",
      "# char level timestamps\n",
      "for\n",
      "stamp\n",
      "in\n",
      "segment_timestamps:\n",
      "print\n",
      "(\n",
      "f\"\n",
      "{stamp[\n",
      "'start'\n",
      "]}\n",
      "s -\n",
      "{stamp[\n",
      "'end'\n",
      "]}\n",
      "s :\n",
      "{stamp[\n",
      "'segment'\n",
      "]}\n",
      "\"\n",
      ")\n",
      "Software Integration:\n",
      "Runtime Engine(s):\n",
      "NeMo 2.2\n",
      "Supported Hardware Microarchitecture Compatibility:\n",
      "NVIDIA Ampere\n",
      "NVIDIA Blackwell\n",
      "NVIDIA Hopper\n",
      "NVIDIA Volta\n",
      "[Preferred/Supported] Operating System(s):\n",
      "Linux\n",
      "Hardware Specific Requirements:\n",
      "Atleast 2GB RAM for model to load. The bigger the RAM, the larger audio input it supports.\n",
      "Model Version\n",
      "Current version: parakeet-tdt-0.6b-v2. Previous versions can be\n",
      "accessed\n",
      "here.\n",
      "Training and Evaluation Datasets:\n",
      "Training\n",
      "This model was trained using the NeMo toolkit [3], following the strategies below:\n",
      "Initialized from a FastConformer SSL checkpoint that was pretrained with a wav2vec method on the LibriLight dataset[7].\n",
      "Trained for 150,000 steps on 64 A100 GPUs.\n",
      "Dataset corpora were balanced using a temperature sampling value of 0.5.\n",
      "Stage 2 fine-tuning was performed for 2,500 steps on 4 A100 GPUs using approximately 500 hours of high-quality, human-transcribed data of NeMo ASR Set 3.0.\n",
      "Training was conducted using this\n",
      "example script\n",
      "and\n",
      "TDT configuration\n",
      ".\n",
      "The tokenizer was constructed from the training set transcripts using this\n",
      "script\n",
      ".\n",
      "Training Dataset\n",
      "The model was trained on the Granary dataset, consisting of approximately 120,000 hours of English speech data:\n",
      "10,000 hours from human-transcribed NeMo ASR Set 3.0, including:\n",
      "LibriSpeech (960 hours)\n",
      "Fisher Corpus\n",
      "National Speech Corpus Part 1\n",
      "VCTK\n",
      "VoxPopuli (English)\n",
      "Europarl-ASR (English)\n",
      "Multilingual LibriSpeech (MLS English) – 2,000-hour subset\n",
      "Mozilla Common Voice (v7.0)\n",
      "AMI\n",
      "110,000 hours of pseudo-labeled data from:\n",
      "YTC (YouTube-Commons) dataset[4]\n",
      "YODAS dataset [5]\n",
      "Librilight [7]\n",
      "All transcriptions preserve punctuation and capitalization. The Granary dataset will be made publicly available after presentation at Interspeech 2025.\n",
      "Data Collection Method by dataset\n",
      "Hybrid: Automated, Human\n",
      "Labeling Method by dataset\n",
      "Hybrid: Synthetic, Human\n",
      "Properties:\n",
      "Noise robust data from various sources\n",
      "Single channel, 16kHz sampled data\n",
      "Evaluation Dataset\n",
      "Huggingface Open ASR Leaderboard datasets are used to evaluate the performance of this model.\n",
      "Data Collection Method by dataset\n",
      "Human\n",
      "Labeling Method by dataset\n",
      "Human\n",
      "Properties:\n",
      "All are commonly used for benchmarking English ASR systems.\n",
      "Audio data is typically processed into a 16kHz mono channel format for ASR evaluation, consistent with benchmarks like the\n",
      "Open ASR Leaderboard\n",
      ".\n",
      "Performance\n",
      "Huggingface Open-ASR-Leaderboard Performance\n",
      "The performance of Automatic Speech Recognition (ASR) models is measured using Word Error Rate (WER). Given that this model is trained on a large and diverse dataset spanning multiple domains, it is generally more robust and accurate across various types of audio.\n",
      "Base Performance\n",
      "The table below summarizes the WER (%) using a Transducer decoder with greedy decoding (without an external language model):\n",
      "Model\n",
      "Avg WER\n",
      "AMI\n",
      "Earnings-22\n",
      "GigaSpeech\n",
      "LS test-clean\n",
      "LS test-other\n",
      "SPGI Speech\n",
      "TEDLIUM-v3\n",
      "VoxPopuli\n",
      "parakeet-tdt-0.6b-v2\n",
      "6.05\n",
      "11.16\n",
      "11.15\n",
      "9.74\n",
      "1.69\n",
      "3.19\n",
      "2.17\n",
      "3.38\n",
      "5.95\n",
      "Noise Robustness\n",
      "Performance across different Signal-to-Noise Ratios (SNR) using MUSAN music and noise samples:\n",
      "SNR Level\n",
      "Avg WER\n",
      "AMI\n",
      "Earnings\n",
      "GigaSpeech\n",
      "LS test-clean\n",
      "LS test-other\n",
      "SPGI\n",
      "Tedlium\n",
      "VoxPopuli\n",
      "Relative Change\n",
      "Clean\n",
      "6.05\n",
      "11.16\n",
      "11.15\n",
      "9.74\n",
      "1.69\n",
      "3.19\n",
      "2.17\n",
      "3.38\n",
      "5.95\n",
      "-\n",
      "SNR 50\n",
      "6.04\n",
      "11.11\n",
      "11.12\n",
      "9.74\n",
      "1.70\n",
      "3.18\n",
      "2.18\n",
      "3.34\n",
      "5.98\n",
      "+0.25%\n",
      "SNR 25\n",
      "6.50\n",
      "12.76\n",
      "11.50\n",
      "9.98\n",
      "1.78\n",
      "3.63\n",
      "2.54\n",
      "3.46\n",
      "6.34\n",
      "-7.04%\n",
      "SNR 5\n",
      "8.39\n",
      "19.33\n",
      "13.83\n",
      "11.28\n",
      "2.36\n",
      "5.50\n",
      "3.91\n",
      "3.91\n",
      "6.96\n",
      "-38.11%\n",
      "Telephony Audio Performance\n",
      "Performance comparison between standard 16kHz audio and telephony-style audio (using μ-law encoding with 16kHz→8kHz→16kHz conversion):\n",
      "Audio Format\n",
      "Avg WER\n",
      "AMI\n",
      "Earnings\n",
      "GigaSpeech\n",
      "LS test-clean\n",
      "LS test-other\n",
      "SPGI\n",
      "Tedlium\n",
      "VoxPopuli\n",
      "Relative Change\n",
      "Standard 16kHz\n",
      "6.05\n",
      "11.16\n",
      "11.15\n",
      "9.74\n",
      "1.69\n",
      "3.19\n",
      "2.17\n",
      "3.38\n",
      "5.95\n",
      "-\n",
      "μ-law 8kHz\n",
      "6.32\n",
      "11.98\n",
      "11.16\n",
      "10.02\n",
      "1.78\n",
      "3.52\n",
      "2.20\n",
      "3.38\n",
      "6.52\n",
      "-4.10%\n",
      "These WER scores were obtained using greedy decoding without an external language model. Additional evaluation details are available on the\n",
      "Hugging Face ASR Leaderboard\n",
      ".[6]\n",
      "References\n",
      "[1]\n",
      "Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition\n",
      "[2]\n",
      "Efficient Sequence Transduction by Jointly Predicting Tokens and Durations\n",
      "[3]\n",
      "NVIDIA NeMo Toolkit\n",
      "[4]\n",
      "Youtube-commons: A massive open corpus for conversational and multimodal data\n",
      "[5]\n",
      "Yodas: Youtube-oriented dataset for audio and speech\n",
      "[6]\n",
      "HuggingFace ASR Leaderboard\n",
      "[7]\n",
      "MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages\n",
      "Inference:\n",
      "Engine\n",
      ":\n",
      "NVIDIA NeMo\n",
      "Test Hardware\n",
      ":\n",
      "NVIDIA A10\n",
      "NVIDIA A100\n",
      "NVIDIA A30\n",
      "NVIDIA H100\n",
      "NVIDIA L4\n",
      "NVIDIA L40\n",
      "NVIDIA Turing T4\n",
      "NVIDIA Volta V100\n",
      "Ethical Considerations:\n",
      "NVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications. When downloaded or used in accordance with our terms of service, developers should work with their supporting model team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse.\n",
      "For more detailed information on ethical considerations for this model, please see the Model Card++ Explainability, Bias, Safety & Security, and Privacy Subcards\n",
      "here\n",
      ".\n",
      "Please report security vulnerabilities or NVIDIA AI Concerns\n",
      "here\n",
      ".\n",
      "Bias:\n",
      "Field\n",
      "Response\n",
      "Participation considerations from adversely impacted groups\n",
      "protected classes\n",
      "in model design and testing\n",
      "None\n",
      "Measures taken to mitigate against unwanted bias\n",
      "None\n",
      "Explainability:\n",
      "Field\n",
      "Response\n",
      "Intended Domain\n",
      "Speech to Text Transcription\n",
      "Model Type\n",
      "FastConformer\n",
      "Intended Users\n",
      "This model is intended for developers, researchers, academics, and industries building conversational based applications.\n",
      "Output\n",
      "Text\n",
      "Describe how the model works\n",
      "Speech input is encoded into embeddings and passed into conformer-based model and output a text response.\n",
      "Name the adversely impacted groups this has been tested to deliver comparable outcomes regardless of\n",
      "Not Applicable\n",
      "Technical Limitations & Mitigation\n",
      "Transcripts may be not 100% accurate. Accuracy varies based on language and characteristics of input audio (Domain, Use Case, Accent, Noise, Speech Type, Context of speech, etc.)\n",
      "Verified to have met prescribed NVIDIA quality standards\n",
      "Yes\n",
      "Performance Metrics\n",
      "Word Error Rate\n",
      "Potential Known Risks\n",
      "If a word is not trained in the language model and not presented in vocabulary, the word is not likely to be recognized. Not recommended for word-for-word/incomplete sentences as accuracy varies based on the context of input text\n",
      "Licensing\n",
      "GOVERNING TERMS: Use of this model is governed by the\n",
      "CC-BY-4.0\n",
      "license.\n",
      "Privacy:\n",
      "Field\n",
      "Response\n",
      "Generatable or reverse engineerable personal data?\n",
      "None\n",
      "Personal data used to create this model?\n",
      "None\n",
      "Is there provenance for all datasets used in training?\n",
      "Yes\n",
      "Does data labeling (annotation, metadata) comply with privacy laws?\n",
      "Yes\n",
      "Is data compliant with data subject requests for data correction or removal, if such a request was made?\n",
      "No, not possible with externally-sourced data.\n",
      "Applicable Privacy Policy\n",
      "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/\n",
      "Safety:\n",
      "Field\n",
      "Response\n",
      "Model Application(s)\n",
      "Speech to Text Transcription\n",
      "Describe the life critical impact\n",
      "None\n",
      "Use Case Restrictions\n",
      "Abide by\n",
      "CC-BY-4.0\n",
      "License\n",
      "Model and dataset restrictions\n",
      "The Principle of least privilege (PoLP) is applied limiting access for dataset generation and model development. Restrictions enforce dataset access during training, and dataset license constraints adhered to.\n",
      "Downloads last month\n",
      "56,581\n",
      "Inference Providers\n",
      "NEW\n",
      "Automatic Speech Recognition\n",
      "This model isn't deployed by any Inference Provider.\n",
      "🙋\n",
      "33\n",
      "Ask for provider support\n",
      "Model tree for\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Adapters\n",
      "2 models\n",
      "Finetunes\n",
      "3 models\n",
      "Quantizations\n",
      "1 model\n",
      "Datasets used to train\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "openslr/librispeech_asr\n",
      "Updated\n",
      "Aug 14, 2024\n",
      "•\n",
      "18.7k\n",
      "•\n",
      "151\n",
      "CSTR-Edinburgh/vctk\n",
      "Updated\n",
      "Aug 14, 2024\n",
      "•\n",
      "582\n",
      "•\n",
      "41\n",
      "mozilla-foundation/common_voice_8_0\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 29, 2023\n",
      "•\n",
      "2.34M\n",
      "•\n",
      "202\n",
      "•\n",
      "35\n",
      "Spaces using\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "15\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "👀\n",
      "dhuynh95/screenshot_to_html\n",
      "🐢\n",
      "istupakov/onnx-asr\n",
      "🦜\n",
      "msekoyan/parakeet-tdt-0.6b-v2\n",
      "🚀\n",
      "DroolingPanda/teachingAssistant\n",
      "🦜\n",
      "fdaudens/parakeet-tdt-0.6b-v2\n",
      "🎙️\n",
      "GavinHuang/asr-demo\n",
      "🦜\n",
      "ridgerun-ai/parakeet-tdt-0.6b-v2\n",
      "🦜\n",
      "fnaval/parakeet-tdt-0.6b-v2\n",
      "🦜\n",
      "sungo-ganpare/parakeet-tdt-0.6b-v2\n",
      "📊\n",
      "NeuralFalcon/parakeet-tdt-0.6b-v2-subtitle\n",
      "🦜\n",
      "SlouchyBuffalo/parakeet-tdt-0.6b-v2\n",
      "+ 10 Spaces\n",
      "+ 3 Spaces\n",
      "Collection including\n",
      "nvidia/parakeet-tdt-0.6b-v2\n",
      "Parakeet\n",
      "Collection\n",
      "NeMo Parakeet ASR Models attain strong speech recognition accuracy while being efficient for inference. Available in CTC and RNN-Transducer variants.\n",
      "•\n",
      "11 items\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "25\n",
      "Evaluation results\n",
      "Test WER\n",
      "on AMI (Meetings test)\n",
      "test set\n",
      "self-reported\n",
      "11.160\n",
      "Test WER\n",
      "on Earnings-22\n",
      "test set\n",
      "self-reported\n",
      "11.150\n",
      "Test WER\n",
      "on GigaSpeech\n",
      "test set\n",
      "self-reported\n",
      "9.740\n",
      "Test WER\n",
      "on LibriSpeech (clean)\n",
      "test set\n",
      "self-reported\n",
      "1.690\n",
      "Test WER\n",
      "on LibriSpeech (other)\n",
      "test set\n",
      "self-reported\n",
      "3.190\n",
      "Test WER\n",
      "on SPGI Speech\n",
      "test set\n",
      "self-reported\n",
      "2.170\n",
      "Test WER\n",
      "on tedlium-v3\n",
      "test set\n",
      "self-reported\n",
      "3.380\n",
      "Test WER\n",
      "on Vox Populi\n",
      "test set\n",
      "self-reported\n",
      "5.950\n",
      "View on Papers With Code\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "NVIDIA OpenCode Reasoning\n",
      "Webpage Title:\n",
      "nvidia/OpenCodeReasoning · Datasets at Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Datasets:\n",
      "nvidia\n",
      "/\n",
      "OpenCodeReasoning\n",
      "like\n",
      "425\n",
      "Follow\n",
      "NVIDIA\n",
      "26.3k\n",
      "Tasks:\n",
      "Text Generation\n",
      "Modalities:\n",
      "Text\n",
      "Formats:\n",
      "parquet\n",
      "Size:\n",
      "100K - 1M\n",
      "ArXiv:\n",
      "arxiv:\n",
      "2504.01943\n",
      "Tags:\n",
      "Synthetic\n",
      "Libraries:\n",
      "Datasets\n",
      "Dask\n",
      "Croissant\n",
      "+ 1\n",
      "License:\n",
      "cc-by-4.0\n",
      "Dataset card\n",
      "Data Studio\n",
      "Files\n",
      "Files and versions\n",
      "Community\n",
      "15\n",
      "Dataset Viewer (First 5GB)\n",
      "Auto-converted\n",
      "to Parquet\n",
      "API\n",
      "Embed\n",
      "Data Studio\n",
      "Subset (2)\n",
      "split_0\n",
      "·\n",
      "~585k rows (showing the first 170k)\n",
      "split_0 (~585k rows, showing the first 170k)\n",
      "split_1 (167k rows)\n",
      "Split (1)\n",
      "split_0\n",
      "·\n",
      "~585k rows (showing the first 170k)\n",
      "split_0 (~585k rows, showing the first 170k)\n",
      "SQL\n",
      "Console\n",
      "id\n",
      "string\n",
      "lengths\n",
      "32\n",
      "32\n",
      "input\n",
      "string\n",
      "lengths\n",
      "28\n",
      "13k\n",
      "output\n",
      "string\n",
      "lengths\n",
      "800\n",
      "90k\n",
      "source\n",
      "string\n",
      "classes\n",
      "5\n",
      "\t\t\t\tvalues\n",
      "license\n",
      "string\n",
      "classes\n",
      "1\n",
      "\t\t\t\tvalue\n",
      "dataset\n",
      "string\n",
      "classes\n",
      "1\n",
      "\t\t\t\tvalue\n",
      "split\n",
      "string\n",
      "classes\n",
      "1\n",
      "\t\t\t\tvalue\n",
      "difficulty\n",
      "string\n",
      "classes\n",
      "30\n",
      "\t\t\t\tvalues\n",
      "solution\n",
      "string\n",
      "lengths\n",
      "0\n",
      "17.9k\n",
      "c0d4209f929db2b5bf3526a47a2520b0\n",
      "Problem description.\n",
      "Vipul is a hardworking super-hero who maintains the bracket ratio of all the strings in the world. Recently he indulged himself in saving the string population so much that he lost his ability for checking brackets (luckily, not permanently ).Being his super-hero friend help him in his time of hardship.\n",
      "Input\n",
      "\n",
      "The first line of the input contains an integer T denoting the number of test cases. The description of T test cases follows.\n",
      "The first line of each test case contains a single string S denoting the string to be checked.\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "For each test case, output a single line printing \"YES\" or \"NO\" (without \" \" and in uppercase only) , denoting if the brackets in the given string is balanced or not .\n",
      "\n",
      "\n",
      "Constraints\n",
      "\n",
      "1 ≤ T ≤ 10\n",
      "1 ≤ length of S ≤ 60\n",
      "\n",
      "\n",
      "Example\n",
      "Input:\n",
      "3\n",
      "((()))\n",
      "(())()\n",
      "()(()\n",
      "\n",
      "Output:\n",
      "YES\n",
      "YES\n",
      "NO\n",
      "\n",
      " \n",
      "\n",
      "Explanation\n",
      "Example is self-explanatory.\n",
      "<think>\n",
      "Okay, I need to solve this problem where I have to check if the brackets in a string are balanced. Hmm, so the input is a string consisting of parentheses, and I have to determine if they're properly balanced. The example given has three test cases. Let's see.\n",
      "\n",
      "So, the problem is similar to the classic valid parentheses problem. Right. The standard approach for that is using a stack. Let me think. For every opening bracket '(', we push it onto the stack. When we encounter a closing bracket ')', we check if the stack is not empty and the top is an opening bracket. If so, we pop it. If at any point the closing bracket doesn't have a matching opening, it's invalid. At the end, the stack should be empty for it to be balanced.\n",
      "\n",
      "Wait, but what about other characters? Oh, the problem says the string S is the one to be checked, but the examples only have parentheses. So maybe the input string only contains '(' and ')'. But the problem statement doesn't specify. Hmm, but the problem says \"bracket ratio\" so maybe all characters in S are brackets. So I can assume that S consists of only parentheses? Or do I need to ignore other characters? The problem statement says \"checking brackets\", so perhaps any non-bracket characters can be ignored. Wait, but the input examples don't have any, and the problem says \"the brackets in the given string is balanced\". So perhaps the entire string is made of parentheses. So in this case, the code can process each character as a bracket.\n",
      "\n",
      "So steps:\n",
      "\n",
      "For each test case (each string S):\n",
      "\n",
      "1. Initialize a stack (maybe a list in Python).\n",
      "2. Iterate through each character in S:\n",
      "   a. If it's '(', push to stack.\n",
      "   b. If it's ')', check if stack is empty. If empty, return NO. Otherwise, pop the top element.\n",
      "   c. Any other characters? Probably, but maybe the problem says S only has brackets. But the problem statement isn't clear. Wait, the input examples have only parentheses, but the problem says \"string S\". So perhaps the code should process all characters, but only consider '(' and ')'. So other characters are ignored? Or are they considered invalid?\n",
      "\n",
      "Wait, the problem says \"bracket ratio\", which implies that the string may have other characters, but we are only checking the brackets. So, for example, if the string is \"a(b)c)\", the brackets are \"(()\", which would be unbalanced. So the code should process only the brackets and ignore other characters.\n",
      "\n",
      "Wait, but the problem statement says \"the brackets in the given string is balanced\". So the code should check if the parentheses in the string are balanced. So other characters don't affect the balance.\n",
      "\n",
      "So, in the code, we can loop through each character in S. For each character, if it's '(', push to stack. If it's ')', check the stack. Other characters are ignored.\n",
      "\n",
      "Wait, but in the problem's example, the input strings are all parentheses, but the code needs to handle other characters. So perhaps in the code, we process all characters, but only '(' and ')'.\n",
      "\n",
      "So the algorithm:\n",
      "\n",
      "Initialize stack.\n",
      "\n",
      "For each char in S:\n",
      "\n",
      "   if char is '(': push to stack.\n",
      "\n",
      "   elif char is ')':\n",
      "\n",
      "       if stack is not empty and top is '(': pop.\n",
      "\n",
      "       else: invalid, return NO.\n",
      "\n",
      "   else:\n",
      "\n",
      "       ignore (or perhaps the problem considers other characters as invalid? No, the problem says to check the brackets. So other characters are irrelevant.)\n",
      "\n",
      "Wait, but in the problem's example, the third input is \"()(()\", which outputs NO. Let's see:\n",
      "\n",
      "\"()((\" would have:\n",
      "\n",
      "After first two, stack is empty. Then two opens. So stack has two, which is not empty. So output NO.\n",
      "\n",
      "So the code would process each character, and if at any point a closing bracket is found without a corresponding open, return NO. At the end, check if stack is empty.\n",
      "\n",
      "So in code:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "stack = []\n",
      "\n",
      "for c in S:\n",
      "\n",
      "    if c == '(':\n",
      "\n",
      "        stack.append(c)\n",
      "\n",
      "    elif c == ')':\n",
      "\n",
      "        if len(stack) == 0:\n",
      "\n",
      "            # invalid, since no opening to match.\n",
      "\n",
      "            # So can immediately return NO for this test case.\n",
      "\n",
      "            # So perhaps, after this, break and return NO.\n",
      "\n",
      "            # But how to handle in code? Well, perhaps after any invalid step, set a flag.\n",
      "\n",
      "        else:\n",
      "\n",
      "            stack.pop()\n",
      "\n",
      "    else:\n",
      "\n",
      "        # ignore?\n",
      "\n",
      "        pass\n",
      "\n",
      "After processing all characters, check if stack is empty. If yes, then YES, else NO.\n",
      "\n",
      "Wait, but if there are other characters, but the brackets are balanced, then it's YES.\n",
      "\n",
      "But the problem's example inputs don't have other characters. But the code should handle cases where there are other characters.\n",
      "\n",
      "So the code would process each character, but only consider '(' and ')'.\n",
      "\n",
      "Wait, but the problem's input is a single string S. So for example, if S is \"a()\", then the code would process the 'a' as a non-bracket, ignore it. The brackets are '()', so balanced. Output YES.\n",
      "\n",
      "But the problem's sample input may not have such cases, but the code must handle according to the problem's requirements.\n",
      "\n",
      "So the code should process each character in S, but only care about the parentheses.\n",
      "\n",
      "So the code would:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "stack = []\n",
      "\n",
      "balanced = True\n",
      "\n",
      "for c in S:\n",
      "\n",
      "    if c == '(':\n",
      "\n",
      "        stack.append(c)\n",
      "\n",
      "    elif c == ')':\n",
      "\n",
      "        if not stack:\n",
      "\n",
      "            balanced = False\n",
      "\n",
      "            break  # can't have more closing than opens\n",
      "\n",
      "        else:\n",
      "\n",
      "            stack.pop()\n",
      "\n",
      "    # else: do nothing\n",
      "\n",
      "After processing all characters, check if stack is empty and balanced is True.\n",
      "\n",
      "Wait, but even if during processing, we had a closing bracket that didn't match, balanced is set to False. And stack could be empty or not.\n",
      "\n",
      "So the code should first check if during processing any invalid case happened (like closing bracket without an open). Then, after processing all, check if stack is empty.\n",
      "\n",
      "Wait, the code needs to check two conditions:\n",
      "\n",
      "1. For every closing bracket, there was a corresponding opening bracket. So if at any time a closing bracket is encountered when the stack is empty, the entire string is invalid.\n",
      "\n",
      "2. At the end, all opening brackets have been closed. So stack is empty.\n",
      "\n",
      "So the code can track a flag (like valid = True). Then, for each closing bracket, check if the stack is not empty. If stack is empty, set valid to False and break. Otherwise, pop.\n",
      "\n",
      "After processing all characters, check if valid is still True and stack is empty.\n",
      "\n",
      "So code steps:\n",
      "\n",
      "For a given string S:\n",
      "\n",
      "valid = True\n",
      "\n",
      "stack = []\n",
      "\n",
      "for c in S:\n",
      "\n",
      "    if c == '(':\n",
      "\n",
      "        stack.append(c)\n",
      "\n",
      "    elif c == ')':\n",
      "\n",
      "        if len(stack) == 0:\n",
      "\n",
      "            valid = False\n",
      "\n",
      "            break\n",
      "\n",
      "        else:\n",
      "\n",
      "            stack.pop()\n",
      "\n",
      "    else:\n",
      "\n",
      "        continue  # ignore other characters\n",
      "\n",
      "if valid and len(stack) == 0:\n",
      "\n",
      "    print(\"YES\")\n",
      "\n",
      "else:\n",
      "\n",
      "    print(\"NO\")\n",
      "\n",
      "Yes. So this code would work for the example.\n",
      "\n",
      "Testing the third example: \"()(()\"\n",
      "\n",
      "Processing each character:\n",
      "\n",
      "First character '(', stack becomes ['(']\n",
      "\n",
      "Second ')', pop, stack is empty.\n",
      "\n",
      "Third '(', stack becomes ['(']\n",
      "\n",
      "Fourth '(', stack becomes ['(', '(']\n",
      "\n",
      "Fifth ')', pop, stack becomes ['(']\n",
      "\n",
      "After processing all characters, valid is True (since no invalid closing) but stack has size 1. So overall, output is NO.\n",
      "\n",
      "Which matches the example.\n",
      "\n",
      "Another test case: \"(()\" → stack ends with size 1 → NO.\n",
      "\n",
      "Another test case: \"())\" → during processing the second ')', stack is empty → valid is False → output NO.\n",
      "\n",
      "So the code should work.\n",
      "\n",
      "Now, handling multiple test cases.\n",
      "\n",
      "In Python, the input is T test cases. Each test case is a single line string.\n",
      "\n",
      "So the code would read T, then read T lines, each being S.\n",
      "\n",
      "So code outline:\n",
      "\n",
      "Read T as integer.\n",
      "\n",
      "For T times:\n",
      "\n",
      "    read S (using input().strip())\n",
      "\n",
      "    process S as per above.\n",
      "\n",
      "But in Python, when reading lines, sometimes leading/trailing spaces can be an issue, but the problem says 'the first line of each test case contains a single string S', so input().strip() should get the correct string.\n",
      "\n",
      "So the code would be:\n",
      "\n",
      "T = int(input())\n",
      "\n",
      "for _ in range(T):\n",
      "\n",
      "    s = input().strip()\n",
      "\n",
      "    stack = []\n",
      "\n",
      "    valid = True\n",
      "\n",
      "    for c in s:\n",
      "\n",
      "        if c == '(':\n",
      "\n",
      "            stack.append(c)\n",
      "\n",
      "        elif c == ')':\n",
      "\n",
      "            if not stack:\n",
      "\n",
      "                valid = False\n",
      "\n",
      "                break\n",
      "\n",
      "            else:\n",
      "\n",
      "                stack.pop()\n",
      "\n",
      "        # else ignored\n",
      "\n",
      "    if valid and not stack:\n",
      "\n",
      "        print(\"YES\")\n",
      "\n",
      "    else:\n",
      "\n",
      "        print(\"NO\")\n",
      "\n",
      "Yes.\n",
      "\n",
      "Testing this code against the sample input:\n",
      "\n",
      "Sample Input:\n",
      "\n",
      "3\n",
      "\n",
      "((()))\n",
      "\n",
      "(())() \n",
      "\n",
      "()(()\n",
      "\n",
      "Sample Output:\n",
      "\n",
      "YES\n",
      "\n",
      "YES\n",
      "\n",
      "NO\n",
      "\n",
      "First test case: '((()))' → each step:\n",
      "\n",
      "'(', '(', '(', ')', ')', ')'\n",
      "\n",
      "Stack after each step: [ '(', '(', '(', ] → then three pops. Ends empty. valid is True. So YES.\n",
      "\n",
      "Second test case: '(())()' → process as:\n",
      "\n",
      "'(', '(', ')', ')', '(', ')'\n",
      "\n",
      "Stack after:\n",
      "\n",
      "push ( → [ ( ]\n",
      "\n",
      "push ( → [ (, ( ]\n",
      "\n",
      "pop → [ ( ]\n",
      "\n",
      "pop → empty.\n",
      "\n",
      "push ( → [ ( ]\n",
      "\n",
      "pop → empty. All processed. Valid, stack empty → YES.\n",
      "\n",
      "Third test case: '()(()' → as before. Ends with stack size 1. So NO.\n",
      "\n",
      "So code works.\n",
      "\n",
      "Another test case: a string with other characters. Like 'a(b)c)'.\n",
      "\n",
      "Processing: the brackets are '( ) )'. So first '(', then ')', then ')'. At the third ')', stack is empty. So valid becomes False. So output is NO.\n",
      "\n",
      "Another test case: '()a' → stack processed as '(', then ')', ends empty. So YES.\n",
      "\n",
      "Yes, code handles that.\n",
      "\n",
      "So the code should be correct.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    stack = []\n",
      "    valid = True\n",
      "    for c in s:\n",
      "        if c == '(':\n",
      "            stack.append(c)\n",
      "        elif c == ')':\n",
      "            if not stack:\n",
      "                valid = False\n",
      "                break\n",
      "            stack.pop()\n",
      "    if valid and not stack:\n",
      "        print(\"YES\")\n",
      "    else:\n",
      "        print(\"NO\")\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "UNKNOWN_DIFFICULTY\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    stack = []\n",
      "    valid = True\n",
      "    for c in s:\n",
      "        if c == '(':\n",
      "            stack.append(c)\n",
      "        elif c == ')':\n",
      "            if not stack:\n",
      "                valid = False\n",
      "                break\n",
      "            stack.pop()\n",
      "    if valid and not stack:\n",
      "        print(\"YES\")\n",
      "    else:\n",
      "        print(\"NO\")\n",
      "5378dbbc2f9928bfe9b3a196e3a45a0b\n",
      "The Chef likes to stay in touch with his staff. So, the Chef, the head server, and the sous-chef all carry two-way transceivers so they can stay in constant contact. Of course, these transceivers have a limited range so if two are too far apart, they cannot communicate directly.\n",
      "\n",
      "\n",
      "The Chef invested in top-of-the-line transceivers which have a few advanced features. One is that even if two people cannot talk directly because they are out of range, if there is another transceiver that is close enough to both, then the two transceivers can still communicate with each other using the third transceiver as an intermediate device.\n",
      "\n",
      "\n",
      "There has been a minor emergency in the Chef's restaurant\n",
      "and he needs to communicate with both the head server and the sous-chef right away. Help the Chef determine if it is possible for all three people to communicate with each other, even if two must communicate through the third because they are too far apart.\n",
      "Input\n",
      "\n",
      "The first line contains a single positive integer T ≤ 100 indicating the number of test cases to follow. The first line of each test case contains a positive integer R ≤ 1,000 indicating that two transceivers can communicate directly without an intermediate transceiver if they are at most R meters away from each other. The remaining three lines of the test case describe the current locations of the Chef, the head server, and the sous-chef, respectively. Each such line contains two integers X,Y (at most 10,000 in absolute value) indicating that the respective person is located at position X,Y.\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "For each test case you are to output a single line containing a single string. If it is possible for all three to communicate then you should output \"yes\". Otherwise, you should output \"no\".\n",
      "\n",
      "\n",
      "To be clear, we say that two transceivers are close enough to communicate directly if the length of the straight line connecting their X,Y coordinates is at most R.\n",
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input:\n",
      "3\n",
      "1\n",
      "0 1\n",
      "0 0\n",
      "1 0\n",
      "2\n",
      "0 1\n",
      "0 0\n",
      "1 0\n",
      "2\n",
      "0 0\n",
      "0 2\n",
      "2 1\n",
      "\n",
      "\n",
      "Output:\n",
      "yes\n",
      "yes\n",
      "no\n",
      "<think>\n",
      "Okay, let's see. The problem is to determine whether all three people (Chef, head server, sous-chef) can communicate with each other, possibly through the third person. So the condition is that all three can form a connected network via their transceivers. The transceivers can communicate directly if the distance between them is <= R. If two are out of range, but both are in range of the third, then they can still communicate through that third person.\n",
      "\n",
      "Hmm. So for each test case, given R and the three positions, we need to check if all three are connected in such a way. How to model this?\n",
      "\n",
      "Let's think about pairwise distances. There are three pairs: Chef and head server, Chef and sous-chef, head server and sous-chef.\n",
      "\n",
      "The communication network is possible if either:\n",
      "\n",
      "1. All three can communicate directly with each other. But that's probably not necessary. Wait, no. Wait, the problem states that if two can't communicate directly but both can reach a third, then they can communicate through that third. So the key is that the three form a connected graph where each pair is either directly connected or connected via the third node.\n",
      "\n",
      "So the communication graph needs to be connected. So the three nodes (people) must form a connected graph, where edges are the pairs that are within R distance.\n",
      "\n",
      "So the possible connected cases are:\n",
      "\n",
      "- All three are within R of each other. Then all edges exist. Connected.\n",
      "\n",
      "- Two pairs are within R. For example, Chef to head server and Chef to sous-chef. Then all three are connected through the Chef.\n",
      "\n",
      "- Or, two are connected, and the third is connected to one of them. Like A-B and B-C. Then all are connected.\n",
      "\n",
      "Wait, but in this problem, there are exactly three nodes. So the graph is connected if at least two of the three possible edges exist in such a way that all three are linked. Wait, no. For three nodes, the graph is connected if there's a path between every pair. So the minimal connected graph would be a chain, like A connected to B, B connected to C. Then A can reach C through B. Or, all three connected via one central node (like star topology).\n",
      "\n",
      "So the condition is that all three can be connected via edges (direct communication) such that there's a path between any two nodes. So, the three nodes form a connected graph.\n",
      "\n",
      "But how do I check this?\n",
      "\n",
      "The possible connected cases for three nodes are:\n",
      "\n",
      "1. All three are connected (each pair is within R). Then the graph is connected.\n",
      "\n",
      "2. Exactly two pairs are connected, but those two pairs share a common node. For example, A-B and B-C. Then all three are connected.\n",
      "\n",
      "3. Only two pairs are connected, but they don't share a common node. Wait, but with three nodes, that's impossible. Let's see: three nodes are A, B, C. If we have edges A-B and C-A, then all are connected. So, any two edges would form a connected graph, except if the two edges are A-B and C-D, but here it's three nodes. So for three nodes, as long as there are at least two edges, and those edges form a connected graph. Wait, no. Wait, if the edges are A-B and A-C, that's connected. If edges are A-B and B-C, that's connected. If the edges are A-C and B-C, that's connected. But if the edges are A-B and C-D, but there is no D. So for three nodes, if two edges are present, but they are disjoint, like A-B and C is connected to no one, then the graph is disconnected. Wait, no. Wait, three nodes can't have two edges that are disjoint. Because for three nodes, the possible edges are A-B, A-C, B-C. So two edges can't be disjoint. For example, if edges are A-B and A-C: then all are connected. If edges are A-B and B-C: then connected. If edges are A-C and B-C: connected. So any two edges in three nodes will form a connected graph. Because each pair of edges shares a node. Because with three nodes, any two edges must share a common node.\n",
      "\n",
      "Wait, no. Suppose the three nodes are A, B, C. Suppose edges are A-B and B-C. Then the graph is connected. If edges are A-B and A-C: connected. If edges are A-B and C-D (but D isn't there), but in our case, it's three nodes, so all edges must be between the three. So any two edges among the three nodes will form a connected graph, because all three nodes are part of the same connected component. Wait, let's think: in a three-node graph with two edges, the graph is connected if there's a path between every pair. So for example, if edges are A-B and B-C, then A can reach C through B. If edges are A-B and A-C, then all are connected. If edges are B-C and A-C, same. So yes, with three nodes, any two edges will form a connected graph. Because any two edges must share a common node. Because three nodes have three possible edges, and any two edges will have at least one node in common. So the minimal connected graph is two edges.\n",
      "\n",
      "Wait, but what if there's only one edge? Then two nodes are connected, the third is isolated. So the graph is disconnected.\n",
      "\n",
      "So for the problem, the condition is that the communication graph (each edge is present if the distance is <= R) is connected.\n",
      "\n",
      "So, to check if all three can communicate, the communication graph must be connected.\n",
      "\n",
      "Therefore, the steps for each test case are:\n",
      "\n",
      "1. Compute the distances between each pair of the three people.\n",
      "\n",
      "2. For each pair, check if the distance is <= R. If yes, that edge exists.\n",
      "\n",
      "3. Determine if the graph formed by these edges is connected.\n",
      "\n",
      "If yes, output \"yes\", else \"no\".\n",
      "\n",
      "So how to compute this?\n",
      "\n",
      "For three nodes, the graph is connected if at least two edges exist, and those edges form a connected graph. But as per the earlier reasoning, any two edges in a three-node graph will form a connected graph, so as long as the number of edges is >=2, or if there are two edges.\n",
      "\n",
      "Wait, no. For example, if edges are A-B and A-C, then it's connected. But if edges are A-B and B-C, same. But if edges are A-B and A-B (same edge), but in reality, each edge is only counted once.\n",
      "\n",
      "Wait, but for three nodes, the maximum edges are three. So for the three-node graph:\n",
      "\n",
      "- If all three edges exist: connected.\n",
      "\n",
      "- If two edges: connected.\n",
      "\n",
      "- If one edge: disconnected.\n",
      "\n",
      "So the condition is that the graph has at least two edges, and that those two edges form a connected graph.\n",
      "\n",
      "But as per earlier reasoning, any two edges among three nodes will form a connected graph, because they must share a common node.\n",
      "\n",
      "Wait, let's take a specific example.\n",
      "\n",
      "Suppose edges are A-B and B-C. Then the graph is connected.\n",
      "\n",
      "Suppose edges are A-B and A-C: connected.\n",
      "\n",
      "Suppose edges are B-C and A-C: connected.\n",
      "\n",
      "Alternatively, if edges are A-B and A-C: connected.\n",
      "\n",
      "But what if the edges are B-C and A-B: same as first case.\n",
      "\n",
      "So in all cases where two edges exist, the graph is connected.\n",
      "\n",
      "Therefore, the graph is connected if the number of edges is 2 or 3.\n",
      "\n",
      "So, the problem reduces to checking if there are at least two edges (pairs within R) OR if there is at least one edge that allows the third node to connect through.\n",
      "\n",
      "Wait, no. Wait, if two edges exist, then the graph is connected. If one edge exists, then the graph is not connected. So the condition for the graph to be connected is that there are >=2 edges.\n",
      "\n",
      "Wait, but let's think: for example, if there are two edges, but they connect three nodes. So, for example, edges AB and BC. Then all three nodes are connected. So two edges are sufficient.\n",
      "\n",
      "So, the conclusion is: the graph is connected if the number of edges (pairs with distance <= R) is at least 2.\n",
      "\n",
      "Wait, but wait. Suppose in the graph, there are two edges but between three nodes. So, any two edges in a three-node graph will form a connected graph. Because any two edges must share a common node. For example, edges AB and AC: connected. Edges AB and BC: connected.\n",
      "\n",
      "Yes. So, the minimal connected graph has two edges. So, for three nodes, the graph is connected if the number of edges is two or three.\n",
      "\n",
      "Therefore, the problem can be solved as follows:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "1. Compute all three pairwise distances (Chef to head, Chef to sous, head to sous).\n",
      "\n",
      "2. Count how many of these pairs are within R.\n",
      "\n",
      "3. If the count is >=2, then output yes.\n",
      "\n",
      "Wait, but no. Because if two pairs are within R but the third node is not connected. Wait, but in three nodes, two edges would connect all three. Let me see.\n",
      "\n",
      "Suppose the three people are A, B, C.\n",
      "\n",
      "Case 1: edges AB and AC. Then all three are connected through A.\n",
      "\n",
      "Case 2: edges AB and BC. Then A connected to B, B connected to C. So A can reach C via B.\n",
      "\n",
      "Case 3: edges AC and BC. Then similar to case 2.\n",
      "\n",
      "So, yes, if any two edges are present, the graph is connected.\n",
      "\n",
      "So, for the problem, the answer is \"yes\" if either:\n",
      "\n",
      "- All three pairs are within R (3 edges), or\n",
      "\n",
      "- Exactly two pairs are within R (2 edges), or\n",
      "\n",
      "- The graph is connected with two edges (which it always is for three nodes).\n",
      "\n",
      "Wait, but what if only two pairs are within R, but those two pairs are the same as two nodes?\n",
      "\n",
      "Wait, no. For three nodes, there are three possible pairs. If two pairs are within R, then those two pairs must share a common node, because the three pairs are AB, AC, BC. For example, if AB and AC are within R, then the two pairs share A. If AB and BC are within R, they share B. If AC and BC are within R, they share C.\n",
      "\n",
      "So in any case, the two edges will form a connected graph.\n",
      "\n",
      "But wait, what if the two edges are AB and AC. Then B is connected to A, C is connected to A. So all three are connected.\n",
      "\n",
      "If the two edges are AB and BC. Then A is connected to B, B to C. So A is connected to C through B.\n",
      "\n",
      "So, in any case, if there are two or three edges, the graph is connected.\n",
      "\n",
      "So, the condition is that the number of edges (pairs with distance <= R) is >= 2.\n",
      "\n",
      "But wait, what about the case where two edges are present but the third person is connected through one of the edges.\n",
      "\n",
      "Wait, that's redundant. Because with two edges, the third is already connected through the two edges.\n",
      "\n",
      "So, the conclusion is: if any two pairs are within R, then output yes. Otherwise, output no.\n",
      "\n",
      "Wait, but wait. Let's consider a case where only two pairs are within R, but the third is not. But in the three-node graph, the two edges would connect all three. For example:\n",
      "\n",
      "Chef is at (0,0), head at (0,1), sous at (0,2). R is 1. Then Chef and head are within R (distance 1). Head and sous are within R (distance 1). Chef and sous are distance 2, which is > R. So edges are Chef-head and head-sous. The graph is connected. So output is yes.\n",
      "\n",
      "But according to the previous logic, since two edges exist, output yes. Which is correct.\n",
      "\n",
      "Another example: R=1. Chef at (0,0), head at (0,1), sous at (2,0). Then chef and head are within R (distance 1). Chef and sous are distance 2, > R. Head and sous are distance sqrt( (2)^2 + (-1)^2 )= sqrt(5) > 2, so >1. So only one edge exists. So the graph has one edge: chef-head. So sous is disconnected. So output is no.\n",
      "\n",
      "Another case: R=2. Chef at (0,0), head at (0,1), sous at (0,3). Chef and head: distance 1 <=2. Chef and sous: distance 3>2. Head and sous: 2 <=2. So edges are chef-head and head-sous. So two edges. So graph is connected. Output yes.\n",
      "\n",
      "So the logic seems to hold.\n",
      "\n",
      "Wait, but wait: what if only two pairs are within R, but they are not overlapping. Wait, that's impossible for three nodes. Because three nodes have three pairs. So two pairs would always share a common node. Because for three nodes, the three pairs are AB, AC, BC. So any two pairs must share one node. For example, AB and AC share A. AB and BC share B. AC and BC share C.\n",
      "\n",
      "So, in any case, two edges will form a connected graph.\n",
      "\n",
      "So the condition is that the number of edges (pairs with distance <= R) is >=2.\n",
      "\n",
      "But wait, let's check the sample input.\n",
      "\n",
      "Sample input 1:\n",
      "\n",
      "3\n",
      "\n",
      "First test case:\n",
      "\n",
      "R=1\n",
      "\n",
      "Chef at (0,1), head at (0,0), sous at (1,0).\n",
      "\n",
      "Compute pairwise distances:\n",
      "\n",
      "Chef to head: sqrt( (0-0)^2 + (1-0)^2 )=1 <=1: yes.\n",
      "\n",
      "Chef to sous: sqrt( (0-1)^2 + (1-0)^2 ) = sqrt(2) ~1.414 >1: no.\n",
      "\n",
      "Head to sous: sqrt( (0-1)^2 + (0-0)^2 )=1 <=1: yes.\n",
      "\n",
      "So two edges: chef-head and head-sous. So total edges=2. So output yes.\n",
      "\n",
      "Sample output is yes. Which matches.\n",
      "\n",
      "Second test case:\n",
      "\n",
      "R=2.\n",
      "\n",
      "Same positions. Then chef to sous: sqrt(2) ~1.414 <=2. So chef-sous is also within R. So edges are chef-head (1<=2), chef-sous (sqrt(2)<=2), head-sous (1<=2). All three edges. So output yes.\n",
      "\n",
      "Third test case:\n",
      "\n",
      "R=2.\n",
      "\n",
      "Chef at (0,0), head at (0,2), sous at (2,1).\n",
      "\n",
      "Compute distances:\n",
      "\n",
      "Chef to head: distance 2 (sqrt( (0-0)^2 + (0-2)^2 ) = 2. So <=2. So edge exists.\n",
      "\n",
      "Chef to sous: sqrt( (0-2)^2 + (0-1)^2 ) = sqrt(4+1) = sqrt(5) ~2.236>2. So no edge.\n",
      "\n",
      "Head to sous: sqrt( (0-2)^2 + (2-1)^2 )= sqrt(4+1) = sqrt(5) ~2.236>2. So no edge.\n",
      "\n",
      "So edges: only chef-head. So one edge. So the graph is disconnected. So output no. Which matches sample.\n",
      "\n",
      "So the logic of checking if the number of edges >=2 works for the sample inputs.\n",
      "\n",
      "Wait, but what about a case where there are two edges but the third node is not connected?\n",
      "\n",
      "Wait, that's impossible. Because with three nodes, two edges would mean that all three are connected.\n",
      "\n",
      "For example, if edges are A-B and B-C, then A can reach C via B. So the graph is connected. So, two edges are sufficient.\n",
      "\n",
      "So the answer is: if the number of edges (pairs with distance <= R) is >=2, then output yes. Otherwise, no.\n",
      "\n",
      "But wait, there's another scenario. What if all three are within R of each other. Then three edges exist. So the answer is yes.\n",
      "\n",
      "Another scenario: two edges, which connect all three. Yes.\n",
      "\n",
      "Another scenario: one edge. Then, two people can communicate directly, but the third is isolated. So output no.\n",
      "\n",
      "So the condition is that the number of edges (pairwise distances <= R) is >=2.\n",
      "\n",
      "But wait, let's think of another example. Suppose R=3.\n",
      "\n",
      "Positions:\n",
      "\n",
      "Chef at (0,0), head at (0,3), sous at (0,6).\n",
      "\n",
      "Chef to head: distance 3 <=3: yes.\n",
      "\n",
      "Head to sous: 3 <=3: yes.\n",
      "\n",
      "Chef to sous: 6>3: no.\n",
      "\n",
      "So edges are chef-head and head-sous. So two edges. So the graph is connected. Output yes.\n",
      "\n",
      "So the logic holds.\n",
      "\n",
      "Another example: R=5.\n",
      "\n",
      "Chef at (0,0), head at (5,0), sous at (10,0).\n",
      "\n",
      "Chef-head: distance 5 <=5: yes.\n",
      "\n",
      "Head-sous: 5 <=5: yes.\n",
      "\n",
      "Chef-sous: 10>5: no.\n",
      "\n",
      "So two edges. Output yes.\n",
      "\n",
      "Yes.\n",
      "\n",
      "So the logic seems correct.\n",
      "\n",
      "So the steps to code this would be:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "- Read R.\n",
      "\n",
      "- Read three points (x1,y1), (x2,y2), (x3,y3).\n",
      "\n",
      "- Compute the squared distances between each pair. Because comparing distance squared with R^2 is the same as comparing the actual distance with R, but avoids floating-point operations. So for each pair, compute dx^2 + dy^2, compare to R^2.\n",
      "\n",
      "But wait, the problem statement says that two transceivers can communicate if the straight line distance is at most R. So for each pair of points (a, b), compute the Euclidean distance between them, and check if it's <= R.\n",
      "\n",
      "But using squared distances avoids the square root, which is more efficient and avoids floating points.\n",
      "\n",
      "So, for each pair:\n",
      "\n",
      "distance_squared = (x1-x2)^2 + (y1-y2)^2\n",
      "\n",
      "if distance_squared <= R*R: then the pair is within R.\n",
      "\n",
      "So, compute this for all three pairs.\n",
      "\n",
      "Count how many of the three pairs are within R. Let's call this count 'count_edges'.\n",
      "\n",
      "If count_edges >=2: output 'yes'\n",
      "\n",
      "Else: 'no'\n",
      "\n",
      "Wait, but wait. What if two edges are not in a chain? For example, if two edges are AB and AC. Then the graph is connected, yes.\n",
      "\n",
      "So the code can just count the number of pairs within R and check if it's at least two.\n",
      "\n",
      "So the code would be:\n",
      "\n",
      "Read T.\n",
      "\n",
      "For each T test cases:\n",
      "\n",
      "Read R.\n",
      "\n",
      "Read three points: p1, p2, p3.\n",
      "\n",
      "Compute d1 = distance squared between p1 and p2.\n",
      "\n",
      "d2 = between p1 and p3.\n",
      "\n",
      "d3 = between p2 and p3.\n",
      "\n",
      "count = 0\n",
      "\n",
      "if d1 <= R^2: count +=1\n",
      "\n",
      "if d2 <= R^2: count +=1\n",
      "\n",
      "if d3 <= R^2: count +=1\n",
      "\n",
      "if count >= 2: print 'yes'\n",
      "\n",
      "else: print 'no'\n",
      "\n",
      "Wait, but this is not correct. Because in the case where two pairs are within R, but the third is not, but the graph is connected. But according to our previous reasoning, this will always be connected, but the code would output 'yes' when count >=2, which is correct.\n",
      "\n",
      "Wait, but let's test the first sample input.\n",
      "\n",
      "Sample 1:\n",
      "\n",
      "Test case 1:\n",
      "\n",
      "R=1.\n",
      "\n",
      "Points:\n",
      "\n",
      "Chef (0,1), head (0,0), sous (1,0).\n",
      "\n",
      "d1 (chef to head): (0-0)^2 + (1-0)^2 = 1. R^2 is 1. So d1 <= R^2 → yes. count=1.\n",
      "\n",
      "d2 (chef to sous): (0-1)^2 + (1-0)^2 = 2 → 2>1 → no. count remains 1.\n",
      "\n",
      "d3 (head to sous): (0-1)^2 + (0-0)^2 =1 → yes. count=2.\n",
      "\n",
      "So count=2 → output yes. Correct.\n",
      "\n",
      "Sample 3:\n",
      "\n",
      "Test case3:\n",
      "\n",
      "R=2.\n",
      "\n",
      "Chef (0,0), head (0,2), sous (2,1).\n",
      "\n",
      "d1 (chef-head): (0-0)^2 + (0-2)^2 =4 → 4 <=4 → yes. count=1.\n",
      "\n",
      "d2 (chef-sous): (0-2)^2 + (0-1)^2 =4+1=5>4 → no. count remains 1.\n",
      "\n",
      "d3 (head-sous): (0-2)^2 + (2-1)^2=4+1=5>4 → no. count=1. So output no.\n",
      "\n",
      "Sample 2:\n",
      "\n",
      "Test case2:\n",
      "\n",
      "R=2.\n",
      "\n",
      "Same as test case 1, but R=2.\n",
      "\n",
      "d1 is 1 <=4 → yes.\n",
      "\n",
      "d2: sqrt(2) squared is 2 <=4 → yes.\n",
      "\n",
      "d3: 1 <=4 → yes. count=3 → yes.\n",
      "\n",
      "So code outputs yes.\n",
      "\n",
      "So the code works for the samples.\n",
      "\n",
      "But wait, what about a case where two edges exist but the third node is not connected via those two edges?\n",
      "\n",
      "Wait, no. Because two edges in three nodes will always form a connected graph.\n",
      "\n",
      "So the code is correct.\n",
      "\n",
      "Therefore, the code can be written as follows.\n",
      "\n",
      "Read T.\n",
      "\n",
      "For each T:\n",
      "\n",
      "Read R.\n",
      "\n",
      "Read three points: (x1,y1), (x2,y2), (x3,y3).\n",
      "\n",
      "Compute the three squared distances:\n",
      "\n",
      "d1 = (x1-x2)^2 + (y1-y2)^2\n",
      "\n",
      "d2 = (x1-x3)^2 + (y1-y3)^2\n",
      "\n",
      "d3 = (x2-x3)^2 + (y2-y3)^2\n",
      "\n",
      "R_squared = R*R\n",
      "\n",
      "count = 0\n",
      "\n",
      "if d1 <= R_squared: count +=1\n",
      "\n",
      "if d2 <= R_squared: count +=1\n",
      "\n",
      "if d3 <= R_squared: count +=1\n",
      "\n",
      "if count >=2: print 'yes'\n",
      "\n",
      "else: print 'no'\n",
      "\n",
      "Yes.\n",
      "\n",
      "This should work.\n",
      "\n",
      "Let's test another case where count is 2.\n",
      "\n",
      "For example:\n",
      "\n",
      "Test case where two pairs are within R.\n",
      "\n",
      "Chef at (0,0), head at (0, R), sous at (0, 2R). Then:\n",
      "\n",
      "d1 (chef-head) is R^2 → yes.\n",
      "\n",
      "d2 (chef-sous): (2R)^2 → 4R^2 > R^2 → no.\n",
      "\n",
      "d3 (head-sous): R^2 → yes.\n",
      "\n",
      "So count is 2 → output yes. But the three points are arranged in a line, chef and sous can communicate through head.\n",
      "\n",
      "So code works.\n",
      "\n",
      "Another case: count is 2 but the third node is not connected. But in reality, two edges must connect all three.\n",
      "\n",
      "Yes.\n",
      "\n",
      "Therefore, the code should be correct.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    T = int(sys.stdin.readline())\n",
      "    for _ in range(T):\n",
      "        R = int(sys.stdin.readline())\n",
      "        R_sq = R * R\n",
      "        points = []\n",
      "        for _ in range(3):\n",
      "            x, y = map(int, sys.stdin.readline().split())\n",
      "            points.append((x, y))\n",
      "        # Compute pairwise squared distances\n",
      "        a, b, c = points\n",
      "        d_ab = (a[0] - b[0])**2 + (a[1] - b[1])**2\n",
      "        d_ac = (a[0] - c[0])**2 + (a[1] - c[1])**2\n",
      "        d_bc = (b[0] - c[0])**2 + (b[1] - c[1])**2\n",
      "        count = 0\n",
      "        if d_ab <= R_sq:\n",
      "            count += 1\n",
      "        if d_ac <= R_sq:\n",
      "            count += 1\n",
      "        if d_bc <= R_sq:\n",
      "            count += 1\n",
      "        print(\"yes\" if count >= 2 else \"no\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "1\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    T = int(sys.stdin.readline())\n",
      "    for _ in range(T):\n",
      "        R = int(sys.stdin.readline())\n",
      "        R_sq = R * R\n",
      "        points = []\n",
      "        for _ in range(3):\n",
      "            x, y = map(int, sys.stdin.readline().split())\n",
      "            points.append((x, y))\n",
      "        # Compute pairwise squared distances\n",
      "        a, b, c = points\n",
      "        d_ab = (a[0] - b[0])**2 + (a[1] - b[1])**2\n",
      "        d_ac = (a[0] - c[0])**2 + (a[1] - c[1])**2\n",
      "        d_bc = (b[0] - c[0])**2 + (b[1] - c[1])**2\n",
      "        count = 0\n",
      "        if d_ab <= R_sq:\n",
      "            count += 1\n",
      "        if d_ac <= R_sq:\n",
      "            count += 1\n",
      "        if d_bc <= R_sq:\n",
      "            count += 1\n",
      "        print(\"yes\" if count >= 2 else \"no\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "5295c0a98f0025a377be5340304aaae3\n",
      "Frank explained its friend Felman the algorithm of Euclides to calculate the GCD \n",
      "of two numbers. Then Felman implements it algorithm \n",
      "\n",
      "\n",
      "int gcd(int a, int b)\n",
      "{\n",
      "\tif (b==0)\n",
      "\t\treturn a;\n",
      "\telse\n",
      "\t\treturn gcd(b,a%b);\n",
      "}\n",
      "\n",
      "and it proposes to Frank that makes it \n",
      "but with a little integer and another integer that has up to 250 digits. \n",
      "Your task is to help Frank programming an efficient code for the challenge of Felman.\n",
      "Input\n",
      "The first line of the input file contains a number representing the number of lines to follow.\n",
      "Each line consists of two number A and B (0 ≤ A ≤ 40000 and A ≤ B < 10^250).\n",
      "\n",
      "\n",
      "Output\n",
      "Print for each pair (A,B) in the input one integer representing the GCD of A and B.\n",
      "\n",
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input:\n",
      "2\n",
      "2 6\n",
      "10 11\n",
      "\n",
      "\n",
      "Output:\n",
      "2\n",
      "1\n",
      "<think>\n",
      "Okay, let's see. I need to compute the GCD of two numbers where one is up to 40000 and the other can be up to 250 digits long. Hmm, the problem says that for each pair (A, B), A is a regular integer and B is a very big number. The challenge is to compute GCD(A, B) efficiently.\n",
      "\n",
      "Wait, the Euclidean algorithm usually requires taking modulo of the two numbers. But when B is a huge number (like 250 digits), calculating B mod A directly might be problematic because in Python, big integers are handled, but maybe there's a more efficient way to compute the modulus without converting the entire B string into an integer, which could be slow. Wait, but Python can handle big integers natively. So maybe converting the string B to an integer is feasible. Let's think about that.\n",
      "\n",
      "But let's check the constraints. For the first number A, it's up to 40000. So when we compute B mod A, even if B is 250 digits, mod A can be computed by processing the digits of B one by one. Because (current_number * 10 + next_digit) mod A can be computed step by step. That way, we don't have to handle the entire big number as an integer. That might be more efficient, especially for very large B. Oh right, because converting a 250-digit string to an integer is possible in Python, but maybe for some programming languages that's an issue. However, in Python, it's manageable. But perhaps using the step-by-step mod calculation is better for efficiency here, especially since A can be up to 40000, which is manageable for such a loop.\n",
      "\n",
      "So the steps would be:\n",
      "\n",
      "For each pair (A, B):\n",
      "- If A is 0, then the GCD is B (since GCD(0, B) = B). But wait, the problem statement says 0 ≤ A ≤ 40000 and A ≤ B. So if A is 0, then B is also 0 (since A <= B and A is 0), but then the GCD of 0 and 0 is undefined, but perhaps in the problem it's considered as 0. Hmm, but the problem's example input doesn't have such cases. Need to handle that edge case.\n",
      "\n",
      "Wait, the problem says \"0 ≤ A ≤ 40000 and A ≤ B < 10^250\". So if A is 0, then B must be at least A (0), but B can be 0. So if A is 0 and B is 0, then what? The GCD of 0 and 0 is undefined mathematically, but sometimes considered 0 in programming contexts. But the problem's input may or may not have such cases. So we need to handle that.\n",
      "\n",
      "But according to the problem statement, the output for each pair is the GCD of A and B. So if both are 0, the output is 0. Otherwise, if A is 0, then the GCD is B. Because GCD(0, B) is B when B is non-zero. Wait, no. GCD(0, B) is B's absolute value, but since B is non-negative here. So if A is 0, then the result is B. But if both are 0, then it's 0.\n",
      "\n",
      "But in the problem's input constraints, since A can be 0 and B can be up to 1e250, but when A is 0, then B must also be 0 (since A <= B, and A is 0). Wait, no. Because A can be 0, and B can be 0 or larger. For example, A=0 and B=5 is allowed? No, because A ≤ B. So if A is 0, then B can be 0 or any number >=0. Wait, the problem says \"A ≤ B < 10^250\". So B is >= A, which can be 0. So when A is 0, B can be 0 or any value up to 1e250. So in that case, when A is 0, the GCD is B, but if B is also 0, then it's 0.\n",
      "\n",
      "Wait, but the GCD of 0 and 0 is undefined. But the problem may expect us to return 0. So in code, perhaps:\n",
      "\n",
      "If A is 0 and B is 0: output 0.\n",
      "\n",
      "If A is 0 and B is non-zero: output B.\n",
      "\n",
      "But how do we handle that when B is given as a string. Because when B is a 250-digit number, but if A is 0, then we need to compute B's integer value mod 0, which is not possible, but perhaps when A is 0, the GCD is just B.\n",
      "\n",
      "Wait, let's think again. According to the Euclidean algorithm, GCD(A, B) when A is 0 is B. But if B is 0, then both are 0, and GCD is 0. So in code:\n",
      "\n",
      "if A == 0:\n",
      "    if B is 0:\n",
      "        return 0\n",
      "    else:\n",
      "        return B\n",
      "else:\n",
      "    compute GCD(B mod A, A)\n",
      "\n",
      "But how do we compute B mod A when B is a very large number given as a string?\n",
      "\n",
      "So for the case where A is non-zero, we need to compute (B mod A). Since B is a very large number, but A is up to 40000, we can compute B mod A by iterating through each digit of B and calculating the mod step by step. For example, start with 0, then for each digit, compute (current * 10 + digit) % A.\n",
      "\n",
      "Yes. So for example, B is \"1234\", A is 5. Then:\n",
      "\n",
      "current = 0\n",
      "\n",
      "0*10 +1 =1 → mod5 is 1\n",
      "\n",
      "1*10 +2=12 → mod5 is 2\n",
      "\n",
      "2*10 +3=23 mod5 is 3\n",
      "\n",
      "3*10 +4=34 mod5 is 4.\n",
      "\n",
      "So B mod A is 4.\n",
      "\n",
      "So, for each character in the B string, we can process it digit by digit, and compute the modulus.\n",
      "\n",
      "This is efficient even for 250 digits, as it's O(n) where n is the length of B (250 steps at most).\n",
      "\n",
      "So the plan is:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "Read A and B (where B is a string, as it's up to 250 digits).\n",
      "\n",
      "If A is 0:\n",
      "\n",
      "   if B is \"0\", then output 0.\n",
      "\n",
      "   else, output the integer value of B (but since B can be up to 250 digits, but in Python, that's manageable, but in this case, if B is very large, but the output is the GCD, which in this case is B. Wait, but if B is a very large number and A is 0, then GCD(A, B) is B. But when B is 0, GCD is 0.\n",
      "\n",
      "Wait, but how to check if B is 0 when A is 0. Because B is given as a string, possibly with leading zeros. For example, if B is \"000\", then it's 0. So need to check if the B string is all zeros. So in code:\n",
      "\n",
      "if A ==0:\n",
      "\n",
      "   if B is all zeros (i.e., after converting to integer, it is 0) → then return 0\n",
      "\n",
      "   else: return B's integer value.\n",
      "\n",
      "But converting B to integer is possible, but for a 250-digit number, Python can handle it. So even if B is \"1234...\", converting to int(B) is okay.\n",
      "\n",
      "But perhaps checking if B is zero can be done without converting the entire string. For example, check if all characters are '0' except for leading zeros.\n",
      "\n",
      "Wait, but in the input, is B given as a string with possible leading zeros? The problem says that each line consists of two numbers A and B. So perhaps B is given as a decimal integer, possibly with leading zeros. For example, the input could be \"0 0000\", which represents A=0 and B=0.\n",
      "\n",
      "So when A is 0, and B's string is \"0000\", then the GCD is 0. If B's string is \"123\", then GCD is 123.\n",
      "\n",
      "But converting the entire B string to integer can be done in Python, but if the string is 250 characters long, it's still possible. So perhaps that's manageable.\n",
      "\n",
      "But if B is 250 digits, converting to an integer is feasible. Because Python's int can handle arbitrarily large integers.\n",
      "\n",
      "So in code:\n",
      "\n",
      "Read A and B_str.\n",
      "\n",
      "If A == 0:\n",
      "\n",
      "   if B_str consists of all '0's → output 0\n",
      "\n",
      "   else → compute GCD of 0 and B is B's value.\n",
      "\n",
      "But wait, when A is 0, the GCD is B's value. But when B is 0, output 0. So in code:\n",
      "\n",
      "if A ==0:\n",
      "\n",
      "   B = int(B_str)\n",
      "\n",
      "   if B ==0:\n",
      "\n",
      "       print(0)\n",
      "\n",
      "   else:\n",
      "\n",
      "       print(B)\n",
      "\n",
      "else:\n",
      "\n",
      "   compute B mod A using the step-by-step method.\n",
      "\n",
      "   then compute GCD(A, mod_value) using Euclidean algorithm.\n",
      "\n",
      "But wait, the Euclidean algorithm says GCD(A, B) = GCD(B mod A, A). So once we compute mod_value = B mod A, then we can compute GCD of (mod_value, A).\n",
      "\n",
      "But then, since A is up to 40000, and mod_value is less than A, the Euclidean steps can be done quickly.\n",
      "\n",
      "So the main steps are:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "1. Read A (as integer) and B_str (as string).\n",
      "\n",
      "2. If A is 0:\n",
      "\n",
      "   a. If B is all zeros (i.e., B is 0), output 0.\n",
      "\n",
      "   b. Else, output B as integer.\n",
      "\n",
      "3. Else:\n",
      "\n",
      "   a. Compute B mod A by processing each character in B_str:\n",
      "\n",
      "      i. Initialize mod_value = 0\n",
      "\n",
      "      ii. For each digit_char in B_str:\n",
      "\n",
      "          mod_value = (mod_value * 10 + int(digit_char)) % A\n",
      "\n",
      "   b. Compute GCD of (mod_value, A) using the Euclidean algorithm.\n",
      "\n",
      "4. Output the result.\n",
      "\n",
      "But wait, how to handle the case where B is 0 when A is non-zero. For example, if A is 3 and B is 0. Then GCD(3,0) is 3.\n",
      "\n",
      "But in the problem statement, when A is non-zero, B can be >=A, but B can be 0? No, because the input constraints say A <= B. So if A is non-zero, B must be >= A. But that's not possible if A is 3 and B is 0. So according to the problem statement, the input pairs are such that A <= B. Therefore, when A is non-zero, B must be >= A, but B can't be 0. Wait, but if A is 0, then B can be 0.\n",
      "\n",
      "Wait, the input constraints are 0 ≤ A ≤40000 and A ≤ B <1e250.\n",
      "\n",
      "So when A is non-zero (say 5), B must be >=5 and up to 250 digits. So B is >=A, hence B can't be 0. So when A is non-zero, B is a number >= A, hence B is non-zero, and in code, when A is non-zero, B is a string representing a number >= A. Therefore, when processing B mod A, the step-by-step computation is valid, and mod_value will be between 0 and A-1.\n",
      "\n",
      "Therefore, in code:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "Read A (as integer), B_str (as string).\n",
      "\n",
      "If A is 0:\n",
      "\n",
      "   if B_str is \"0\" (after converting to integer is 0), then output 0.\n",
      "\n",
      "   else, output B_str converted to integer.\n",
      "\n",
      "Else:\n",
      "\n",
      "   compute mod_value as (B_str mod A) via digit processing.\n",
      "\n",
      "   then compute GCD of mod_value and A using Euclidean algorithm.\n",
      "\n",
      "But how to handle the case where B is 0 when A is non-zero? According to the problem constraints, A <= B, so when A is non-zero, B can't be zero. So such cases won't appear in the input.\n",
      "\n",
      "Therefore, the code can proceed as described.\n",
      "\n",
      "Now, implementing this in Python.\n",
      "\n",
      "First, read the number of test cases. Then for each test case, read A and B_str.\n",
      "\n",
      "But wait, the input lines may have two numbers: A and B. So for each line after the first, split into two parts. For example, in the sample input:\n",
      "\n",
      "2\n",
      "\n",
      "2 6\n",
      "\n",
      "10 11\n",
      "\n",
      "The first line is the number of test cases. Then two lines, each with two numbers. So the code should read the first line as the number of test cases, then read that many lines, each containing two numbers: A (int) and B (string, since it can be very large).\n",
      "\n",
      "So in Python:\n",
      "\n",
      "n = int(input())\n",
      "\n",
      "for _ in range(n):\n",
      "\n",
      "    line = input().strip()\n",
      "\n",
      "    # Split into A and B.\n",
      "\n",
      "    a_str, b_str = line.split()\n",
      "\n",
      "    a = int(a_str)\n",
      "\n",
      "    if a == 0:\n",
      "\n",
      "        # Check if B is all zeros.\n",
      "\n",
      "        # Since B is a string, check if all characters are '0's.\n",
      "\n",
      "        # For example, '0000' is 0.\n",
      "\n",
      "        # So, if b_str is all '0's, then output 0.\n",
      "\n",
      "        # Else, output int(b_str)\n",
      "\n",
      "        if all(c == '0' for c in b_str):\n",
      "\n",
      "            print(0)\n",
      "\n",
      "        else:\n",
      "\n",
      "            print(int(b_str))\n",
      "\n",
      "    else:\n",
      "\n",
      "        # Compute B mod a by processing each character.\n",
      "\n",
      "        mod = 0\n",
      "\n",
      "        for c in b_str:\n",
      "\n",
      "            mod = (mod * 10 + int(c)) % a\n",
      "\n",
      "        # Now compute gcd(a, mod)\n",
      "\n",
      "        # Python has math.gcd, but returns positive value.\n",
      "\n",
      "        # Also, math.gcd(0, x) returns x. But in this case, mod is between 0 and a-1.\n",
      "\n",
      "        import math\n",
      "\n",
      "        # Because a is non-zero here.\n",
      "\n",
      "        # So compute gcd(a, mod). Since a is non-zero.\n",
      "\n",
      "        result = math.gcd(a, mod)\n",
      "\n",
      "        print(result)\n",
      "\n",
      "Wait, but what if mod is 0? Then GCD(a, 0) is a. Because the GCD of a and 0 is a. So math.gcd(a, 0) returns a.\n",
      "\n",
      "For example, if a is 6 and B is 6, then mod is 6%6=0. Then GCD(6,0) is 6.\n",
      "\n",
      "So the code is correct.\n",
      "\n",
      "Testing the sample input:\n",
      "\n",
      "Sample Input:\n",
      "\n",
      "2\n",
      "\n",
      "2 6\n",
      "\n",
      "10 11\n",
      "\n",
      "First case: a=2, B_str='6'.\n",
      "\n",
      "Compute mod:\n",
      "\n",
      "mod starts at 0.\n",
      "\n",
      "First digit '6': 0*10 +6 =6 mod 2 → 0.\n",
      "\n",
      "So mod is 0. GCD(2,0) is 2. Output 2.\n",
      "\n",
      "Second case: a=10, B_str='11'.\n",
      "\n",
      "Compute mod:\n",
      "\n",
      "mod starts at 0.\n",
      "\n",
      "First digit 1: 0*10 +1 =1 mod10 →1.\n",
      "\n",
      "Second digit 1: 1*10 +1=11 mod10=1. So mod is 1.\n",
      "\n",
      "GCD(10,1) is 1. Output 1. Which matches the sample output.\n",
      "\n",
      "Another test case: a=0, B=0. Output 0.\n",
      "\n",
      "Another test case: a=0, B=5. Then output 5.\n",
      "\n",
      "If a=3, B=6 (string '6'). mod is 6 mod3=0. GCD(3,0) is 3.\n",
      "\n",
      "So the code should handle all cases correctly.\n",
      "\n",
      "Now, for the case where a=0 and B is a very long string of zeros, like '0000', the code will output 0. If B is a very long non-zero string, like '123456...250 digits', it will output that number as the GCD.\n",
      "\n",
      "This should handle all cases correctly.\n",
      "\n",
      "So the code should work.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "n = int(input())\n",
      "for _ in range(n):\n",
      "    a_str, b_str = input().split()\n",
      "    a = int(a_str)\n",
      "    if a == 0:\n",
      "        if all(c == '0' for c in b_str):\n",
      "            print(0)\n",
      "        else:\n",
      "            print(int(b_str))\n",
      "    else:\n",
      "        mod = 0\n",
      "        for c in b_str:\n",
      "            mod = (mod * 10 + int(c)) % a\n",
      "        print(math.gcd(a, mod))\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "MEDIUM\n",
      "import math\n",
      "\n",
      "n = int(input())\n",
      "for _ in range(n):\n",
      "    a_str, b_str = input().split()\n",
      "    a = int(a_str)\n",
      "    if a == 0:\n",
      "        if all(c == '0' for c in b_str):\n",
      "            print(0)\n",
      "        else:\n",
      "            print(int(b_str))\n",
      "    else:\n",
      "        mod = 0\n",
      "        for c in b_str:\n",
      "            mod = (mod * 10 + int(c)) % a\n",
      "        print(math.gcd(a, mod))\n",
      "e2e75d9d7d47d6f22c7eb408f8911af8\n",
      "A Little Elephant from the Zoo of Lviv likes lucky strings, i.e., the strings that consist only of the lucky digits 4 and 7.\n",
      "The Little Elephant calls some string T of the length M balanced if there exists at least one integer X (1 ≤ X ≤ M) such that the number of digits 4 in the substring T[1, X - 1] is equal to the number of digits 7 in the substring T[X, M]. For example, the string S = 7477447 is balanced since S[1, 4] = 7477 has 1 digit 4 and S[5, 7] = 447 has 1 digit 7. On the other hand, one can verify that the string S = 7 is not balanced.\n",
      " The Little Elephant has the string S of the length N. He wants to know the number of such pairs of integers (L; R) that 1 ≤ L ≤ R ≤ N and the substring S[L, R]  is balanced. Help him to find this number.\n",
      "Notes.\n",
      "\n",
      "Let S be some lucky string. Then\n",
      "\n",
      "\n",
      "|S| denotes the length of the string S;\n",
      "\n",
      "S[i] (1 ≤ i ≤ |S|) denotes the i^th character of S (the numeration of characters starts from 1);\n",
      "\n",
      " S[L, R] (1 ≤ L ≤ R ≤ |S|) denotes the string with the following sequence of characters: S[L], S[L + 1], ..., S[R], and is called a substring of S. For L > R we mean by S[L, R] an empty string.\n",
      "Input\n",
      "The first line of the input file contains a single integer T, the number of test cases. Each of the following T lines contains one string, the string S for the corresponding test case. The input file does not contain any whitespaces.\n",
      "\n",
      "Output\n",
      "For each test case output a single line containing the answer for this test case.\n",
      "\n",
      "\n",
      "Constraints\n",
      " 1 ≤ T ≤ 10\n",
      " 1 ≤ |S| ≤ 100000\n",
      " S consists only of the lucky digits 4 and 7.\n",
      "\n",
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input:\n",
      "4\n",
      "47\n",
      "74\n",
      "477\n",
      "4747477\n",
      "\n",
      "Output:\n",
      "2\n",
      "2\n",
      "3\n",
      "23\n",
      "\n",
      "\n",
      "\n",
      "Explanation\n",
      "In the first test case balance substrings are S[1, 1] = 4 and S[1, 2] = 47.\n",
      "In the second test case balance substrings are S[2, 2] = 4 and S[1, 2] = 74.\n",
      "Unfortunately, we can't provide you with the explanations of the third and the fourth test cases. You should figure it out by yourself. Please, don't ask about this in comments.\n",
      "<think>\n",
      "Okay, I need to solve this problem where I have to count the number of balanced substrings in a given string of 4s and 7s. Let's try to understand the problem step by step.\n",
      "\n",
      "First, the definition of a balanced substring T of length M. It's balanced if there exists an X between 1 and M (inclusive) such that the number of 4s in the prefix T[1 to X-1] is equal to the number of 7s in the suffix T[X to M]. So for example, if the substring is of length 2, like '47', then X could be 1. Because the prefix before X is nothing (so 0 4s), and the suffix from X=1 to 2 is '47' which has one 7. Wait, but 0 vs 1? Oh wait, maybe I'm misunderstanding the example.\n",
      "\n",
      "Wait the example given in the problem is S=7477447. The balanced substring is when L=1 and R=7. The split is at X=4. So S[1..4] is 7477, which has 1 four (since positions 2 is 4, and positions 1,3,4 are 7,7,7?) Wait wait, no. Wait S is 7 4 7 7 4 4 7. So S[1,4] is 7,4,7,7. The 4s here are 1. Then S[5,7] is 4,4,7. The 7s here are 1. So 1 equals 1, so it's balanced.\n",
      "\n",
      "So the idea is that for a substring T (which is a part of S), we split it into two parts before X and after (including X). The number of 4s in the prefix (before X) should equal the number of 7s in the suffix (from X to end). And for the substring to be balanced, there must be at least one such X in it.\n",
      "\n",
      "The problem is to find all possible substrings (L, R) where L <= R, such that in that substring, there exists such an X.\n",
      "\n",
      "Now, how to approach this efficiently?\n",
      "\n",
      "The naive approach would be to check all possible substrings (there are O(n^2) of them for a string of length n) and for each substring check all possible X positions (O(n) per substring). But for n=1e5, that's O(n^3) which is impossible.\n",
      "\n",
      "So we need a smarter way.\n",
      "\n",
      "Let's think about the conditions. For a substring S[L..R], which is length M = R-L+1. We need to find if there exists an X (1<=X<=M) such that:\n",
      "\n",
      "number of 4s in S[L..L+X-2] equals the number of 7s in S[L+X-1..R].\n",
      "\n",
      "Wait, because in the original definition, the substring T is from position 1 to X-1 (which in the original string is from L to L+X-2) and the suffix is X to M (which is L+X-1 to R).\n",
      "\n",
      "Wait, T is the substring S[L..R]. Let's say the length of T is M = R-L+1. Then X can be from 1 to M. The prefix is T[1..X-1], which is S[L..L+X-2] (since T's positions are 1-based). The suffix is T[X..M], which is S[L+X-1..R].\n",
      "\n",
      "So for each possible substring (L, R), we need to check if there's any X such that the count of 4s in prefix is equal to the count of 7s in suffix.\n",
      "\n",
      "But how can we compute this efficiently?\n",
      "\n",
      "Let's try to model this. Let's denote:\n",
      "\n",
      "For the substring S[L..R], the total 4s in the entire substring is total_4. The total 7s is total_7 = (R-L+1) - total_4.\n",
      "\n",
      "But for the split X, the prefix (before X) has A 4s, and the suffix (from X onwards) has B 7s. The condition is A = B.\n",
      "\n",
      "But the total 4s in the substring is A + (number of 4s in suffix). Because the prefix is up to X-1, and the suffix includes X. So the 4s in the suffix would be total_4 - A. Similarly, the 7s in the suffix would be (total_7) - (number of 7s in the prefix) + (number of 7s in the suffix). Wait, maybe it's easier to model the suffix's 7s.\n",
      "\n",
      "Wait the suffix from X to M (T's X to M) is S[L+X-1..R]. The number of 7s in the suffix is equal to the total number of 7s in the substring T minus the number of 7s in the prefix (since the prefix is from 1 to X-1, which is S[L..L+X-2], which is part of the substring T).\n",
      "\n",
      "Wait, maybe for the substring S[L..R], let's precompute the prefix sums of 4s and 7s.\n",
      "\n",
      "Let me think of the prefix sum arrays for the entire original string. Let's precompute for the entire string S:\n",
      "\n",
      "- For each position i, count_4[i] is the number of 4s in S[1..i].\n",
      "Similarly for count_7[i].\n",
      "\n",
      "Then, for a substring L..R, the total 4s is count_4[R] - count_4[L-1], and similarly for 7s.\n",
      "\n",
      "For the split X in the substring (which is X in 1..M, where M = R-L+1), the prefix of the substring (positions 1 to X-1) corresponds to S[L..L+X-2]. The number of 4s in this prefix is count_4[L+X-2] - count_4[L-1], but only if L+X-2 >= L. Otherwise, if X-1 is 0, then it's 0.\n",
      "\n",
      "Similarly, the suffix of the substring is positions X to M, which is S[L+X-1..R]. The number of 7s here is count_7[R] - count_7[L+X-1 - 1] (since L+X-1 is the start of the suffix, so subtract up to L+X-2). So that's count_7[R] - count_7[L+X-1 -1] = count_7[R] - count_7[L+X-2].\n",
      "\n",
      "So the condition is:\n",
      "\n",
      "(count_4[L+X-2] - count_4[L-1]) = (count_7[R] - count_7[L+X-2])\n",
      "\n",
      "We can rearrange this equation:\n",
      "\n",
      "count_4[L+X-2] - count_4[L-1] = count_7[R] - count_7[L+X-2]\n",
      "\n",
      "Rearranging terms:\n",
      "\n",
      "count_4[L+X-2] + count_7[L+X-2] = count_4[L-1] + count_7[R]\n",
      "\n",
      "But count_4[L+X-2] + count_7[L+X-2] is equal to (L+X-2) because every position is either 4 or 7. So the left side is (L+X-2). The right side is (count_4[L-1] + count_7[R]).\n",
      "\n",
      "So the equation becomes:\n",
      "\n",
      "L + X - 2 = count_4[L-1] + count_7[R]\n",
      "\n",
      "Let's solve for X:\n",
      "\n",
      "X = count_4[L-1] + count_7[R] - L + 2\n",
      "\n",
      "But X must be in 1..M, where M = R-L+1.\n",
      "\n",
      "So substituting M:\n",
      "\n",
      "X must satisfy 1 ≤ X ≤ R-L+1.\n",
      "\n",
      "So substituting X into that inequality:\n",
      "\n",
      "1 ≤ (count_4[L-1] + count_7[R] - L + 2) ≤ R-L+1.\n",
      "\n",
      "Let me rearrange the equation:\n",
      "\n",
      "X = (count_4[L-1] + count_7[R] ) - (L - 2)\n",
      "\n",
      "So X = (count_4[L-1] + count_7[R] ) - L + 2.\n",
      "\n",
      "Wait, no. Because X is equal to (count_4[L-1] + count_7[R] ) - L + 2?\n",
      "\n",
      "Wait, let me recheck:\n",
      "\n",
      "Original equation after rearrangement:\n",
      "\n",
      "L + X -2 = count_4[L-1] + count_7[R]\n",
      "\n",
      "So X = (count_4[L-1] + count_7[R]) - L + 2.\n",
      "\n",
      "Yes.\n",
      "\n",
      "So X = (count_4[L-1] + count_7[R] ) - L + 2.\n",
      "\n",
      "So for X to be valid, X must be between 1 and R-L+1, inclusive.\n",
      "\n",
      "So substituting:\n",
      "\n",
      "1 ≤ X ≤ R-L+1.\n",
      "\n",
      "But X is expressed in terms of L and R. So for a given L and R, we can compute X. Then check if X is in the allowed range, and also check if the original condition holds (since this equation is derived from the condition, but perhaps X could be such that L+X-2 is beyond the allowed indices. Wait no, because X is part of the substring, so X can be up to R-L+1. So L+X-2 can be up to L + (R-L+1) -2 = R -1. Which is within the substring's prefix (since the substring is L..R, so up to R-1).\n",
      "\n",
      "Wait, the prefix is T[1..X-1], which is S[L..L+X-2], because T is the substring S[L..R]. So for X to be 1, X-1 is 0, so the prefix is empty. For X being M, the prefix is up to M-1, which is R- L+1 -1 = R - L. So S[L..R-1].\n",
      "\n",
      "So for each (L, R), compute X as (count_4[L-1] + count_7[R]) - L + 2. Then check if X is in 1 <= X <= M (where M = R-L+1). If yes, then check if the original condition holds (the number of 4s in the prefix equals the number of 7s in the suffix). But since the equation was derived from the condition, perhaps if X is in the valid range, then the condition holds. So perhaps once X is in the valid range, then (L, R) is counted as a valid substring.\n",
      "\n",
      "Wait, but how?\n",
      "\n",
      "Because when we derived X from the equation, that equation must hold. So if X is in the valid range, then the equation holds, which is equivalent to the original condition. So perhaps for each (L, R), if the computed X is in the valid range, then the substring is balanced.\n",
      "\n",
      "But why?\n",
      "\n",
      "Let me think again. Suppose we have a substring L..R, and compute X as (count_4[L-1] + count_7[R] ) - L + 2. Then X must be in 1 <= X <= R-L+1. Then substituting into the equation L + X -2 = count_4[L-1] + count_7[R], which came from the original condition. So if X is valid (in the range), then the equation holds, which implies the original condition. Therefore, (L, R) is a balanced substring.\n",
      "\n",
      "So the algorithm becomes: for each possible substring (L, R), compute X using the formula. Check if X is in [1, M], where M=R-L+1. If yes, then count this substring.\n",
      "\n",
      "So the problem reduces to finding all (L, R) pairs where X (as computed) is in the valid range. But how do we compute this efficiently?\n",
      "\n",
      "But even this approach would require checking O(n^2) substrings, which is not feasible for n=1e5. So we need a way to compute the number of (L, R) pairs such that X is in the valid range.\n",
      "\n",
      "Alternatively, perhaps we can find for each possible X (in the entire string) and see which (L, R) pairs have a split at X.\n",
      "\n",
      "Wait, maybe there's a way to model this with some mathematical expressions and precompute the counts.\n",
      "\n",
      "Let me try to model X as (count_4[L-1] + count_7[R]) - L + 2. We need X to be between 1 and M, which is (R-L+1).\n",
      "\n",
      "So substituting M:\n",
      "\n",
      "1 <= X <= R-L+1.\n",
      "\n",
      "But X = (count_4[L-1] + count_7[R]) - L + 2.\n",
      "\n",
      "So:\n",
      "\n",
      "1 <= (count_4[L-1] + count_7[R]) - L + 2 <= R - L +1.\n",
      "\n",
      "Let me subtract 2 from all parts:\n",
      "\n",
      "-1 <= (count_4[L-1] + count_7[R]) - L <= R - L -1.\n",
      "\n",
      "Rearranging:\n",
      "\n",
      "(count_4[L-1] + count_7[R]) - L >= -1.\n",
      "\n",
      "and\n",
      "\n",
      "(count_4[L-1] + count_7[R]) - L <= R - L -1.\n",
      "\n",
      "The second inequality can be rewritten as:\n",
      "\n",
      "count_4[L-1] + count_7[R] <= R - L -1 + L = R -1.\n",
      "\n",
      "So:\n",
      "\n",
      "count_4[L-1] + count_7[R] <= R -1.\n",
      "\n",
      "But I'm not sure if that's helpful.\n",
      "\n",
      "Alternatively, perhaps we can express X in terms of L and R.\n",
      "\n",
      "Another approach: For a given L, can we find all R such that when we compute X, it is within the required range for (L, R)?\n",
      "\n",
      "But how?\n",
      "\n",
      "Alternatively, for a fixed X (the split point in the substring), perhaps we can find L and R that satisfy certain conditions.\n",
      "\n",
      "Alternatively, perhaps we can model the problem by considering that for each possible split point in the original string (i.e., each position k between 1 and N), find all substrings that include k as the X-th position in their own substring. But I'm not sure.\n",
      "\n",
      "Alternatively, let's think of the split in the substring T (L..R) as being at position X. Then, the split in the original string would be at position L + X -1. Let's denote this position as K = L + X -1.\n",
      "\n",
      "For the condition to hold, the number of 4s in S[L..K-1] (the prefix of T) must equal the number of 7s in S[K..R] (the suffix of T).\n",
      "\n",
      "Let me denote:\n",
      "\n",
      "A = number of 4s in S[L..K-1] = count_4[K-1] - count_4[L-1]\n",
      "\n",
      "B = number of 7s in S[K..R] = count_7[R] - count_7[K-1]\n",
      "\n",
      "So A = B.\n",
      "\n",
      "So we have:\n",
      "\n",
      "count_4[K-1] - count_4[L-1] = count_7[R] - count_7[K-1]\n",
      "\n",
      "Rearranged:\n",
      "\n",
      "count_4[K-1] + count_7[K-1] = count_4[L-1] + count_7[R]\n",
      "\n",
      "But as before, count_4[K-1] + count_7[K-1] = (K-1) - since each position is either 4 or 7, the sum of 4s and 7s up to K-1 is K-1.\n",
      "\n",
      "So K-1 = count_4[L-1] + count_7[R]\n",
      "\n",
      "So K = count_4[L-1] + count_7[R] + 1.\n",
      "\n",
      "But K is also equal to L + X -1. Wait, K is the position in the original string where the split occurs. So for a substring starting at L and ending at R, K must be between L and R (since X is between 1 and M=R-L+1, so K ranges from L+0 to L + (M-1) = R).\n",
      "\n",
      "So substituting K:\n",
      "\n",
      "L + X -1 = count_4[L-1] + count_7[R] + 1.\n",
      "\n",
      "Wait, no, previous step:\n",
      "\n",
      "We have K = count_4[L-1] + count_7[R] + 1.\n",
      "\n",
      "But K must also be in [L, R], because X is between 1 and M, so K is between L and R.\n",
      "\n",
      "So, for a given L and R, if there exists a K in [L, R] such that K = count_4[L-1] + count_7[R] + 1, then the substring (L, R) is balanced.\n",
      "\n",
      "But K has to be between L and R. So for each (L, R), compute K = count_4[L-1] + count_7[R] + 1. If K is between L and R, then (L, R) is a valid substring.\n",
      "\n",
      "Wait, but this seems like a different approach. Because now, for each (L, R), we can compute K and check if it's in the range [L, R]. If yes, then the substring is balanced.\n",
      "\n",
      "So the problem reduces to counting the number of pairs (L, R) where L <= R, and K = count_4[L-1] + count_7[R] + 1 is in [L, R].\n",
      "\n",
      "This seems manageable. Because for each L and R, we can compute K and check if L <= K <= R.\n",
      "\n",
      "But again, for n=1e5, checking all O(n^2) pairs is impossible. So we need a smarter way.\n",
      "\n",
      "Let's think of variables. Let's precompute the count_4 and count_7 arrays.\n",
      "\n",
      "Then, for each possible R, we can iterate through all possible L's such that K = count_4[L-1] + count_7[R] +1 is between L and R.\n",
      "\n",
      "Alternatively, for each R, find all L's where L <= K <= R, where K = count_4[L-1] + count_7[R] +1.\n",
      "\n",
      "But even that is O(n^2) if not optimized.\n",
      "\n",
      "Alternatively, for each R, perhaps we can model the equation K = count_4[L-1] + count_7[R] +1 and find L's such that L <= K <= R.\n",
      "\n",
      "But K is a function of L and R. Let's see:\n",
      "\n",
      "We can write K = (count_4[L-1] ) + (count_7[R] +1)\n",
      "\n",
      "Let's denote for a fixed R, count_7[R] is known. Let C = count_7[R] +1.\n",
      "\n",
      "Then K = C + count_4[L-1].\n",
      "\n",
      "But K must be between L and R.\n",
      "\n",
      "So for fixed R and C, the equation becomes:\n",
      "\n",
      "L <= C + count_4[L-1] <= R.\n",
      "\n",
      "But L is the variable here. For each L (from 1 to R), we can compute count_4[L-1], then compute K, and check if it's between L and R.\n",
      "\n",
      "But even for a fixed R, checking all L is O(R) which is O(n) per R, leading to O(n^2) total time. Not feasible.\n",
      "\n",
      "Hmm. So we need a way to find, for each R, the number of L's such that:\n",
      "\n",
      "L <= C + count_4[L-1] <= R, where C is count_7[R] +1.\n",
      "\n",
      "But how to find such L's efficiently.\n",
      "\n",
      "Let me reorganize the inequalities.\n",
      "\n",
      "First, the lower bound: C + count_4[L-1] >= L.\n",
      "\n",
      "Rearranged: count_4[L-1] >= L - C.\n",
      "\n",
      "Second, the upper bound: C + count_4[L-1] <= R.\n",
      "\n",
      "Rearranged: count_4[L-1] <= R - C.\n",
      "\n",
      "So for a fixed R and C, the L's must satisfy:\n",
      "\n",
      "L - C <= count_4[L-1] <= R - C.\n",
      "\n",
      "But L varies from 1 to R. So for each L, compute count_4[L-1] and check if it's within [L - C, R - C].\n",
      "\n",
      "But how to find all L's such that this is true?\n",
      "\n",
      "Alternatively, for each R, we can compute C = count_7[R] + 1. Then, for all possible L, we need count_4[L-1] to be in [L - C, R - C], and also L must be <= R.\n",
      "\n",
      "Wait, but count_4[L-1] can be precomputed. For example, for L=1, count_4[0] is 0. For L=2, count_4[1] is the number of 4s in the first character. So for each R, we can iterate L from 1 to R and check the conditions. But that's O(n^2) again.\n",
      "\n",
      "We need a smarter way. Let's think of possible data structures or pre-processing.\n",
      "\n",
      "Suppose we have the count_4 array. For each R, C is known. Then for each L, we need:\n",
      "\n",
      "count_4[L-1] >= L - C\n",
      "\n",
      "and\n",
      "\n",
      "count_4[L-1] <= R - C.\n",
      "\n",
      "But how to find the number of L's (1 <= L <= R) that satisfy both.\n",
      "\n",
      "The key observation is that for each R, C is fixed. So for each R, we can compute the range [A, B] where A = L - C and B = R - C, and count_4[L-1] must be between A and B.\n",
      "\n",
      "But L is part of the variable here. So for each possible L, we can precompute for all R, but that's not helpful.\n",
      "\n",
      "Alternatively, perhaps for each R, we can model this as:\n",
      "\n",
      "For L in 1..R, check if count_4[L-1] - (L-1) >= (L - C) - (L-1) = 1 - C.\n",
      "\n",
      "But I'm not sure.\n",
      "\n",
      "Alternatively, let's consider that for each L, the value count_4[L-1] is known.\n",
      "\n",
      "Let me define for each index i (0-based?), the value of count_4[i] which is the number of 4s in the first i characters (assuming 0-based). So for example, count_4[0] is 0 (since there are no characters before 0), count_4[1] is 1 if S[0] is '4', else 0, etc.\n",
      "\n",
      "Then, for a given R (1-based in the original string?), count_7[R] is the number of 7s up to R. Then C = count_7[R] +1.\n",
      "\n",
      "Now, for each possible L (1-based), which is in 1..R, the conditions are:\n",
      "\n",
      "count_4[L-1] >= L - C\n",
      "\n",
      "count_4[L-1] <= R - C\n",
      "\n",
      "But L is in 1..R.\n",
      "\n",
      "So for each R, we need to find the number of L in 1..R where count_4[L-1] is in [L - C, R - C].\n",
      "\n",
      "But how?\n",
      "\n",
      "Let me think of this as for each R, we can compute C, then for each possible L in 1..R, check if count_4[L-1] is between (L - C) and (R - C). The number of such L is the contribution to the answer for this R.\n",
      "\n",
      "So for each R, the total is the sum over L=1 to R of 1 if (count_4[L-1] >= L - C) and (count_4[L-1] <= R - C).\n",
      "\n",
      "But even this approach is O(n^2), which is not feasible.\n",
      "\n",
      "We need a way to compute, for each R, the number of L's where count_4[L-1] is in the interval [L-C, R-C], and L is <= R.\n",
      "\n",
      "But how to model this.\n",
      "\n",
      "Let's consider that for a fixed C, and R, we can represent the problem as:\n",
      "\n",
      "For each L in 1..R, check if count_4[L-1] is in [L - C, R - C].\n",
      "\n",
      "Let me make a substitution. Let D = L - C. Then the condition is count_4[L-1] >= D and count_4[L-1] <= R - C.\n",
      "\n",
      "But D = L - C → L = D + C.\n",
      "\n",
      "Since L ranges from 1 to R, D ranges from 1 - C to R - C.\n",
      "\n",
      "But this substitution might not help.\n",
      "\n",
      "Alternatively, for each R, the range R - C is fixed. So the upper bound is R - C.\n",
      "\n",
      "The lower bound is L - C, which depends on L.\n",
      "\n",
      "But this seems tricky. How can we find all L where count_4[L-1] >= L - C and count_4[L-1] <= (R - C).\n",
      "\n",
      "Another way: For a given R and C, the upper bound is fixed (R-C). The lower bound for L is L - C. So for count_4[L-1] to be >= L - C → count_4[L-1] + C >= L.\n",
      "\n",
      "But count_4[L-1] is known. So for each L, this is a condition.\n",
      "\n",
      "Wait, count_4[L-1] + C >= L → C >= L - count_4[L-1].\n",
      "\n",
      "But C is count_7[R] + 1, which is fixed for this R.\n",
      "\n",
      "So for a fixed R, the condition is:\n",
      "\n",
      "count_4[L-1] >= L - C → C >= L - count_4[L-1].\n",
      "\n",
      "But C is a constant here. So for each L, compute (L - count_4[L-1]) and check if C >= that value.\n",
      "\n",
      "Similarly, the upper bound is count_4[L-1] <= R - C → count_4[L-1] + C <= R → which is always true because C is count_7[R] + 1. Since count_4[L-1] + count_7[L-1] = L-1. So count_4[L-1] + C = (L-1 - count_7[L-1]) + (count_7[R] + 1) = L + (count_7[R] - count_7[L-1]).\n",
      "\n",
      "But how does this relate to R? For L <= R, count_7[R] >= count_7[L-1], so (count_7[R] - count_7[L-1]) >=0. So count_4[L-1] + C = L + (count_7[R] - count_7[L-1]) -1 + 1 → ?\n",
      "\n",
      "Wait, perhaps this isn't helpful.\n",
      "\n",
      "Alternative approach: Let's consider that for each possible L, we can precompute count_4[L-1] and compute for all R >= L, whether the condition holds. But this again leads to O(n^2).\n",
      "\n",
      "Hmm. Maybe there's a way to model this with some mathematical transformations.\n",
      "\n",
      "Wait, let's think again about the two conditions:\n",
      "\n",
      "For a fixed R and C = count_7[R] +1:\n",
      "\n",
      "1. count_4[L-1] >= L - C\n",
      "2. count_4[L-1] <= R - C\n",
      "\n",
      "But L can be up to R.\n",
      "\n",
      "Let me define for each L, the value of count_4[L-1] - L. Let's call this V_L.\n",
      "\n",
      "Then, condition 1 becomes V_L >= -C.\n",
      "\n",
      "Condition 2 becomes V_L <= (R - C) - L.\n",
      "\n",
      "But R is fixed here. Hmm.\n",
      "\n",
      "Alternatively, condition 1 can be rewritten as:\n",
      "\n",
      "V_L = count_4[L-1] - L >= -C.\n",
      "\n",
      "So V_L >= -C.\n",
      "\n",
      "And condition 2:\n",
      "\n",
      "count_4[L-1] <= R - C → V_L <= (R - C) - L → V_L + L <= R - C → V_L <= (R - C) - L.\n",
      "\n",
      "But (R - C) is fixed for a given R. So for each L, this becomes:\n",
      "\n",
      "V_L <= (R - C) - L.\n",
      "\n",
      "But I'm not sure.\n",
      "\n",
      "Another idea: For each possible L, the value of count_4[L-1] is fixed. So for each L, we can precompute count_4[L-1], and then for a given R and C, we can check if L satisfies the conditions.\n",
      "\n",
      "But again, this is O(n^2).\n",
      "\n",
      "We need to find for each R, the number of L's (<=R) such that count_4[L-1] is in [L - C, R - C], where C = count_7[R] +1.\n",
      "\n",
      "But how to compute this for all R efficiently.\n",
      "\n",
      "Another observation: For a substring (L, R) to be balanced, there must exist an X in 1..M such that the split at X satisfies the condition. But maybe there's a way to model this for each possible split in the entire string.\n",
      "\n",
      "Alternatively, let's consider that for each position K in the string (1 <= K <= N), we can find all substrings (L, R) where K is the split point (i.e., K = L + X -1, and X is within 1..R-L+1). For each K, the condition is:\n",
      "\n",
      "count_4[K-1] - count_4[L-1] = count_7[R] - count_7[K-1]\n",
      "\n",
      "Rearranged:\n",
      "\n",
      "count_4[K-1] + count_7[K-1] = count_4[L-1] + count_7[R]\n",
      "\n",
      "But count_4[K-1] + count_7[K-1] = K-1 (since each character is either 4 or 7). So:\n",
      "\n",
      "K-1 = count_4[L-1] + count_7[R]\n",
      "\n",
      "So for a given K, L and R must satisfy:\n",
      "\n",
      "count_4[L-1] + count_7[R] = K-1.\n",
      "\n",
      "Additionally, K must be between L and R. Because K is the split point in the substring (L..R), so K >= L and K <= R.\n",
      "\n",
      "So for each K, we need to find the number of pairs (L, R) such that:\n",
      "\n",
      "1. count_4[L-1] + count_7[R] = K-1.\n",
      "\n",
      "2. L <= K <= R.\n",
      "\n",
      "So the problem now is to, for each K, find the number of (L, R) pairs satisfying these two conditions, then sum over all K.\n",
      "\n",
      "This seems promising. Because for each K, we can precompute all possible L and R pairs that satisfy the equation and the inequalities.\n",
      "\n",
      "But how?\n",
      "\n",
      "Let me think. For a fixed K, the equation is count_4[L-1] + count_7[R] = K-1.\n",
      "\n",
      "We need L <= K <= R.\n",
      "\n",
      "So for each K, we can iterate over all possible R >= K, and compute the required L based on R. Or vice versa.\n",
      "\n",
      "Alternatively, for each K, iterate over R >= K, and compute the required count_4[L-1] = (K-1) - count_7[R], then find how many L's <= K such that count_4[L-1] equals that value and L <= K.\n",
      "\n",
      "Wait, because L must be <= K (since K >= L).\n",
      "\n",
      "So for a fixed K and R (>= K), the required L-1 is such that count_4[L-1] = (K-1) - count_7[R]. \n",
      "\n",
      "Then, L-1 can be any index from 0 to K-1 (since L <= K → L-1 <= K-1). So for each R >= K, the number of valid L's is the number of L-1's (which are 0-based indices) where count_4[L-1] equals (K-1 - count_7[R]).\n",
      "\n",
      "But this would require for each K, and each R >= K, to find the frequency of (K-1 - count_7[R]) in the count_4 array up to index K-1 (0-based). \n",
      "\n",
      "This approach would be O(n^2) in the worst case, but maybe we can preprocess some frequency tables.\n",
      "\n",
      "For example, for each K, precompute a frequency map of count_4[0...K-1]. Then for each R >= K, compute the target value (K-1 - count_7[R]) and look up how many times this target appears in the count_4 array up to K-1.\n",
      "\n",
      "But this is O(n^2) time and space, which is not feasible.\n",
      "\n",
      "But perhaps we can find for each K, the possible R's and for each R, compute the target and use a hash map or a precomputed array.\n",
      "\n",
      "Alternatively, for each possible value of (count_7[R], K), precompute the number of L's.\n",
      "\n",
      "Alternatively, let's think of the following steps:\n",
      "\n",
      "1. Precompute count_4 and count_7 arrays.\n",
      "\n",
      "2. For each K from 1 to N:\n",
      "\n",
      "   a. The required equation is count_4[L-1] + count_7[R] = K-1.\n",
      "\n",
      "   b. For R to be >= K, and L must be <= K.\n",
      "\n",
      "   c. For each R >= K, compute target = (K-1) - count_7[R].\n",
      "\n",
      "   d. The number of valid L's is the number of times count_4[L-1] equals target, where L-1 ranges from 0 to K-1-1 (since L-1 <= K-1-1 implies L <= K).\n",
      "\n",
      "   So for each R >= K, the valid L's are those with count_4[L-1] = target and L-1 <= K-1-1 → L-1 <= K-2 → L <= K-1.\n",
      "\n",
      "Wait, L must be <= K (since L <= K). So L can be up to K.\n",
      "\n",
      "Wait, L is the start of the substring, and K must be in [L, R]. So L can be from 1 to K.\n",
      "\n",
      "So for a fixed K and R >= K:\n",
      "\n",
      "The valid L's are those where:\n",
      "\n",
      "count_4[L-1] = (K-1) - count_7[R]\n",
      "\n",
      "and L <= K.\n",
      "\n",
      "L-1 can range from 0 to K-1.\n",
      "\n",
      "So for each K, the count_4 array up to K-1 (0-based) can be preprocessed with a frequency map. For example, for each K, we can have a dictionary that maps the value of count_4[i] (for i up to K-1) to the number of times it occurs.\n",
      "\n",
      "Then, for each R >= K, the target is (K-1) - count_7[R], and the number of L's is the frequency of that target in the frequency map of K.\n",
      "\n",
      "The total for K is the sum over R >= K of the frequency of (K-1 - count_7[R]) in the map for K.\n",
      "\n",
      "But building frequency maps for each K is O(n) per K, which is O(n^2) time and space, which is not feasible.\n",
      "\n",
      "Alternative idea: For each possible value of target, precompute a prefix sum array that tracks the occurrences of target in the count_4 array up to each position.\n",
      "\n",
      "For example, for each value x, create an array pos_x, which contains all indices i where count_4[i] == x. Then, for a given K and target x, the number of valid L-1's (which are <= K-1) is the number of elements in pos_x that are <= K-1.\n",
      "\n",
      "But how to do this efficiently.\n",
      "\n",
      "Alternatively, for each x, we can keep a sorted list of the indices where count_4[i] == x. Then, for a query x and K, the number of valid L-1's is the number of elements in the list for x that are <= K-1. This can be found via binary search.\n",
      "\n",
      "This way, for each K and R, we can compute the target x = (K-1) - count_7[R], then find how many times x occurs in count_4 up to position K-1.\n",
      "\n",
      "So the steps would be:\n",
      "\n",
      "1. Precompute count_4 and count_7 arrays.\n",
      "\n",
      "2. For each x, build a sorted list of indices where count_4[i] == x. For example, a dictionary where the key is x and the value is a list of i's (0-based) where count_4[i] equals x.\n",
      "\n",
      "3. For each K from 1 to N:\n",
      "\n",
      "   a. For each R >= K:\n",
      "\n",
      "      i. Compute x = (K-1) - count_7[R]\n",
      "\n",
      "      ii. Find how many indices i in the list for x where i <= K-1. This is the number of valid L's for this R and K.\n",
      "\n",
      "      iii. Add this count to the total.\n",
      "\n",
      "But this is still O(n^2), which is not feasible.\n",
      "\n",
      "Hmm. But perhaps there's a way to find, for each K, all R >= K where x = (K-1) - count_7[R] exists in the count_4 array up to K-1.\n",
      "\n",
      "But even so, how to sum over all R >= K.\n",
      "\n",
      "Alternative approach: For each K, iterate R from K to N, and for each R, compute x = (K-1) - count_7[R], then query how many times x appears in count_4 up to K-1. Sum all these counts.\n",
      "\n",
      "But for K from 1 to N, and R from K to N, this is O(n^2) time. Not feasible.\n",
      "\n",
      "So this approach is not efficient enough.\n",
      "\n",
      "Alternative idea: For each possible R, compute all K <= R such that count_4[L-1] = (K-1) - count_7[R], and L <= K.\n",
      "\n",
      "But I'm not sure.\n",
      "\n",
      "Another observation: Since K must be <= R and >= L, perhaps for each R, K can range from L to R. But this again brings us back to the same problem.\n",
      "\n",
      "Alternatively, perhaps for each R, we can find all possible K in 1..R, and for each K, compute x = (K-1) - count_7[R], and count the number of L's where count_4[L-1] = x and L <= K. Sum over K.\n",
      "\n",
      "But this is also O(n^2) time.\n",
      "\n",
      "Hmm. Maybe there's a mathematical way to model this. Let's think about the possible values of K and R.\n",
      "\n",
      "For a given R, K can be any value from 1 to R. For each K, the required x is (K-1) - count_7[R].\n",
      "\n",
      "We need to find the number of L's <= K such that count_4[L-1] = x.\n",
      "\n",
      "So for each R, the total contribution is the sum over K=1 to R of the number of L's <= K where count_4[L-1] = (K-1) - count_7[R].\n",
      "\n",
      "But even this is O(n^2) operations.\n",
      "\n",
      "Alternative idea: Let's precompute for each possible x, the positions where count_4[i] = x. Then, for each R and K, compute x = (K-1) - count_7[R], and find the number of i's <= K-1 where count_4[i] = x.\n",
      "\n",
      "This can be done using a binary search on the list of positions for x.\n",
      "\n",
      "But even this requires O(n^2) binary searches, which is O(n^2 log n) time, which is too slow for n=1e5.\n",
      "\n",
      "So, this approach is not feasible.\n",
      "\n",
      "We need to find a way to find, for each R, all K's such that x = (K-1) - count_7[R] is present in the count_4 array up to K-1.\n",
      "\n",
      "But I'm stuck here. Let's think of the problem from another angle.\n",
      "\n",
      "Alternative approach: Let's model the problem in terms of variables.\n",
      "\n",
      "For a substring (L, R), the condition is that there exists K in [L, R] such that count_4[K-1] - count_4[L-1] = count_7[R] - count_7[K-1].\n",
      "\n",
      "Rearranged:\n",
      "\n",
      "count_4[K-1] + count_7[K-1] = count_4[L-1] + count_7[R].\n",
      "\n",
      "But the left side is K-1. So:\n",
      "\n",
      "K-1 = count_4[L-1] + count_7[R].\n",
      "\n",
      "So for a substring (L, R) to be valid, there must exist a K between L and R such that K-1 = count_4[L-1] + count_7[R].\n",
      "\n",
      "But K must be in [L, R], so:\n",
      "\n",
      "L <= K <= R → L <= (count_4[L-1] + count_7[R] + 1) <= R.\n",
      "\n",
      "Rearranged:\n",
      "\n",
      "L <= count_4[L-1] + count_7[R] + 1 <= R.\n",
      "\n",
      "But this is the same as:\n",
      "\n",
      "L - count_4[L-1] -1 <= count_7[R] <= R - count_4[L-1] -1.\n",
      "\n",
      "But this seems complicated.\n",
      "\n",
      "But perhaps for each L, we can find the range of R's where this inequality holds.\n",
      "\n",
      "Let me try to fix L and see for which R's this is true.\n",
      "\n",
      "For a fixed L, we need R >= K → K = count_4[L-1] + count_7[R] +1.\n",
      "\n",
      "But R must be >= K → R >= count_4[L-1] + count_7[R] +1.\n",
      "\n",
      "Hmm, but R and count_7[R] are related, which makes this difficult.\n",
      "\n",
      "Alternative idea: For each L, let's precompute count_4[L-1] as a value. Let's call this a. Then, for R >= L, we need:\n",
      "\n",
      "a + count_7[R] +1 >= L → count_7[R] >= L - a -1.\n",
      "\n",
      "And R >= a + count_7[R] +1 → R - count_7[R] >= a +1.\n",
      "\n",
      "So for a fixed L and a, the conditions on R are:\n",
      "\n",
      "count_7[R] >= L - a -1.\n",
      "\n",
      "and\n",
      "\n",
      "R - count_7[R] >= a +1.\n",
      "\n",
      "But how to find such R's.\n",
      "\n",
      "But for each R, R - count_7[R] is known. Let's denote this as D[R] = R - count_7[R].\n",
      "\n",
      "So for a fixed L and a, the conditions are:\n",
      "\n",
      "count_7[R] >= C (where C = L - a -1).\n",
      "\n",
      "and\n",
      "\n",
      "D[R] >= a +1.\n",
      "\n",
      "But D[R] = R - count_7[R] = count_4[R], since count_4[R] + count_7[R] = R.\n",
      "\n",
      "Wait, because count_4[R] + count_7[R] = R (assuming 0-based index and S is 1-based? Or wait, count_4 is the number of 4s up to position i. For example, for a 1-based string S, count_4[i] is the number of 4s in S[1..i]. So count_4[i] + count_7[i] = i.\n",
      "\n",
      "So R - count_7[R] = count_4[R].\n",
      "\n",
      "So D[R] = count_4[R].\n",
      "\n",
      "So the conditions for R are:\n",
      "\n",
      "count_7[R] >= C → count_7[R] >= L - a -1.\n",
      "\n",
      "and\n",
      "\n",
      "count_4[R] >= a + 1.\n",
      "\n",
      "But a is count_4[L-1], so a = count_4[L-1].\n",
      "\n",
      "So the conditions become:\n",
      "\n",
      "count_7[R] >= L - count_4[L-1] -1.\n",
      "\n",
      "count_4[R] >= count_4[L-1] + 1.\n",
      "\n",
      "But how to find R's >= L that satisfy these conditions.\n",
      "\n",
      "For each L, we can compute C1 = L - count_4[L-1] -1.\n",
      "\n",
      "And C2 = count_4[L-1] + 1.\n",
      "\n",
      "Then, for R >= L, we need count_7[R] >= C1 and count_4[R] >= C2.\n",
      "\n",
      "But how to count the number of R >= L where these two conditions are met.\n",
      "\n",
      "This seems like a range query problem. If we can precompute for each R the count_7[R] and count_4[R], then for each L, we can query the number of R >= L where count_7[R] >= C1 and count_4[R] >= C2.\n",
      "\n",
      "But even this requires for each L to perform a query over the range [L, N], which could be O(n) per L, leading to O(n^2) total time.\n",
      "\n",
      "Which is not feasible.\n",
      "\n",
      "But perhaps we can preprocess some data structures to allow for efficient range queries.\n",
      "\n",
      "For example, we can build a 2D prefix sum array where for each R, we store count_4[R] and count_7[R]. Then, for a query [L, N], C1 and C2, we need the number of R >= L where count_7[R] >= C1 and count_4[R] >= C2.\n",
      "\n",
      "But such a query is not straightforward to answer with standard data structures. Possible options include a segment tree with each node storing a list of (count_4, count_7) for the range, sorted, and then for each query, we can perform a binary search. But this would have a high time complexity.\n",
      "\n",
      "Alternatively, for each possible R, precompute count_4[R] and count_7[R], and store them in two separate arrays. Then, for a given L, iterate R from L to N and check the conditions. But this is again O(n^2) time.\n",
      "\n",
      "This seems like a dead end.\n",
      "\n",
      "Another observation: The problem seems similar to the problem of finding pairs (i, j) where some function of i and j is true. Sometimes these can be solved with inclusion-exclusion or other mathematical tricks.\n",
      "\n",
      "Let's think again about the initial approach where X must be in [1, M] for the substring (L, R). And X is computed as X = count_4[L-1] + count_7[R] - L + 2.\n",
      "\n",
      "And the substring is valid if X is in [1, R-L+1].\n",
      "\n",
      "But substituting M = R-L+1, the condition is 1 <= X <= M.\n",
      "\n",
      "So substituting X into the inequalities:\n",
      "\n",
      "1 <= count_4[L-1] + count_7[R] - L + 2 <= R - L +1.\n",
      "\n",
      "Rearranging:\n",
      "\n",
      "1 <= (count_4[L-1] - L) + (count_7[R] + 2) <= R - L +1.\n",
      "\n",
      "But this might not help.\n",
      "\n",
      "Alternatively, the lower bound:\n",
      "\n",
      "count_4[L-1] + count_7[R] - L + 2 >= 1 → count_4[L-1] + count_7[R] >= L -1.\n",
      "\n",
      "The upper bound:\n",
      "\n",
      "count_4[L-1] + count_7[R] - L + 2 <= R - L +1 → count_4[L-1] + count_7[R] <= R - L +1 + L -2 → count_4[L-1] + count_7[R] <= R -1.\n",
      "\n",
      "So for a valid substring (L, R), the following must hold:\n",
      "\n",
      "L-1 <= count_4[L-1] + count_7[R] <= R-1.\n",
      "\n",
      "But how to count the number of (L, R) pairs that satisfy this.\n",
      "\n",
      "But this is a different way of looking at the condition. For each (L, R), we need the sum of count_4[L-1] and count_7[R] to be between L-1 and R-1, inclusive.\n",
      "\n",
      "So the problem reduces to counting the number of pairs (L, R) where 1 <= L <= R <= N, and L-1 <= count_4[L-1] + count_7[R] <= R-1.\n",
      "\n",
      "This is a new perspective. Let's see if this can be optimized.\n",
      "\n",
      "Let's precompute the count_4 and count_7 arrays.\n",
      "\n",
      "Then, for each possible pair (L, R), check if L-1 <= (count_4[L-1] + count_7[R]) <= R-1.\n",
      "\n",
      "But this is again O(n^2).\n",
      "\n",
      "But perhaps there's a way to model this as a 2D range query problem. For each L, we can find the number of R >= L such that count_7[R] is between (L-1 - count_4[L-1]) and (R-1 - count_4[L-1]).\n",
      "\n",
      "But the upper bound here is R-1 - count_4[L-1], which depends on R, making it difficult to model.\n",
      "\n",
      "Alternative approach: Let's consider that for each L, the lower bound is fixed (L-1 - count_4[L-1]), and the upper bound is R-1 - count_4[L-1]. But as R increases, the upper bound increases as well.\n",
      "\n",
      "For a fixed L, we need R >= L, and count_7[R] >= (L-1 - count_4[L-1]).\n",
      "\n",
      "Moreover, count_7[R] <= (R-1 - count_4[L-1]).\n",
      "\n",
      "But count_7[R] is the number of 7s up to R. So count_7[R] <= R.\n",
      "\n",
      "So for a fixed L, the valid R's must satisfy:\n",
      "\n",
      "count_7[R] >= (L-1 - count_4[L-1]) → count_7[R] >= C1 (C1 = L-1 - count_4[L-1])\n",
      "\n",
      "and \n",
      "\n",
      "count_7[R] <= (R-1 - count_4[L-1]) → count_7[R] + count_4[L-1] +1 <= R.\n",
      "\n",
      "But this is equivalent to:\n",
      "\n",
      "count_4[L-1] + count_7[R] +1 <= R → which is the same as the earlier condition.\n",
      "\n",
      "But I'm not sure.\n",
      "\n",
      "Alternatively, for a fixed L, the upper bound on count_7[R] is R-1 - count_4[L-1]. But R is varying. So for each R, this upper bound is R-1 - a (a = count_4[L-1]).\n",
      "\n",
      "So for each R, we need count_7[R] <= R-1 - a → count_7[R] + a <= R-1.\n",
      "\n",
      "But a = count_4[L-1], which is a fixed value for the current L.\n",
      "\n",
      "But count_4[L-1] + count_7[R] <= R-1 → count_4[L-1] <= R-1 - count_7[R] → which is count_4[L-1] <= count_4[R] (because count_4[R] + count_7[R] = R → count_4[R] = R - count_7[R] → R-1 - count_7[R] = count_4[R] -1).\n",
      "\n",
      "Wait, no. count_4[R] = R - count_7[R], so count_4[R] = R - count_7[R] → R-1 - count_7[R] = count_4[R] -1.\n",
      "\n",
      "So the condition becomes:\n",
      "\n",
      "count_4[L-1] <= count_4[R] -1 → count_4[L-1] < count_4[R].\n",
      "\n",
      "So for a fixed L, the upper bound is count_7[R] <= R-1 - a → which is equivalent to count_4[R] > a.\n",
      "\n",
      "So the condition for R is:\n",
      "\n",
      "count_7[R] >= C1 (C1 = L-1 - a)\n",
      "\n",
      "and\n",
      "\n",
      "count_4[R] > a.\n",
      "\n",
      "But how to count R's >= L that satisfy these two conditions.\n",
      "\n",
      "For each L, the valid R's are those >= L where:\n",
      "\n",
      "count_7[R] >= C1.\n",
      "\n",
      "and\n",
      "\n",
      "count_4[R] > a.\n",
      "\n",
      "But C1 is L-1 - a, and a is count_4[L-1].\n",
      "\n",
      "But a = count_4[L-1], so C1 = L-1 - count_4[L-1].\n",
      "\n",
      "But count_4[L-1] is the number of 4's up to L-1. So L-1 - count_4[L-1] is the number of 7's up to L-1. Because count_4[L-1] + count_7[L-1] = L-1 → count_7[L-1] = L-1 - count_4[L-1].\n",
      "\n",
      "So C1 = count_7[L-1].\n",
      "\n",
      "So the conditions for R are:\n",
      "\n",
      "count_7[R] >= count_7[L-1].\n",
      "\n",
      "count_4[R] > count_4[L-1].\n",
      "\n",
      "So for a fixed L, the valid R's are those >= L where count_7[R] is at least count_7[L-1] and count_4[R] is greater than count_4[L-1].\n",
      "\n",
      "Wait, this is a big insight.\n",
      "\n",
      "Because:\n",
      "\n",
      "C1 = L-1 - a = L-1 - count_4[L-1] = count_7[L-1].\n",
      "\n",
      "So for a fixed L, the valid R's must be >= L and satisfy:\n",
      "\n",
      "count_7[R] >= count_7[L-1].\n",
      "\n",
      "count_4[R] > count_4[L-1].\n",
      "\n",
      "But count_7[R] is non-decreasing, since adding more characters can only increase or keep the same count of 7's. Similarly, count_4[R] is non-decreasing.\n",
      "\n",
      "Wait, count_4 is the number of 4's up to R, so as R increases, count_4 can either increase by 1 (if the next character is 4) or stay the same (if it's 7). So count_4 is a non-decreasing function.\n",
      "\n",
      "Similarly, count_7 is also a non-decreasing function.\n",
      "\n",
      "So for a fixed L, count_7[L-1] is a value. Since count_7 is non-decreasing, for R >= L, count_7[R] >= count_7[L], but count_7[L] >= count_7[L-1] (since L >= L-1). So for R >= L, count_7[R] >= count_7[L-1] is automatically true. Because count_7 is non-decreasing, once R >= L, count_7[R] >= count_7[L-1] (since L >= L-1 +1 is not necessarily true. For example, L=1, R=1: count_7[1] >= count_7[0] (0) is true.)\n",
      "\n",
      "Wait, count_7 is non-decreasing, so for any R >= L-1, count_7[R] >= count_7[L-1]. So for R >= L, which is >= L-1, count_7[R] >= count_7[L-1]. So the first condition (count_7[R] >= count_7[L-1]) is always satisfied for R >= L.\n",
      "\n",
      "Thus, the first condition is automatically satisfied. So the only condition is that count_4[R] > count_4[L-1], and R >= L.\n",
      "\n",
      "So for a fixed L, the valid R's are those R >= L where count_4[R] > count_4[L-1].\n",
      "\n",
      "But count_4 is a non-decreasing array. So once count_4[R] > count_4[L-1], all R' >= R will also satisfy count_4[R'] > count_4[L-1].\n",
      "\n",
      "So for each L, the minimal R where count_4[R] > count_4[L-1] is some position, say R0. Then, all R >= R0 will be valid.\n",
      "\n",
      "Thus, for each L, the number of valid R's is (N - R0 + 1), where R0 is the smallest R >= L such that count_4[R] > count_4[L-1].\n",
      "\n",
      "If no such R0 exists (i.e., count_4[R] never exceeds count_4[L-1] for R >= L), then there are 0 valid R's.\n",
      "\n",
      "This is a key insight.\n",
      "\n",
      "So the problem reduces to for each L, find the minimal R >= L such that count_4[R] > count_4[L-1], and then the number of valid R's is max(0, N - R0 + 1).\n",
      "\n",
      "But how to compute R0 for each L efficiently.\n",
      "\n",
      "Since count_4 is a non-decreasing array, for each L, R0 can be found using binary search.\n",
      "\n",
      "For example, for each L, we can binary search in the range [L, N] to find the first R where count_4[R] > count_4[L-1]. Because count_4 is non-decreasing, the binary search can be applied.\n",
      "\n",
      "This would allow us to compute R0 in O(log n) per L, leading to O(n log n) time for all L's.\n",
      "\n",
      "Then, for each L, the number of valid R's is max(0, N - R0 + 1) if R0 exists, else 0.\n",
      "\n",
      "But how to handle the case where count_4[L-1] is equal to count_4[N]. In that case, there is no R >= L where count_4[R] > count_4[L-1], so the count is 0.\n",
      "\n",
      "So the algorithm is:\n",
      "\n",
      "1. Precompute count_4 array.\n",
      "\n",
      "2. For each L from 1 to N:\n",
      "\n",
      "   a. a = count_4[L-1].\n",
      "\n",
      "   b. Find the minimal R >= L where count_4[R] > a. Let's call this R0.\n",
      "\n",
      "   c. If R0 exists, the number of valid R's is N - R0 + 1.\n",
      "\n",
      "   d. Sum these counts for all L.\n",
      "\n",
      "But wait, why is this the case?\n",
      "\n",
      "Because for each L, the valid R's are those >= L and count_4[R] > a.\n",
      "\n",
      "Because count_4 is non-decreasing, once R0 is found, all R >= R0 will have count_4[R] > a.\n",
      "\n",
      "So the number of valid R's is the number of R's from R0 to N.\n",
      "\n",
      "Which is N - R0 + 1.\n",
      "\n",
      "But why is this the case?\n",
      "\n",
      "For example, if R0 is 5 and N is 10, then R can be 5,6,7,8,9,10 → 6 numbers → 10-5+1=6.\n",
      "\n",
      "Yes.\n",
      "\n",
      "So this approach would work.\n",
      "\n",
      "But then, the total number of valid pairs (L, R) is the sum over all L of (N - R0 + 1) if R0 exists.\n",
      "\n",
      "But why does this approach work? Because we have reduced the problem to the condition that for each L, R must be >= L and count_4[R] > count_4[L-1], which was derived from the original conditions.\n",
      "\n",
      "But wait, how does this relate to the original problem?\n",
      "\n",
      "The original problem requires that for a substring (L, R), there exists some X such that the split at X makes the 4s in the prefix equal to the 7s in the suffix. We derived that this is equivalent to the sum count_4[L-1] + count_7[R] = K-1, where K is in [L, R]. Then, after multiple steps, we found that the problem reduces to counting pairs (L, R) where count_4[R] > count_4[L-1], and R >= L.\n",
      "\n",
      "But why is that?\n",
      "\n",
      "Ah, because when count_4[R] > count_4[L-1], it implies that there exists K in [L, R] such that K-1 = count_4[L-1] + count_7[R], and K is in [L, R].\n",
      "\n",
      "But I'm not sure. So let's re-verify.\n",
      "\n",
      "Wait, the previous steps led us to the conclusion that for a pair (L, R) to be valid, the sum count_4[L-1] + count_7[R] must be between L-1 and R-1, and R >= L.\n",
      "\n",
      "But under the assumption that count_4 is non-decreasing and count_7 is non-decreasing, the first condition count_7[R] >= count_7[L-1] is always true. So the remaining condition is count_4[L-1] + count_7[R] <= R-1.\n",
      "\n",
      "But how does this relate to count_4[R] > count_4[L-1]?\n",
      "\n",
      "Because count_4[L-1] + count_7[R] <= R-1.\n",
      "\n",
      "But count_7[R] = R - count_4[R], since count_4[R] + count_7[R] = R.\n",
      "\n",
      "So substituting:\n",
      "\n",
      "count_4[L-1] + (R - count_4[R]) <= R-1.\n",
      "\n",
      "Rearranged:\n",
      "\n",
      "count_4[L-1] - count_4[R] <= -1 → count_4[R] >= count_4[L-1] + 1.\n",
      "\n",
      "So count_4[R] > count_4[L-1].\n",
      "\n",
      "Ah! So the condition count_4[L-1] + count_7[R] <= R-1 is equivalent to count_4[R] > count_4[L-1].\n",
      "\n",
      "Thus, the valid pairs (L, R) are those where R >= L and count_4[R] > count_4[L-1].\n",
      "\n",
      "So the entire problem reduces to counting the number of pairs (L, R) with L <= R and count_4[R] > count_4[L-1].\n",
      "\n",
      "This is a huge simplification.\n",
      "\n",
      "So the solution is to count the number of pairs (L, R) where L <= R and count_4[R] > count_4[L-1].\n",
      "\n",
      "This is a much easier problem.\n",
      "\n",
      "Because count_4 is a non-decreasing array, since each character is either a 4 or 7. Adding a 4 increases count_4 by 1, adding a 7 leaves it the same. So count_4 is a non-decreasing array.\n",
      "\n",
      "Thus, for each L, the R's >= L where count_4[R] > count_4[L-1] form a contiguous range from R0 to N.\n",
      "\n",
      "Thus, for each L, the number of valid R's is N - R0 + 1, where R0 is the smallest index >= L where count_4[R0] > count_4[L-1].\n",
      "\n",
      "If no such R0 exists (count_4 remains <= count_4[L-1] for all R >= L), then the count is 0.\n",
      "\n",
      "So the algorithm becomes:\n",
      "\n",
      "For each L in 1..N:\n",
      "\n",
      "- Find the smallest R >= L where count_4[R] > count_4[L-1].\n",
      "\n",
      "- If such R exists, add (N - R + 1) to the answer.\n",
      "\n",
      "This is correct because for each such R, all R' >= R will also satisfy count_4[R'] > count_4[L-1].\n",
      "\n",
      "Now, how to compute R0 efficiently.\n",
      "\n",
      "Since count_4 is non-decreasing, for each L, we can perform a binary search on the range [L, N] to find the first R where count_4[R] > count_4[L-1].\n",
      "\n",
      "This will take O(log n) per L, leading to O(n log n) time for all L's.\n",
      "\n",
      "So, the steps are:\n",
      "\n",
      "1. Precompute the count_4 array.\n",
      "\n",
      "2. For each L from 1 to N:\n",
      "\n",
      "   a. a = count_4[L-1]\n",
      "\n",
      "   b. Binary search in count_4 from index L to N to find the smallest R where count_4[R] > a.\n",
      "\n",
      "   c. If found, add (N - R + 1) to the answer.\n",
      "\n",
      "   d. Else, add 0.\n",
      "\n",
      "This approach should work.\n",
      "\n",
      "Let's test this against the sample inputs.\n",
      "\n",
      "Sample Input 1:\n",
      "\n",
      "4\n",
      "47\n",
      "74\n",
      "477\n",
      "4747477\n",
      "\n",
      "Sample Output:\n",
      "\n",
      "2\n",
      "2\n",
      "3\n",
      "23\n",
      "\n",
      "Let's take the first test case: input is \"47\".\n",
      "\n",
      "The string is \"4\", \"7\".\n",
      "\n",
      "count_4 array (0-based):\n",
      "\n",
      "count_4[0] = 1 (since first character is 4)\n",
      "\n",
      "count_4[1] = 1 (second is 7, so count remains 1)\n",
      "\n",
      "For L=1:\n",
      "\n",
      "count_4[L-1] = count_4[0] = 1.\n",
      "\n",
      "Find R >=1 where count_4[R] > 1.\n",
      "\n",
      "The count_4 array from index 1 to 1 is [1]. No elements >1. So no valid R's.\n",
      "\n",
      "So contribution is 0.\n",
      "\n",
      "For L=2:\n",
      "\n",
      "count_4[L-1] = count_4[1] = 1.\n",
      "\n",
      "Find R >=2 (which is 2). count_4[2-1] = count_4[1] = 1. So no R >=2 where count_4[R] >1. So contribution is 0.\n",
      "\n",
      "Wait, but according to the sample output, the first test case's answer is 2. But according to this approach, the answer would be 0. So something is wrong.\n",
      "\n",
      "Wait, this suggests a mistake in the reasoning.\n",
      "\n",
      "Ah! What's wrong here.\n",
      "\n",
      "Wait, the sample input 47 has output 2. The valid substrings are (1,1) and (1,2). So according to the approach, we need to see why these are counted.\n",
      "\n",
      "Let's see for the first test case:\n",
      "\n",
      "S = '47' → indexes 1 and 2 (1-based).\n",
      "\n",
      "count_4 is computed as:\n",
      "\n",
      "count_4[0] = 0 (since S is 1-based)\n",
      "\n",
      "count_4[1] = 1 (S[1] is '4').\n",
      "\n",
      "count_4[2] = 1 (S[2] is '7').\n",
      "\n",
      "So for L=1:\n",
      "\n",
      "count_4[L-1] = count_4[0] = 0.\n",
      "\n",
      "We need to find R >=1 where count_4[R] > 0.\n",
      "\n",
      "In the count_4 array from R=1 to 2:\n",
      "\n",
      "count_4[1] =1 >0 → yes. So R0 is 1.\n",
      "\n",
      "So contribution is N - R0 +1 = 2 -1 +1 = 2.\n",
      "\n",
      "So for L=1, we add 2.\n",
      "\n",
      "For L=2:\n",
      "\n",
      "count_4[1] =1. We look for R >=2 where count_4[R] >1. count_4[2] is 1, which is not >1. So contribution is 0.\n",
      "\n",
      "Total is 2 +0 = 2, which matches the sample.\n",
      "\n",
      "Ah, so the mistake was in the way the count_4 array is built. The count_4 array is 0-based, where count_4[0] is 0 (number of 4s up to 0 characters), count_4[1] is the number of 4s in S[1], count_4[2] is the number of 4s in S[1..2], etc.\n",
      "\n",
      "So in the previous example, for L=1, L-1 is 0, so count_4[0] is 0.\n",
      "\n",
      "Thus, the algorithm is correct.\n",
      "\n",
      "This explains why the first test case works.\n",
      "\n",
      "Another sample: input '74', output is 2.\n",
      "\n",
      "The string is '7', '4'.\n",
      "\n",
      "count_4 array:\n",
      "\n",
      "count_4[0] =0\n",
      "\n",
      "count_4[1] =0 (first character is 7)\n",
      "\n",
      "count_4[2] =1 (second character is4)\n",
      "\n",
      "For L=1:\n",
      "\n",
      "count_4[0] =0. We look for R >=1 where count_4[R] >0. The first such R is 2. So contribution is 2-2 +1=1.\n",
      "\n",
      "But wait, R0 is 2, so contribution is 2-2+1=1 (since N=2).\n",
      "\n",
      "So for L=1, the contribution is 1.\n",
      "\n",
      "For L=2:\n",
      "\n",
      "count_4[1] =0. Look for R >=2 where count_4[R] >0. R=2 has count_4=1>0. So contribution is 2-2+1=1.\n",
      "\n",
      "Total is 1+1=2, which matches the sample.\n",
      "\n",
      "So the approach works.\n",
      "\n",
      "Thus, the algorithm is correct.\n",
      "\n",
      "Now, the code.\n",
      "\n",
      "The code needs to:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "- Precompute count_4 array (0-based, length n+1), where count_4[i] is the number of 4s in the first i characters (assuming 1-based string).\n",
      "\n",
      "Wait, S is 1-based. So for a string of length n, count_4[0] =0.\n",
      "\n",
      "count_4[i] = count_4[i-1] + (1 if S[i] == '4' else 0).\n",
      "\n",
      "Then, for each L in 1..n:\n",
      "\n",
      "a = count_4[L-1]\n",
      "\n",
      "We need to find the minimal R >= L such that count_4[R] > a.\n",
      "\n",
      "If found, add (n - R +1) to the answer.\n",
      "\n",
      "Thus, the code can be structured as follows:\n",
      "\n",
      "Read T test cases.\n",
      "\n",
      "For each test case:\n",
      "\n",
      "   s = input string.\n",
      "\n",
      "   n = len(s)\n",
      "\n",
      "   count_4 = [0]*(n+1)\n",
      "\n",
      "   for i in range(1, n+1):\n",
      "\n",
      "      count_4[i] = count_4[i-1] + (1 if s[i-1] == '4' else 0)\n",
      "\n",
      "   ans =0\n",
      "\n",
      "   for L in range(1, n+1):\n",
      "\n",
      "      a = count_4[L-1]\n",
      "\n",
      "      # binary search for the smallest R >= L where count_4[R] > a.\n",
      "\n",
      "      # the search is in the range [L, n]\n",
      "\n",
      "      low = L\n",
      "\n",
      "      high = n\n",
      "\n",
      "      res = None\n",
      "\n",
      "      while low <= high:\n",
      "\n",
      "          mid = (low + high) // 2\n",
      "\n",
      "          if count_4[mid] > a:\n",
      "\n",
      "              res = mid\n",
      "\n",
      "              high = mid -1\n",
      "\n",
      "          else:\n",
      "\n",
      "              low = mid +1\n",
      "\n",
      "      if res is not None:\n",
      "\n",
      "          ans += (n - res +1)\n",
      "\n",
      "   print(ans)\n",
      "\n",
      "This should work.\n",
      "\n",
      "Testing this code on the first sample:\n",
      "\n",
      "Test case 1: '47'\n",
      "\n",
      "count_4 is [0, 1, 1].\n",
      "\n",
      "L=1:\n",
      "\n",
      "a = count_4[0] =0.\n",
      "\n",
      "We search for R>=1 where count_4[R] >0.\n",
      "\n",
      "In the array, count_4[1]=1>0. So mid is 1, which is found.\n",
      "\n",
      "res=1. ans += (2-1+1) =2.\n",
      "\n",
      "L=2:\n",
      "\n",
      "a=count_4[1]=1.\n",
      "\n",
      "Search R>=2 (n=2). count_4[2]=1, which is not >1. So no res. ans +=0.\n",
      "\n",
      "Total is 2. Correct.\n",
      "\n",
      "Test case 2: '74' → '7','4'.\n",
      "\n",
      "count_4 is [0,0,1].\n",
      "\n",
      "L=1:\n",
      "\n",
      "a=0.\n",
      "\n",
      "Search R>=1: count_4[1]=0 <=0 → search higher. mid=1.5→2.\n",
      "\n",
      "count_4[2] =1>0 → res=2. ans += (2-2+1)=1.\n",
      "\n",
      "L=2:\n",
      "\n",
      "a=0 (count_4[1] =0).\n",
      "\n",
      "search R>=2: count_4[2]=1>0 → res=2. ans +=1.\n",
      "\n",
      "Total is 2. Correct.\n",
      "\n",
      "Another sample input: '477' → output is3.\n",
      "\n",
      "Let's see:\n",
      "\n",
      "S is '4','7','7'.\n",
      "\n",
      "count_4 is [0,1,1,1].\n",
      "\n",
      "L=1:\n",
      "\n",
      "a=0. Find R >=1 where count_4[R] >0.\n",
      "\n",
      "The earliest is R=1. ans += 3-1+1=3.\n",
      "\n",
      "L=2:\n",
      "\n",
      "a=1. Find R >=2 where count_4[R]>1. But count_4[2]=1, count_4[3]=1. So no such R. contribution 0.\n",
      "\n",
      "L=3:\n",
      "\n",
      "a=1. Find R >=3. count_4[3]=1. No. contribution 0.\n",
      "\n",
      "L=4? No, L ranges up to n=3.\n",
      "\n",
      "Wait, for n=3, L ranges from 1 to 3.\n",
      "\n",
      "Wait, L=1:\n",
      "\n",
      "a=0. R0=1. Contribution 3-1+1=3.\n",
      "\n",
      "But sample output is 3. So why?\n",
      "\n",
      "Sample input '477' has output 3. According to the code, it would give 3 (from L=1) plus others?\n",
      "\n",
      "Wait, wait. Let's re-calculate:\n",
      "\n",
      "Test case 3: input is '477'.\n",
      "\n",
      "The code's count_4 array is:\n",
      "\n",
      "indexes 0,1,2,3.\n",
      "\n",
      "count_4[0] =0.\n",
      "\n",
      "count_4[1] =1 (s[0] is '4').\n",
      "\n",
      "count_4[2] =1 (s[1] is '7').\n",
      "\n",
      "count_4[3] =1 (s[2] is '7').\n",
      "\n",
      "L=1:\n",
      "\n",
      "a=0. search R >=1:\n",
      "\n",
      "count_4[1] =1>0 → R0=1. contribution 3-1+1=3.\n",
      "\n",
      "L=2:\n",
      "\n",
      "a=count_4[1] =1. Search R >=2. count_4[2] =1, count_4[3]=1. So no R where count_4[R] >1. contribution 0.\n",
      "\n",
      "L=3:\n",
      "\n",
      "a=count_4[2] =1. Search R >=3. count_4[3] =1 → no. contribution 0.\n",
      "\n",
      "Total ans=3. Which matches the sample.\n",
      "\n",
      "Yes.\n",
      "\n",
      "So the code works for this case.\n",
      "\n",
      "The fourth test case is more complex, but the code should handle it.\n",
      "\n",
      "Thus, the code is correct.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "import bisect\n",
      "\n",
      "def count_balanced_substrings(s):\n",
      "    n = len(s)\n",
      "    count_4 = [0] * (n + 1)\n",
      "    for i in range(1, n+1):\n",
      "        count_4[i] = count_4[i-1] + (1 if s[i-1] == '4' else 0)\n",
      "    ans = 0\n",
      "    for L in range(1, n+1):\n",
      "        a = count_4[L-1]\n",
      "        # Binary search for the smallest R >= L where count_4[R] > a\n",
      "        # The count_4 array is non-decreasing, so we can use bisect\n",
      "        # We need to search in the subarray count_4[L..n]\n",
      "        # Using bisect_right to find the first element > a\n",
      "        R = bisect.bisect_right(count_4, a, lo=L, hi=n+1)\n",
      "        if R <= n:\n",
      "            ans += (n - R + 1)\n",
      "    return ans\n",
      "\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    print(count_balanced_substrings(s))\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "interview\n",
      "import bisect\n",
      "\n",
      "def count_balanced_substrings(s):\n",
      "    n = len(s)\n",
      "    count_4 = [0] * (n + 1)\n",
      "    for i in range(1, n+1):\n",
      "        count_4[i] = count_4[i-1] + (1 if s[i-1] == '4' else 0)\n",
      "    ans = 0\n",
      "    for L in range(1, n+1):\n",
      "        a = count_4[L-1]\n",
      "        # Binary search for the smallest R >= L where count_4[R] > a\n",
      "        # The count_4 array is non-decreasing, so we can use bisect\n",
      "        # We need to search in the subarray count_4[L..n]\n",
      "        # Using bisect_right to find the first element > a\n",
      "        R = bisect.bisect_right(count_4, a, lo=L, hi=n+1)\n",
      "        if R <= n:\n",
      "            ans += (n - R + 1)\n",
      "    return ans\n",
      "\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    print(count_balanced_substrings(s))\n",
      "06aaff0ac61dca6506122cd03fa73ab0\n",
      "Given a string s. Can you make it a palindrome by deleting exactly one character? Note that size of the string after deletion would be one less than it was before.\n",
      "Input\n",
      "First line of the input contains a single integer T denoting number of test cases.\n",
      "For each test case, you are given a single line containing string  s. \n",
      "\n",
      "Output\n",
      "For each test case, print YES or NO depending on the answer of the problem. \n",
      "\n",
      "Constraints\n",
      "\n",
      " Example\n",
      "Input:\n",
      "4\n",
      "aaa\n",
      "abc\n",
      "abdbca\n",
      "abba\n",
      "\n",
      "Output:\n",
      "YES\n",
      "NO\n",
      "YES\n",
      "YES\n",
      "\n",
      "Explanation\n",
      "Example case 1. Delete any one 'a', resulting string is \"aa\" which is a palindrome.\n",
      "Example case 2. It is not possible to delete exactly one character and having a palindrome.\n",
      "Example case 3. Delete 'c', resulting string is \"abdba\" which is a palindrome. \n",
      "Example case 4. Delete 'b', resulting string is \"aba\" which is a palindrome.\n",
      "<think>\n",
      "Okay, I need to solve this problem where I have to determine if a given string can become a palindrome by deleting exactly one character. Let's think about how to approach this.\n",
      "\n",
      "First, I remember that a palindrome reads the same forwards and backwards. So the basic idea is that if the string is already a palindrome, but maybe even then we need to check if removing one character (which would be possible, but wait, the original string's length might be even or odd. For example, if the original string is a palindrome and has even length, then removing one character would make it odd, but maybe not a palindrome. Wait, no. Wait, the problem says to delete exactly one character, and then check if the resulting string is a palindrome. So even if the original is a palindrome, if after deleting any one character, it's no longer a palindrome, then the answer would be no. Wait, but in the sample input, the fourth test case is \"abba\", which is a palindrome. The output is YES. Because deleting one 'b' gives \"aba\", which is also a palindrome. So even if the original is a palindrome, but the length is even, like 4, after deleting one character, it's 3. So \"abba\" becomes \"aba\" when you delete the second 'b', which is a palindrome. So in that case, the answer is yes.\n",
      "\n",
      "Wait, but how to handle the case when the original string is a palindrome. For example, if the original string is \"aaa\", then deleting any one 'a' gives \"aa\", which is a palindrome. So output is YES.\n",
      "\n",
      "So the approach is: For each test case, check if there exists a position i such that by deleting the character at position i, the resulting string is a palindrome.\n",
      "\n",
      "But checking this for every possible position (each character deletion) might be O(n^2) for each test case, which should be acceptable given the constraints, but maybe there's a smarter way.\n",
      "\n",
      "The constraints weren't given in the problem statement, but assuming that the string can be up to, say, 1e5 characters, then O(n^2) would be too slow. However, in programming competition problems, such a solution might not pass for large n. But the sample input includes a case like \"abdbca\" which is length 6, but perhaps the problem expects that the solution is efficient enough for the given test cases.\n",
      "\n",
      "Alternatively, maybe there's a way to use a two-pointer approach to check in linear time with possible one divergence.\n",
      "\n",
      "Here's an idea: The standard way to check for a possible palindrome with at most one deletion is to use a helper function that checks if the substring is a palindrome, allowing one skip. So, we can have a helper function that takes two pointers, left and right, and allows one skip. When a mismatch is found, we check two possibilities: skip the left character or skip the right character, and see if either leads to a valid palindrome.\n",
      "\n",
      "Wait, but how does this apply to the problem here? The problem requires exactly one deletion, not at most one. So if the original string is already a palindrome, then we need to delete exactly one character, and the resulting string must be a palindrome. So, for example, \"abba\" is a palindrome. If we delete one 'b', then \"aba\" is still a palindrome. But if the original string is a palindrome with even length, then perhaps deleting the middle two characters (if even) would still leave a palindrome. Wait, but for even length, like \"abba\", deleting any one character would result in a string of odd length. For example, deleting the first 'a' gives 'bba', which is not a palindrome. So the answer for \"abba\" is yes because there exists a position to delete (like the second 'b') that leaves a palindrome.\n",
      "\n",
      "So the problem is not about allowing at most one deletion, but exactly one. So the approach is: For the given string, check if there exists exactly one character to delete such that the resulting string is a palindrome.\n",
      "\n",
      "But how to efficiently check this?\n",
      "\n",
      "The two-pointer approach can be modified. Let me think:\n",
      "\n",
      "We can have a helper function that checks if the substring s[left:right+1] is a palindrome. If not, then we can try deleting either the left or right character and see if either of the resulting substrings is a palindrome.\n",
      "\n",
      "But since we need to check after exactly one deletion, maybe we can first check if the original string is a palindrome. If it is, then we need to see if after deleting any one character, the resulting string is a palindrome. But for a palindrome of even length, deleting a character in the first half may result in a palindrome. For example, 'abba' becomes 'aba' if you delete the second 'b'. However, for a palindrome of length 4, after deletion of one character, the string is length 3. The middle character can be anything. For example, in 'aba', the first and third characters are the same. So if the original string is a palindrome, then we can delete the middle character (if odd length) and get another palindrome, but for even length, maybe it's possible.\n",
      "\n",
      "Wait, no. For example, 'abba' is even length. If I delete the first 'b', the string becomes 'ab a' (wait, 'abba' deleting index 1 (the second character) gives 'aba', which is a palindrome. So in that case, yes. So for a palindrome string, if its length is even, then deleting any of the middle two characters (like the first 'b' in 'abba') would leave a palindrome. Wait, no. Let me see:\n",
      "\n",
      "Original: a b b a (indices 0,1,2,3). Delete index 1: a b a (indices 0,2,3?) Wait, no, the string becomes 'aba' (since after deleting index 1, the characters are a, b, a). So that's a palindrome. So for even-length palindromes, there's at least one way to delete a character to get another palindrome.\n",
      "\n",
      "But what if the original string is a palindrome of even length? Then, the answer is yes. Wait, let's see. Take 'aaaa' (length 4). Deleting any 'a' would leave 'aaa', which is a palindrome. So yes. So if the original string is a palindrome, then regardless of even or odd length, there exists a way to delete exactly one character and have a palindrome.\n",
      "\n",
      "Wait, but take 'aba' (length 3). Original is a palindrome. Deleting the middle 'b' gives 'aa' which is a palindrome. So yes. So for any original palindrome, the answer is yes. So the case where the original is a palindrome automatically returns yes.\n",
      "\n",
      "Wait, but in the sample input, the first test case is 'aaa', which is a palindrome, and the output is yes. Fourth test case 'abba' is a palindrome and output is yes.\n",
      "\n",
      "But wait, if the original string is a palindrome and its length is 1, then after deleting one character, the string is empty, which is a palindrome. So in that case, the answer is yes. But the problem constraints say that after deletion the size is one less. So for a string of length 1, after deletion, length 0. So the empty string is a palindrome. So that's allowed. So, for the original string being a palindrome, regardless of length, the answer is yes.\n",
      "\n",
      "But that's not correct. Wait, for example, the string 'a' (length 1). Delete the only character. The resulting string is empty, which is a palindrome. So output is yes.\n",
      "\n",
      "Another example: 'aa' (length 2). Delete any 'a' to get 'a', which is a palindrome. So yes.\n",
      "\n",
      "So, in general, if the original string is a palindrome, then the answer is yes. Because you can delete the middle character (for odd length) or any of the middle two (for even) to get a palindrome.\n",
      "\n",
      "Wait, but this is only if the original string's length is at least 2. Because for a single character, deleting it gives an empty string, which is a palindrome.\n",
      "\n",
      "So if the original string is a palindrome, then the answer is YES, except when the original string is of length 1. Because then, after deleting one character, it's empty, which is a palindrome. So even then, it's YES.\n",
      "\n",
      "So for all original palindromes, the answer is YES. Because deleting exactly one character would leave a palindrome. So the answer is YES.\n",
      "\n",
      "Wait, but what about a palindrome of length 3 where the middle character is different? Wait, no. If it's a palindrome, the first and third characters are the same. For example, 'aba' is a palindrome. Deleting the middle 'b' gives 'aa', which is a palindrome. So yes.\n",
      "\n",
      "So, the first step is to check if the original string is a palindrome. If it is, then the answer is YES.\n",
      "\n",
      "But wait, the sample input 4 is 'abba' which is a palindrome, and the output is YES. So that's correct.\n",
      "\n",
      "But then why the sample input 3 is 'abdbca' (which is not a palindrome) and the output is YES. So the original string isn't a palindrome. So in that case, we need to check if there's a position to delete that would make it a palindrome.\n",
      "\n",
      "So the approach would be:\n",
      "\n",
      "For each test case, first check if the original string is a palindrome. If yes, then output YES.\n",
      "\n",
      "If not, then check whether there exists exactly one character to delete (so, after deletion, the string is a palindrome).\n",
      "\n",
      "But how?\n",
      "\n",
      "So the problem is not about the original string being a palindrome. Because even if it's not, we can delete a character and make it a palindrome.\n",
      "\n",
      "So the plan is:\n",
      "\n",
      "Check if the original string is a palindrome. If yes, output YES.\n",
      "\n",
      "Else, check for all possible positions where deleting that character makes the string a palindrome. If any such position exists, output YES, else NO.\n",
      "\n",
      "But checking each possible position (n positions) and for each, checking if the resulting string is a palindrome (O(n) per check) would be O(n^2) time. For n up to say 1e5, this is not feasible, but perhaps the problem's constraints are small.\n",
      "\n",
      "But in the sample input, for example, 'abc' is length 3. The original is not a palindrome. Deleting any of the three characters:\n",
      "\n",
      "Delete 'a' → 'bc' → not palindrome.\n",
      "\n",
      "Delete 'b' → 'ac' → not.\n",
      "\n",
      "Delete 'c' → 'ab' → not. So output is NO.\n",
      "\n",
      "So the code for each test case would be:\n",
      "\n",
      "For the given string s:\n",
      "\n",
      "1. Check if s is a palindrome. If yes, return YES.\n",
      "\n",
      "2. Else, for each i in 0 to len(s)-1:\n",
      "\n",
      "   a. Create a new string by deleting the i-th character.\n",
      "\n",
      "   b. Check if that new string is a palindrome.\n",
      "\n",
      "   c. If any such string is a palindrome, return YES.\n",
      "\n",
      "3. If none found, return NO.\n",
      "\n",
      "But this approach could be O(n^2) time. For example, if the string is 1e4 characters, then 1e8 operations, which is probably too slow.\n",
      "\n",
      "But perhaps in practice, the test cases are small. However, given that the sample input includes 'abdbca' which is length 6, but for larger cases, this approach may not be efficient enough.\n",
      "\n",
      "So we need a more efficient approach.\n",
      "\n",
      "The standard way to handle this is to use a helper function that allows checking if the string can be made a palindrome by skipping up to one character. Then, in that process, we can track whether exactly one character was skipped.\n",
      "\n",
      "Wait, but the problem requires exactly one deletion. So if the original string is not a palindrome, but can be made into a palindrome by deleting exactly one character.\n",
      "\n",
      "But the helper function for the 'valid palindrome II' problem (Leetcode) allows us to skip one character, either left or right. So in that case, the code can be modified to check that exactly one character is deleted.\n",
      "\n",
      "Wait, perhaps the approach is to find the first position where the characters don't match, then try skipping the left character and check if the rest is a palindrome. Or try skipping the right character and check. If either is a palindrome, then return YES. But in this approach, the number of deletions is one. Because the original string is not a palindrome, so at least one deletion is needed, and the code checks if one deletion is sufficient.\n",
      "\n",
      "Wait, but for the problem in Leetcode (valid palindrome II), the problem is to check if the string can be made into a palindrome by deleting at most one character. So in that case, even if the original is a palindrome, it's considered valid. But in our problem, the original being a palindrome is also a valid case (since deleting exactly one character and getting a palindrome). So perhaps the approach is:\n",
      "\n",
      "Check if the original is a palindrome → if yes, return YES.\n",
      "\n",
      "Else, check using the helper function (allowing one deletion) → if returns true, then return YES. Else, NO.\n",
      "\n",
      "But how does the helper function work?\n",
      "\n",
      "The helper function would check whether the string can be made into a palindrome by deleting at most one character. So, for the problem, the answer is YES if either the original is a palindrome (so deleting any one character would leave a palindrome, but the original must be a palindrome. Wait, no. For example, the original is a palindrome, but after deleting a character, it's not. But the problem requires that after exactly one deletion, the string is a palindrome. So for example, if the original string is 'abba', deleting the first 'a' gives 'bba', which is not a palindrome. But deleting the second 'b' gives 'aba', which is a palindrome. So even though the original is a palindrome, we have to check if there exists at least one character to delete that leaves a palindrome.\n",
      "\n",
      "So the initial approach of checking if the original is a palindrome, then checking if any of the possible deletions leads to a palindrome is correct, but for large strings, this approach is O(n^2), which is not efficient.\n",
      "\n",
      "So perhaps a better approach is to:\n",
      "\n",
      "Check if the original is a palindrome. If yes, return YES.\n",
      "\n",
      "Else, find the positions where the first mismatch occurs when checking from left and right. Then, check the two possibilities: delete left character or delete right character, and see if either of the resulting substrings is a palindrome.\n",
      "\n",
      "This is the approach used in the valid palindrome II problem.\n",
      "\n",
      "Let me think about this.\n",
      "\n",
      "For example, in the string 'abdbca':\n",
      "\n",
      "Check left and right pointers:\n",
      "\n",
      "Start at left=0 (a), right=5 (a). They match. Move left and right inward.\n",
      "\n",
      "Left=1 (b), right=4 (c). Mismatch. So we need to check two possibilities:\n",
      "\n",
      "Delete left character (b) and check if the substring from left+1 to right (d, b, c, a) → 'dbca' → but wait, that's not correct. Wait, the current pointers are left=1, right=4. So the characters are s[1] = 'b' and s[4] = 'c' (since the original string is 'a','b','d','b','c','a'). So after deleting left (index 1), the new string would be 'a d b c a' → 'ad bc a' → 'adbc a' (assuming the string becomes 'adbc a', which is 'adbca' (length 5). Checking if this is a palindrome.\n",
      "\n",
      "Wait, 'a' at start, 'a' at end. Then 'd' vs 'c' next. So no. Not a palindrome.\n",
      "\n",
      "Alternatively, delete the right character (index 4, which is 'c'), so the string becomes 'abdb a' (since the original is 'a','b','d','b','c','a' → deleting index 4 gives 'abdb a' → 'abdba', which is a palindrome. So this would be a valid case.\n",
      "\n",
      "So the helper function would find that deleting the right character (index 4) gives a palindrome, so return True.\n",
      "\n",
      "So the approach is:\n",
      "\n",
      "Find the first mismatch between left and right pointers.\n",
      "\n",
      "Check if deleting the left or right character would result in a palindrome.\n",
      "\n",
      "If either is possible, return YES.\n",
      "\n",
      "But how to implement this.\n",
      "\n",
      "So code steps for each test case:\n",
      "\n",
      "1. Check if the original string is a palindrome. If yes, output YES.\n",
      "\n",
      "   Wait, no. Because even if the original is a palindrome, we have to delete exactly one character. For example, the original is 'abba'. The code would check if the original is a palindrome (yes), but then need to check if there's a way to delete a character and get a palindrome. But according to the sample input, 'abba' is a yes. But according to the helper function approach, which checks for up to one deletion, the helper function would return yes. But in this case, the original is a palindrome, so the helper function would return true, which would indicate that the answer is yes. But according to the helper function logic, it allows up to one deletion. But in this case, the original is a palindrome, so the helper function would return true (since 0 deletions are allowed).\n",
      "\n",
      "But the problem requires exactly one deletion. So the helper function approach is not directly applicable.\n",
      "\n",
      "So the approach has two cases:\n",
      "\n",
      "Case 1: The original string is a palindrome. Then, we need to check if there exists at least one character to delete such that the resulting string is a palindrome.\n",
      "\n",
      "Case 2: The original string is not a palindrome. Then, check if there exists exactly one character to delete to make it a palindrome.\n",
      "\n",
      "So combining these cases.\n",
      "\n",
      "But how to handle case 1 efficiently.\n",
      "\n",
      "For case 1, the original is a palindrome. So we need to check if after deleting any one character, the remaining string is a palindrome.\n",
      "\n",
      "But for a palindrome of length n, after deleting any character, the resulting string's palindrome status depends on which character is deleted.\n",
      "\n",
      "For example, in 'abba', deleting the first 'a' gives 'bba' which is not a palindrome, but deleting the first 'b' gives 'aba' which is a palindrome.\n",
      "\n",
      "So in case 1, even though the original is a palindrome, we have to check if there's at least one character whose deletion leaves a palindrome.\n",
      "\n",
      "But how to check this efficiently.\n",
      "\n",
      "One approach is: For a palindrome, the minimal way is to delete the first character and check if the resulting string is a palindrome. If yes, then return yes. Otherwise, delete the last character and check. If either is a palindrome, then return yes. If not, then return no.\n",
      "\n",
      "But this is not sufficient. For example, consider the string 'abcba'. If you delete the middle 'c', you get 'abba', which is a palindrome. But if you delete the first 'a', you get 'bcba', which is not a palindrome. Deleting the first 'b' gives 'acba', which is not a palindrome. So the code that deletes first and last and checks would not find the valid case.\n",
      "\n",
      "So this approach is not sufficient.\n",
      "\n",
      "So, for case 1, when the original is a palindrome, we have to check whether there exists any position where deleting that character leaves a palindrome. But for large n, this is O(n^2), which is not efficient.\n",
      "\n",
      "Alternatively, perhaps in a palindrome, deleting any character except the first half's characters (for even length) or the middle (for odd) would result in a non-palindrome. So perhaps for a palindrome of length >=2, the answer is always yes. Because for example, in a palindrome of even length, deleting the first character may not leave a palindrome, but deleting the middle character (for even length, maybe the middle two?) would. Wait, 'abba' is even. Deleting the middle two characters (indexes 1 and 2) gives 'aa' which is a palindrome. But if you delete index 1, the string becomes 'aba', which is a palindrome. So in this case, the answer is yes.\n",
      "\n",
      "But what about a palindrome of even length 4, 'aaaa' → deleting any 'a' gives 'aaa', which is a palindrome. So yes.\n",
      "\n",
      "What about a palindrome of even length 2, 'aa' → deleting either gives 'a', which is a palindrome.\n",
      "\n",
      "So perhaps for a palindrome of even length, deleting either of the two middle characters would result in a palindrome.\n",
      "\n",
      "For a palindrome of odd length >=3, like 'aba', deleting the middle 'b' gives 'aa' which is a palindrome. Deleting the first 'a' gives 'ba', which is not. So the answer is yes.\n",
      "\n",
      "So in general, if the original string is a palindrome, then there exists at least one character to delete to make it a palindrome. So the answer is YES.\n",
      "\n",
      "Wait, but let's think of a palindrome that is of length 5: 'abcba'. Deleting the middle 'c' gives 'abba', which is a palindrome. So yes.\n",
      "\n",
      "Another example: 'abbba' (length 5). Deleting the middle 'b' gives 'abba' (palindrome). So yes.\n",
      "\n",
      "So, for any palindrome of length >=2, the answer is YES. Because, for even length, there are two middle characters (like in 'abba', the two 'b's). Deleting either would leave a palindrome. For odd length, deleting the middle character would leave a palindrome.\n",
      "\n",
      "So, if the original string is a palindrome, then the answer is YES, provided that the original length is at least 2. But if the original length is 1, then deleting the only character leaves an empty string, which is a palindrome. So even in that case, the answer is YES.\n",
      "\n",
      "So, in all cases where the original string is a palindrome, the answer is YES.\n",
      "\n",
      "So the code can be optimized as follows:\n",
      "\n",
      "For each test case:\n",
      "\n",
      "1. Check if the original string is a palindrome. If yes, output YES.\n",
      "\n",
      "2. Else, check if there exists a single character to delete (either by skipping left or right in the first mismatch) such that the resulting string is a palindrome. If yes, output YES. Else, NO.\n",
      "\n",
      "So the code would first check if the original is a palindrome. If not, then use the helper function to check for the possibility of deleting exactly one character.\n",
      "\n",
      "So, the steps:\n",
      "\n",
      "For a given string s:\n",
      "\n",
      "if is_palindrome(s):\n",
      "\n",
      "   return YES\n",
      "\n",
      "else:\n",
      "\n",
      "   check if by deleting one character (either left or right in the first mismatch), the resulting string is a palindrome. If any of the two possibilities is a palindrome, return YES, else NO.\n",
      "\n",
      "But how to implement the helper function.\n",
      "\n",
      "The helper function would be similar to the one in Leetcode's valid palindrome II problem.\n",
      "\n",
      "Here's the code outline:\n",
      "\n",
      "def is_palindrome(s):\n",
      "\n",
      "   return s == s[::-1]\n",
      "\n",
      "def can_form_palindrome(s):\n",
      "\n",
      "   left = 0\n",
      "\n",
      "   right = len(s) -1\n",
      "\n",
      "   while left < right:\n",
      "\n",
      "       if s[left] == s[right]:\n",
      "\n",
      "           left +=1\n",
      "\n",
      "           right -=1\n",
      "\n",
      "       else:\n",
      "\n",
      "           # check two possibilities: delete left or delete right\n",
      "\n",
      "           # check delete left: s[left+1 ... right]\n",
      "\n",
      "           # check delete right: s[left ... right-1]\n",
      "\n",
      "           return is_palindrome(s[left+1: right+1]) or is_palindrome(s[left: right])\n",
      "\n",
      "   return True\n",
      "\n",
      "Wait, but this function is for the case where we can delete at most one character. So, if the original string is a palindrome, this function returns True. But in our case, we have to first check if the original is a palindrome (which would return YES), else check if the helper function returns True.\n",
      "\n",
      "So combining this, the code would be:\n",
      "\n",
      "for each test case s:\n",
      "\n",
      "   if is_palindrome(s):\n",
      "\n",
      "       print(\"YES\")\n",
      "\n",
      "   else:\n",
      "\n",
      "       if can_form_palindrome(s):\n",
      "\n",
      "           print(\"YES\")\n",
      "\n",
      "       else:\n",
      "\n",
      "           print(\"NO\")\n",
      "\n",
      "But wait, the can_form_palindrome function returns True even if the original is a palindrome. But in our code, we have already checked for that, so it's not a problem.\n",
      "\n",
      "But how does the can_form_palindrome function work when the original is not a palindrome. It checks if by deleting one character (left or right in the first mismatch), the resulting string is a palindrome.\n",
      "\n",
      "So, for example, in the string 'abdbca', which is not a palindrome. The helper function would find the first mismatch at positions 1 and 4 (characters 'b' and 'c'). Then it checks deleting left (i=1) → substring from 2 to 5 (s[2:5+1] → 'dbca') → which is 'dbca' → is it a palindrome? 'd' vs 'a' → no. Then check deleting right (i=4) → substring from 1 to 4 → s[1:4] → 'bdbca'? Wait, no. Wait, the code is s[left:right], which for left=1 and right=4 (original right is 4). So s[1:4] would be s[1], s[2], s[3], which is 'b', 'd', 'b'. So the substring 'bdb'. Wait, wait the original string is 'abdbca' → indexes 0:a, 1:b, 2:d, 3:b,4:c,5:a.\n",
      "\n",
      "In the helper function, when left=1 and right=4 (s[1]=b, s[4]=c), the code would check s[left+1:right+1] (left+1=2, right+1=5 → s[2:5] is d, b, c → 'dbc'? No. Wait, in Python, s[a:b] is from index a up to but not including b. So s[2:5] is characters at 2,3,4 → 'd', 'b', 'c' → 'dbc', which is not a palindrome. Then check s[left:right] → s[1:4] → indexes 1,2,3 → 'b', 'd', 'b' → which is 'bdb', a palindrome. So the helper function would return True.\n",
      "\n",
      "So in this case, the helper function returns True, so the code outputs YES.\n",
      "\n",
      "So the helper function works for this case.\n",
      "\n",
      "Another example: 'abc' → the helper function would find the first mismatch at left=0 (a) and right=2 (c). Then check s[1:3] (bc) → not palindrome. Check s[0:2] (ab) → not palindrome. So helper function returns False → code outputs NO.\n",
      "\n",
      "So this works.\n",
      "\n",
      "So the code would be:\n",
      "\n",
      "Read T test cases.\n",
      "\n",
      "For each s:\n",
      "\n",
      "if s is a palindrome → YES\n",
      "\n",
      "else:\n",
      "\n",
      "   check if deleting one character (via helper) can make it a palindrome → if yes, YES else NO.\n",
      "\n",
      "But what about cases where the original is not a palindrome, but there are multiple mismatches and deleting a character that is not in the first pair?\n",
      "\n",
      "For example, the string 'abccdba' → suppose after the first mismatch, the helper function tries deleting the left or right, but the actual solution is to delete a character further along.\n",
      "\n",
      "But the helper function would only check the first pair of mismatched characters and try deleting left or right. So this could miss some cases.\n",
      "\n",
      "For example, consider the string 'abcde fgdcba' → wait, maybe this is not a good example. Let's think of a string where the first mismatch can be fixed by deleting either left or right, but after that, there's another mismatch that can't be fixed. Or perhaps a case where the first mismatch's deletion possibilities are not correct, but a later deletion is needed.\n",
      "\n",
      "For example, the string 'aabcdbaa' → let's see:\n",
      "\n",
      "The string is 'a', 'a', 'b', 'c', 'd', 'b', 'a', 'a'.\n",
      "\n",
      "Check from left and right:\n",
      "\n",
      "left=0 (a), right=7 (a) → match.\n",
      "\n",
      "left=1 (a), right=6 (a) → match.\n",
      "\n",
      "left=2 (b), right=5 (b) → match.\n",
      "\n",
      "left=3 (c), right=4 (d) → mismatch.\n",
      "\n",
      "So the helper function would check deleting left (c) → s becomes 'aabddbaa' (since we delete index 3, the string is 'aabddbaa'? Wait, original string is 'a a b c d b a a' → indexes 0-7. Deleting index 3 (c), the string becomes 'aab d b a a' → 'aabdb aa'? Then check if this is a palindrome. The new string is 'aabdb aa' → which is 'a a b d b a a' → length 7. Check left and right:\n",
      "\n",
      "left=0, right=6 (a and a → match.\n",
      "\n",
      "left=1, right=5 (a and a → match.\n",
      "\n",
      "left=2 (b), right=4 (d → mismatch. So the helper function would return False for this path.\n",
      "\n",
      "Alternatively, delete the right character (d, index 4). The new string is 'a a b c b a a' → 'aabcb aa' → which is 'a a b c b a a'. Check:\n",
      "\n",
      "left=0 and 6 (a, a → match.\n",
      "\n",
      "left=1 and 5 (a and a → match.\n",
      "\n",
      "left=2 and 4 (b and b → match.\n",
      "\n",
      "left=3 (c), left=3, right=3. So it's a palindrome. So the helper function returns True.\n",
      "\n",
      "So the code would return YES.\n",
      "\n",
      "But in this example, the helper function's approach of checking only the first mismatch and deleting left or right worked.\n",
      "\n",
      "But what about a case where the first mismatch can't be fixed by deleting left or right, but a later deletion could fix it.\n",
      "\n",
      "For example, the string 'abbaac'.\n",
      "\n",
      "Original string is 'a', 'b', 'b', 'a', 'a', 'c'. The original is not a palindrome.\n",
      "\n",
      "Check left=0 (a) and right=5 (c). Mismatch.\n",
      "\n",
      "So helper function would check deleting left (a) → 'bbaa c' → 'bbaa c' → 'bbaac' (since after deleting index 0, the string is 'bbaa c' → 'bbaac' which is 'b b a a c'. Check if this is a palindrome: left 0 (b) and right 4 (c → mismatch. So not a palindrome.\n",
      "\n",
      "Then check deleting right (c), the string becomes 'abbaa'. Check if it's a palindrome. 'abbaa' → length 5. Check left=0 (a) and right=4 (a → match. left=1 (b) and right=3 (a → mismatch. So not a palindrome. So helper function returns False.\n",
      "\n",
      "But the actual correct deletion is to delete the last 'c' and the second 'a' in the middle. Wait, no. Wait, the string is 'abbaac'. The correct deletion would be to delete the 'c' to make 'abbaa', which is not a palindrome. So perhaps there's no solution.\n",
      "\n",
      "But then the code would return NO. But what if there's a case where the first deletion is not the correct one but a later deletion is needed?\n",
      "\n",
      "For example, 'cabac'. Original string is not a palindrome. First mismatch is c vs c (left 0 and right 4). Wait, no. Let me see:\n",
      "\n",
      "Original string: c a b a c. It is a palindrome. So code returns YES.\n",
      "\n",
      "Another example: 'caba'. Original is not a palindrome. Check first mismatch: left 0 (c) and right 3 (a). Delete left (c) → 'aba' → palindrome. So helper function returns True.\n",
      "\n",
      "But what if the string is 'cbaab' → not a palindrome. Let's see:\n",
      "\n",
      "Left=0 (c) and right=4 (b). Mismatch. So delete left (c → 'baab' → which is a palindrome. So helper function returns True.\n",
      "\n",
      "So in this case, the code works.\n",
      "\n",
      "But what if the first mismatch is at positions 0 and 4, and deleting either gives a non-palindrome, but there's a deletion elsewhere that would work.\n",
      "\n",
      "For example: 'abcdedcbaa' → original string is a palindrome? Let's see: a b c d e d c b a a. No. The first a and last a are same. Next b and a → no. So first mismatch is at positions 1 (b) and 9 (a). So helper function tries deleting left (b) → check s[2:9+1] → substring from 2 to 10 (since Python slicing is up to but not including end. So original string is length 10, indexes 0-9.\n",
      "\n",
      "So deleting left (index 1) → the substring is s[2:10] → 'cdedcbaa'.\n",
      "\n",
      "Check if this is a palindrome. 'c d e d c b a a' → first c and last a: no. So not a palindrome.\n",
      "\n",
      "Delete right (index 9, a) → substring is s[0:9] → 'abcdedcba', which is a palindrome. So helper function returns True.\n",
      "\n",
      "So code returns YES.\n",
      "\n",
      "So even though there are multiple mismatches, the helper function's approach of checking the first pair and trying to delete either left or right works.\n",
      "\n",
      "Thus, the helper function's approach is sufficient.\n",
      "\n",
      "Thus, the code can be written as:\n",
      "\n",
      "Check if the original is a palindrome → if yes, return YES.\n",
      "\n",
      "Else, use the helper function to see if after deleting one character (left or right in the first mismatch) results in a palindrome.\n",
      "\n",
      "Thus, the code is as follows:\n",
      "\n",
      "Read T test cases.\n",
      "\n",
      "For each test case:\n",
      "\n",
      "s = input().strip()\n",
      "\n",
      "if s == s[::-1]:\n",
      "\n",
      "    print(\"YES\")\n",
      "\n",
      "else:\n",
      "\n",
      "    left = 0\n",
      "\n",
      "    right = len(s) - 1\n",
      "\n",
      "    while left < right:\n",
      "\n",
      "        if s[left] == s[right]:\n",
      "\n",
      "            left +=1\n",
      "\n",
      "            right -=1\n",
      "\n",
      "        else:\n",
      "\n",
      "            # check delete left or right\n",
      "\n",
      "            s1 = s[left+1:right+1]  # after deleting left\n",
      "\n",
      "            s2 = s[left:right]      # after deleting right\n",
      "\n",
      "            if s1 == s1[::-1] or s2 == s2[::-1]:\n",
      "\n",
      "                print(\"YES\")\n",
      "\n",
      "            else:\n",
      "\n",
      "                print(\"NO\")\n",
      "\n",
      "            break\n",
      "\n",
      "    else:\n",
      "\n",
      "        print(\"YES\")\n",
      "\n",
      "Wait, but what if the loop completes without breaking (the else clause of the while loop). This can only happen if the loop condition is not met, i.e., left >= right. Which would imply that all characters matched, so the original is a palindrome. But we have already checked that before entering the else block. So this part of the code is unreachable.\n",
      "\n",
      "So the code can be:\n",
      "\n",
      "for each test case:\n",
      "\n",
      "    s = input().strip()\n",
      "\n",
      "    if s == s[::-1]:\n",
      "\n",
      "        print(\"YES\")\n",
      "\n",
      "    else:\n",
      "\n",
      "        left = 0\n",
      "\n",
      "        right = len(s) -1\n",
      "\n",
      "        found = False\n",
      "\n",
      "        while left < right:\n",
      "\n",
      "            if s[left] == s[right]:\n",
      "\n",
      "                left +=1\n",
      "\n",
      "                right -=1\n",
      "\n",
      "            else:\n",
      "\n",
      "                # check two options\n",
      "\n",
      "                s1 = s[left+1: right+1]\n",
      "\n",
      "                s2 = s[left: right]\n",
      "\n",
      "                if s1 == s1[::-1] or s2 == s2[::-1]:\n",
      "\n",
      "                    print(\"YES\")\n",
      "\n",
      "                else:\n",
      "\n",
      "                    print(\"NO\")\n",
      "\n",
      "                found = True\n",
      "\n",
      "                break\n",
      "\n",
      "        if not found:\n",
      "\n",
      "            print(\"YES\")\n",
      "\n",
      "But since the original string is not a palindrome, the loop must have found a mismatch, so the 'found' would be set to True, and the code would have printed YES or NO.\n",
      "\n",
      "Thus, the code is correct.\n",
      "\n",
      "But wait, in the case where the original is not a palindrome, the loop will break at the first mismatch, check s1 and s2, and print YES or NO.\n",
      "\n",
      "So, this code should handle all cases.\n",
      "\n",
      "Testing the sample input:\n",
      "\n",
      "Sample Input 4:\n",
      "\n",
      "4\n",
      "\n",
      "aaa → is a palindrome → print YES.\n",
      "\n",
      "abc → not a palindrome. Mismatch at a and c. Check s1 (bc) and s2 (ab). Neither is palindrome → print NO.\n",
      "\n",
      "abdbca → not a palindrome. Mismatch at b and c. Check s1 (d,b,c,a) → s[left+1:right+1] is s[2:5+1] → indexes 2-5 (d, b, c, a) → 'dbca' → no. s2 is s[1:4] → 'bdb c' → no. Wait, wait, the original string is 'abdbca' → indexes 0:a,1:b,2:d,3:b,4:c,5:a. So left is 1, right is 4. So s1 = s[2:5] (since right+1 is 5 → indexes 2,3,4 → d, b, c → 'dbc' which is not a palindrome. s2 is s[1:4] → indexes 1,2,3 → b, d, b → 'bdb' which is a palindrome. So the code would print YES.\n",
      "\n",
      "Fourth test case: abba → is a palindrome → print YES.\n",
      "\n",
      "Which matches the sample output.\n",
      "\n",
      "Another test case: 'abba' → code outputs YES.\n",
      "\n",
      "Another test case: 'a' → is a palindrome → YES.\n",
      "\n",
      "Another test case: 'aa' → YES.\n",
      "\n",
      "Another test case: 'ab' → not a palindrome. Check s1 (b) → palindrome. So output YES. Wait, no. 'ab' → after deleting 'a', we get 'b' → palindrome. So code should output YES.\n",
      "\n",
      "Wait, but according to the code:\n",
      "\n",
      "s = 'ab'. It is not a palindrome.\n",
      "\n",
      "In the loop:\n",
      "\n",
      "left=0, right=1. s[0] = 'a', s[1] = 'b' → mismatch.\n",
      "\n",
      "s1 is s[1:2] → 'b' → palindrome. So code prints YES.\n",
      "\n",
      "So for input 'ab', output is YES.\n",
      "\n",
      "But according to the problem statement, the sample input 'abba' is YES because deleting one 'b' gives 'aba'. But according to the code, 'ab' would return YES. But according to the problem statement, the answer depends on whether the resulting string is a palindrome after exactly one deletion.\n",
      "\n",
      "So for 'ab', the code is correct.\n",
      "\n",
      "Thus, the code is correct.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "def is_palindrome(s):\n",
      "    return s == s[::-1]\n",
      "\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    if is_palindrome(s):\n",
      "        print(\"YES\")\n",
      "        continue\n",
      "    left = 0\n",
      "    right = len(s) - 1\n",
      "    found = False\n",
      "    while left < right:\n",
      "        if s[left] == s[right]:\n",
      "            left += 1\n",
      "            right -= 1\n",
      "        else:\n",
      "            # Check two possibilities: delete left or delete right\n",
      "            s1 = s[left+1 : right+1]  # Delete left character\n",
      "            s2 = s[left : right]      # Delete right character\n",
      "            if is_palindrome(s1) or is_palindrome(s2):\n",
      "                print(\"YES\")\n",
      "            else:\n",
      "                print(\"NO\")\n",
      "            found = True\n",
      "            break\n",
      "    if not found:\n",
      "        print(\"YES\")\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "2\n",
      "def is_palindrome(s):\n",
      "    return s == s[::-1]\n",
      "\n",
      "T = int(input())\n",
      "for _ in range(T):\n",
      "    s = input().strip()\n",
      "    if is_palindrome(s):\n",
      "        print(\"YES\")\n",
      "        continue\n",
      "    left = 0\n",
      "    right = len(s) - 1\n",
      "    found = False\n",
      "    while left < right:\n",
      "        if s[left] == s[right]:\n",
      "            left += 1\n",
      "            right -= 1\n",
      "        else:\n",
      "            # Check two possibilities: delete left or delete right\n",
      "            s1 = s[left+1 : right+1]  # Delete left character\n",
      "            s2 = s[left : right]      # Delete right character\n",
      "            if is_palindrome(s1) or is_palindrome(s2):\n",
      "                print(\"YES\")\n",
      "            else:\n",
      "                print(\"NO\")\n",
      "            found = True\n",
      "            break\n",
      "    if not found:\n",
      "        print(\"YES\")\n",
      "158a2912d0543c34123ff7faa6739b3f\n",
      "An established group of scientists are working on finding solution to NP hard problems. They claim Subset Sum  as an NP-hard problem. The problem is to determine whether there exists a subset of a given set S whose sum is a given number K.  \n",
      "You are a computer engineer and you claim to solve this problem given that all numbers in the set are non-negative. Given a set S of size N of non-negative integers, find whether there exists a subset whose sum is K.\n",
      "Input\n",
      "First line of input contains T, the number of test cases. T test cases follow. \n",
      "Each test case contains 2 lines. First line contains two integers N and K. Next line contains N space separated non-negative integers (each less than 100000).\n",
      "0 < T < 1000\n",
      "0 < N < 1000\n",
      "0 < K < 1000\n",
      "\n",
      "Output\n",
      "Output T lines, one for each test case. Every line should be either 0 or 1 depending on whether such a subset exists or not.\n",
      "\n",
      "Example\n",
      "\n",
      "Input:\n",
      "2\n",
      "5 10\n",
      "3 4 6 1 9\n",
      "3 2\n",
      "1 3 4\n",
      "\n",
      "Output:\n",
      "1\n",
      "0\n",
      "<think>\n",
      "Okay, I need to solve this subset sum problem where all numbers are non-negative. Let's see. The problem is to determine if any subset of the given set S adds up exactly to K. The constraints are that T can be up to 1000 test cases, and N can be up to 1000 elements. Hmm, but wait, K is up to 1000. Oh right, that's important. So maybe a dynamic programming approach would work here since the target K is not too big.\n",
      "\n",
      "Wait, the standard subset sum approach with DP uses a 2D array where dp[i][j] is True if there's a subset of the first i elements that sums to j. But with N up to 1000 and K up to 1000, the space might be manageable. But even better, since each state only depends on the previous row, maybe we can use a 1D array to optimize space.\n",
      "\n",
      "Let me think. For each element in the set, we can iterate through the possible sums from K down to the element's value and update the dp array. The initial state is that sum 0 is achievable (since the empty subset sums to 0). Then, for each number, we check if adding it to existing sums can reach new sums.\n",
      "\n",
      "Wait, but what if K is 0? Well, according to the input constraints, K is greater than 0. The problem statement says 0 < K < 1000, so the empty subset (sum 0) is only considered if K is 0, which is not allowed here. So we can ignore that case.\n",
      "\n",
      "So the steps would be:\n",
      "\n",
      "1. For each test case, read N, K, and the list of numbers.\n",
      "2. Initialize a boolean array dp of size K+1, with dp[0] = True (base case), others False.\n",
      "3. For each number in the list:\n",
      "   a. For each possible sum j from K down to the number's value:\n",
      "      i. If dp[j - num] is True, then set dp[j] to True.\n",
      "4. After processing all numbers, check if dp[K] is True. Output 1 or 0 accordingly.\n",
      "\n",
      "But wait, we have to handle numbers that are larger than K. Because if a number is larger than K, we can't include it in any subset that sums to K. So in such cases, we just skip them. So for each num in S, if num > K, ignore it. Otherwise, process it as part of the DP.\n",
      "\n",
      "But how about when K is zero? Well, the problem says K is greater than 0, so we don't need to handle that case.\n",
      "\n",
      "Let's test this approach with the example.\n",
      "\n",
      "First example input:\n",
      "N=5, K=10, S=[3,4,6,1,9]\n",
      "\n",
      "Process the numbers. Let's see:\n",
      "\n",
      "Start with dp[0] = True.\n",
      "\n",
      "First number is 3. For j from 10 down to 3:\n",
      "Check j - 3. For j=3: dp[0] is True, so set dp[3] to True. Then j=4, 5, ..., 10. For j=6: j-3=3 is True, so set dp[6] to True. Similarly, up to j=10. So after first step, dp[3] and dp[6] (if 3+3=6 is possible, but wait, 3 is the only element so far. So maybe I made a mistake here. Wait, no. The first element is 3. So after processing 3, the possible sums are 0 (not considered) and 3.\n",
      "\n",
      "Wait, the initial dp is [True, False, ..., False]. For each num, we look for j from K down to num. So for 3, j can be 3 to 10, but K is 10. So the loop for j in range(min(current_max, K), num-1, -1). Wait, maybe the loop should be from K down to num. Because adding the current num can contribute to sums up to K.\n",
      "\n",
      "So for the first number 3, the possible j is 3. So dp[3] becomes True.\n",
      "\n",
      "Next number is 4. Now, for j from 10 down to 4. For each j, check if j-4 is in the dp. For j=4: j-4=0, which is True. So dp[4] = True. For j=7: j-4=3, which is True, so dp[7] becomes True. Then j=8: j-4=4 (now 4 is True?), so dp[8] becomes True. Wait, but after processing 3, the possible sums are 0,3. Then processing 4:\n",
      "\n",
      "Loop j from 10 down to 4.\n",
      "\n",
      "j=10: j-4=6. dp[6] is currently False (after first iteration, we have 3). So no change.\n",
      "\n",
      "j=9: 9-4=5, not set.\n",
      "\n",
      "j=8: 8-4=4, which is not set yet. Wait, when j is 8, j-4=4. But in this step, when we process 4, are we considering adding it to existing subsets?\n",
      "\n",
      "Wait, the way the DP works is that for each number, we process the current possible sums and see if adding the number can reach a new sum.\n",
      "\n",
      "But the order of processing j from high to low is important to prevent reusing the same element multiple times. Because if we go from low to high, each element can be used multiple times (like in the unbounded knapsack problem). But here, since each element can be used at most once, we process j from high to low.\n",
      "\n",
      "So in the example:\n",
      "\n",
      "After processing 3: possible sums are 0 and 3.\n",
      "\n",
      "Processing 4:\n",
      "\n",
      "For j from 10 down to 4.\n",
      "\n",
      "At j=7: j-4=3. Since 3 is in the dp (from previous step), set dp[7] to True.\n",
      "\n",
      "At j=4: j-4=0, so set dp[4] to True.\n",
      "\n",
      "So after processing 4, the possible sums are 0,3,4,7.\n",
      "\n",
      "Next number is 6. Now K is 10. So for j from 10 down to 6.\n",
      "\n",
      "Check each j:\n",
      "\n",
      "j=10: j-6=4. 4 is True (from previous step). So set dp[10] to True. We can stop here, since the target is found.\n",
      "\n",
      "So in this case, the answer is 1.\n",
      "\n",
      "The second test case is N=3, K=2. The numbers are 1,3,4.\n",
      "\n",
      "Processing:\n",
      "\n",
      "Initialize dp[0] = True.\n",
      "\n",
      "First number is 1. j runs from 2 down to 1.\n",
      "\n",
      "j=2: j-1=1, which is not in dp (only 0 is True). So no change.\n",
      "\n",
      "j=1: j-1=0, which is True. So dp[1] becomes True.\n",
      "\n",
      "Now possible sums are 0 and 1.\n",
      "\n",
      "Next number is 3. Since 3 is larger than K (2), we skip it.\n",
      "\n",
      "Third number is 4, also larger than K, so skip.\n",
      "\n",
      "At the end, dp[2] is False, so output 0.\n",
      "\n",
      "So the approach works for the sample.\n",
      "\n",
      "Now, considering the constraints. For each test case, the DP array is of size K+1. Since K can be up to 1000, each test case's DP array is 1001 elements. For each element in S (up to 1000 elements), we iterate from K down to the element's value. But if the element's value is larger than K, we skip it.\n",
      "\n",
      "So the time complexity for each test case is O(N*K). For T=1000, N=1000, K=1000, this would be 1e9 operations, which is way too much. Wait, but 1e9 operations would take too long, right? But wait, the problem statement says K is up to 1000. Wait, the input constraints for K are 0 < K < 1000, so K can be up to 999. So each test case is O(1000 * 1000) = 1e6 operations, and with T=1000, that's 1e9 operations. Which would be too slow for Python, as Python can handle about 1e8 operations per second. So this approach may not work for the constraints given. Hmm, that's a problem.\n",
      "\n",
      "Wait, but maybe the test data is designed such that the allowed time is sufficient. But I need to find a way to optimize this. Alternatively, maybe the problem's constraints are not as per the input description, but the actual constraints are smaller. Let me check the problem statement again.\n",
      "\n",
      "The problem says:\n",
      "\n",
      "Input constraints:\n",
      "\n",
      "0 < T < 1000\n",
      "\n",
      "0 < N < 1000\n",
      "\n",
      "0 < K < 1000\n",
      "\n",
      "So N is up to 999, K is up to 999. So each test case is O(N*K) = 999*999 = ~1e6. For T=999, that's 1e9 operations. That's way too much for Python. So this approach would not pass within the time limit.\n",
      "\n",
      "Wait, but wait—what's the actual maximum possible? Let's see. For T=1000, each with N=1000, K=1000. Each test case would take 1e6 operations. 1000 * 1e6 = 1e9 operations. Python can handle about 1e6 operations per second, maybe 1e8 is 100 seconds, which is way beyond the time limit. So this approach would not work for the given constraints. So I need a better approach.\n",
      "\n",
      "Hmm. So the standard DP approach might not be feasible. What's another way?\n",
      "\n",
      "Alternative approaches: Maybe using bitmask operations. Because each step, the possible sums can be represented as a bitmask. For example, a bitmask where the i-th bit is set if sum i is possible. Then, for each number, the new bitmask is the old bitmask OR (old bitmask shifted left by the number). But since K is up to 1000, the bitmask can be up to 1001 bits. But in Python, integers can be arbitrary length. Let's see.\n",
      "\n",
      "For example, initial bitmask is 1 (binary 1, which represents sum 0 is possible). For each number num in S:\n",
      "\n",
      "new_mask = mask | (mask << num)\n",
      "\n",
      "But we need to cap it at K, i.e., if shifting left by num would exceed K, then those bits beyond K can be ignored.\n",
      "\n",
      "So the mask is updated as:\n",
      "\n",
      "mask |= mask << num\n",
      "\n",
      "Then, after all elements, check if the K-th bit is set.\n",
      "\n",
      "This approach can be much faster because bitwise operations are fast. Let's see:\n",
      "\n",
      "In Python, integers can be arbitrarily large, but shifting and OR operations are optimized. For each element, the mask is updated by OR'ing with (mask << num), but since we only care about sums up to K, we can mask the result to K bits.\n",
      "\n",
      "Wait, for example, after each shift, we can do a bitwise AND with ( (1 << (K+1)) - 1 ), which keeps only the first K+1 bits. This way, we prevent the mask from growing beyond K.\n",
      "\n",
      "So the steps would be:\n",
      "\n",
      "Initialize mask = 1 (only the 0th bit is set).\n",
      "\n",
      "For each num in S:\n",
      "\n",
      "if num > K: skip.\n",
      "\n",
      "mask |= mask << num\n",
      "\n",
      "mask &= (1 << (K+1)) - 1  # keep only bits up to K\n",
      "\n",
      "After processing all numbers, check if the K-th bit is set in mask.\n",
      "\n",
      "This approach could be much faster, as each operation is O(1) per number (bitwise operations are fast), even for large K. Let's see for K=1000, each mask is 1001 bits. So shifting and OR'ing are manageable.\n",
      "\n",
      "So let's try this approach.\n",
      "\n",
      "In Python, for each test case:\n",
      "\n",
      "Read N, K.\n",
      "\n",
      "Read the list of numbers.\n",
      "\n",
      "Initialize mask = 1.\n",
      "\n",
      "For num in the list:\n",
      "\n",
      "   if num > K or num ==0:  # since if num is 0, adding it doesn't change the sum. But the problem says non-negative. So 0 is allowed, but including or excluding 0 in the subset doesn't affect the sum. So if K is zero, then the subset can be empty (but according to the problem, K is greater than 0). So 0s in the input can be ignored? Because including a 0 in a subset doesn't change the sum. So, for example, if the subset is {0}, sum is zero. But since K is always >0, the presence of 0s in the input doesn't affect the possible sum. So for numbers equal to 0, we can skip them. Because including them or not doesn't change the subset sum. So, for num in S:\n",
      "\n",
      "   if num == 0: skip.\n",
      "\n",
      "   else if num > K: skip.\n",
      "\n",
      "   else:\n",
      "\n",
      "      mask |= mask << num\n",
      "\n",
      "      mask &= ( (1 << (K+1)) ) -1\n",
      "\n",
      "At the end, check if (mask & (1 << K)) != 0. If yes, output 1, else 0.\n",
      "\n",
      "Let's test this with the first example.\n",
      "\n",
      "Test case 1: K=10, numbers [3,4,6,1,9].\n",
      "\n",
      "Processing each number:\n",
      "\n",
      "mask starts as 1 (binary ...0001).\n",
      "\n",
      "Process 3:\n",
      "\n",
      "mask <<3 is 8 (binary 1000). mask becomes 1 | 8 = 9 (binary 1001). This represents sums 0 and 3.\n",
      "\n",
      "Process 4:\n",
      "\n",
      "mask <<4 is 9 <<4 = 144 (binary 10010000). OR with 9 gives 10010000 | 00001001 = 10011001 (153). Now, mask is 153. The possible sums are 0,3,4,7.\n",
      "\n",
      "Process 6:\n",
      "\n",
      "mask <<6 is 153 <<6 = 153 * 64 = 9792. In binary, 10011001 shifted left by 6 is 10011001000000. OR with 153 gives 10011001000000 | 0000000010011001 = 1001100110011001. Then, mask is this value, but we need to mask with (1 << 11) -1 (since K is 10, 10+1=11 bits). So (1 <<11) -1 is 2047. So after masking, the mask would be 10011001000000 | 0000000010011001 = 1001100110011001 (binary). Wait, but after shifting and OR'ing, the sum can be up to 3+4+6=13. But since K is 10, any sum beyond 10 is irrelevant. So when we apply mask &= (1 << (K+1)) -1, which is 2047 (binary 11111111111), the bits beyond the 10th position are cleared. So after processing 6:\n",
      "\n",
      "mask after <<6 would be 153 <<6 = 153 *64= 9792. Binary of 9792 is 10011001000000. Then OR with 153 (1001 1001) gives 10011001000000 | 0000000010011001 = 1001100110011001. Then, after masking with 2047 (binary 11111111111), which is 11 bits. So 1001100110011001 in binary is 16 bits. When ANDed with 2047 (11 bits), the higher bits are masked out. So 1001100110011001 & 0000011111111111 (assuming leading zeros) would be 0010011001 (binary). Wait, perhaps I'm getting the bit positions wrong. Let's see: 2047 is 0b11111111111 (11 ones). So any bits beyond the 11th position (starting from 0) are masked out.\n",
      "\n",
      "So 9792 in binary is 10011001000000. Let's count the bits. 9792 is 13 bits (since 2^13 is 8192, 2^13=8192, 2^14=16384. 9792 is between 8192 and 16384, so 14 bits? Wait, 8192 is 13 bits. 8192 is 2^13. So 9792 is 1001 1001 0000 0000. That's 14 bits. When we shift mask (153) by 6, we get 153 <<6 = 153 *64 = 9792. So binary 10011001000000. Then, when ORed with 153 (binary 10011001), the result is 10011001000000 | 0000000010011001 = 1001100110011001. Then, after masking with 2047 (binary 11111111111), which is 11 bits. The mask now becomes the bits of 1001100110011001 that fit into the first 11 bits. So the first 11 bits (from the right) are 00110011001. Let's compute 0b00110011001. That is 1 + 8 + 16 + 128 + 256 = 1+8=9, 9+16=25, 25+128=153, 153+256=409? Wait, 256 is 2^8. 0b00110011001 is:\n",
      "\n",
      "Positions (from right, 0-based):\n",
      "\n",
      "0: 1 (1)\n",
      "\n",
      "3: 8\n",
      "\n",
      "4: 16\n",
      "\n",
      "7: 128\n",
      "\n",
      "8: 256\n",
      "\n",
      "So total is 1+8+16+128+256 = 409. So mask is 409. What's the significance of that? It represents the possible sums. Let's see:\n",
      "\n",
      "The binary 00110011001 is 409 in decimal. The bits set are positions 0, 3,4,7,8. So possible sums are 0,3,4,7,8.\n",
      "\n",
      "Wait, but after processing 4, the mask had sums 0,3,4,7. Then processing 6:\n",
      "\n",
      "mask <<6 would add 6 to each of the existing sums.\n",
      "\n",
      "So 0+6=6, 3+6=9,4+6=10,7+6=13. But since K is 10, 13 is beyond. So when we OR the original sums (0,3,4,7) with the new sums (6,9,10), and mask to K+1=11 bits (sum up to 10), the new sums are 0,3,4,6,7,9,10. So after processing 6, the mask would have 10 as a possible sum. So the answer should be 1. But according to the code, after processing 6, the mask would have the 10th bit set. Let's see:\n",
      "\n",
      "After processing 6, the mask is 153 <<6 OR 153 (original mask). Let's compute:\n",
      "\n",
      "Original mask after processing 4 is 153 (binary 10011001). So possible sums are 0,3,4,7. Then, shifting by 6 gives 3+6=9, 4+6=10, 7+6=13 (masked out), 0+6=6. So new sums are 6,9,10. So when we OR the original mask (0,3,4,7) with these new sums, the mask becomes 0,3,4,6,7,9,10. The mask for 10 is set, so the code would output 1 here. So during processing 6, after the shift and OR, the 10th bit is set, so the code can break early if possible. But in Python, it's possible that after processing 6, the mask already includes K, so the remaining numbers can be skipped.\n",
      "\n",
      "So this approach works for the first example.\n",
      "\n",
      "The second test case: K=2. Numbers are 1,3,4.\n",
      "\n",
      "Processing:\n",
      "\n",
      "mask starts as 1.\n",
      "\n",
      "Process 1: mask <<1 is 2. OR with 1 gives 3 (binary 11). mask is 3, which represents sums 0 and 1.\n",
      "\n",
      "Process 3: since 3>2, skip.\n",
      "\n",
      "Process 4: skip.\n",
      "\n",
      "mask is 3 (binary 11). The 2nd bit (sum=2) is not set, so output 0.\n",
      "\n",
      "This matches the sample.\n",
      "\n",
      "Now, the time complexity. For each number in the set, the code performs a left shift and OR, then a mask. Each of these operations is O(1) in Python for integers. For each test case, the number of operations is O(N), which for N=1e3 and T=1e3 is 1e6 operations. That's manageable in Python.\n",
      "\n",
      "Therefore, the bitmask approach is feasible.\n",
      "\n",
      "Now, code:\n",
      "\n",
      "Read T test cases.\n",
      "\n",
      "For each test case:\n",
      "\n",
      "Read N and K.\n",
      "\n",
      "Read the list S.\n",
      "\n",
      "Initialize mask = 1.\n",
      "\n",
      "For each num in S:\n",
      "\n",
      "   if num ==0 or num > K: continue.\n",
      "\n",
      "   mask |= mask << num\n",
      "\n",
      "   mask &= (1 << (K+1)) -1  # to keep only up to K bits.\n",
      "\n",
      "Then, check if (mask & (1 << K)) != 0. Output 1 if yes, else 0.\n",
      "\n",
      "Wait, but what if K is 0? But according to the problem statement, K is >0, so we don't have to handle that case.\n",
      "\n",
      "But wait, in the input, K can be up to 999. So the code is correct.\n",
      "\n",
      "But need to note that in the problem statement, the elements can be zero. So if a subset includes zero, the sum is not changed. But since K is positive, the presence of zeros in the set doesn't affect the sum. So including or excluding them doesn't help reach K. So we can safely skip them.\n",
      "\n",
      "Now, code:\n",
      "\n",
      "In Python:\n",
      "\n",
      "Read T.\n",
      "\n",
      "For each T:\n",
      "\n",
      "n, k = map(int, input().split())\n",
      "\n",
      "s = list(map(int, input().split()))\n",
      "\n",
      "mask = 1\n",
      "\n",
      "for num in s:\n",
      "\n",
      "    if num ==0 or num >k:\n",
      "\n",
      "        continue\n",
      "\n",
      "    mask |= mask << num\n",
      "\n",
      "    mask &= (1 << (k+1)) -1\n",
      "\n",
      "if mask & (1 << k):\n",
      "\n",
      "    print(1)\n",
      "\n",
      "else:\n",
      "\n",
      "    print(0)\n",
      "\n",
      "But wait, for example, if the same number is added multiple times? No, the code considers each number once, and since the mask is built by left shifting, which is equivalent to adding the number once. So each element is considered once.\n",
      "\n",
      "This should work.\n",
      "\n",
      "Testing the first example:\n",
      "\n",
      "Test case 1:\n",
      "\n",
      "After processing 3,4,6: mask includes 10.\n",
      "\n",
      "Yes, output 1.\n",
      "\n",
      "Test case 2: mask after processing 1 is 3. 3 in binary is 11. So 2nd bit (value 2) is not set (since bits are 0-based). So 1 << 2 is 4. 3 &4 is 0, so output 0.\n",
      "\n",
      "Another test case: K=6, S=[3,3].\n",
      "\n",
      "The code would process the first 3: mask becomes 1 | 8 = 9 (binary 1001). Then the second 3. mask <<3 is 9 <<3 = 72 (1001000). OR with 9 gives 1001000 | 0001001 = 1001001 (73). The mask after AND (1<<7)-1 is 73. 73 is 1001001. The bits set are 0,3,6. So K=6 is set. Output 1. But the subset is 3+3=6. So correct.\n",
      "\n",
      "Another test case: K=5, S=[2,3]. mask starts as 1. Process 2: mask becomes 1 | 4 =5 (101). Process 3: mask <<3 is 5<<3=40. OR with 5 gives 45. 45 is 101101. The bits set are 0,2,3,5. So 5 is present. Output 1. Which is correct (3+2=5).\n",
      "\n",
      "So the code works.\n",
      "\n",
      "So the code should handle all test cases correctly.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    input = sys.stdin.read().split()\n",
      "    idx = 0\n",
      "    T = int(input[idx])\n",
      "    idx +=1\n",
      "    for _ in range(T):\n",
      "        N, K = int(input[idx]), int(input[idx+1])\n",
      "        idx +=2\n",
      "        S = list(map(int, input[idx:idx+N]))\n",
      "        idx +=N\n",
      "        mask = 1\n",
      "        for num in S:\n",
      "            if num == 0 or num > K:\n",
      "                continue\n",
      "            mask |= mask << num\n",
      "            mask &= (1 << (K+1)) -1  # Keep only up to K bits\n",
      "        if mask & (1 << K):\n",
      "            print(1)\n",
      "        else:\n",
      "            print(0)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "codechef\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "UNKNOWN_DIFFICULTY\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    input = sys.stdin.read().split()\n",
      "    idx = 0\n",
      "    T = int(input[idx])\n",
      "    idx +=1\n",
      "    for _ in range(T):\n",
      "        N, K = int(input[idx]), int(input[idx+1])\n",
      "        idx +=2\n",
      "        S = list(map(int, input[idx:idx+N]))\n",
      "        idx +=N\n",
      "        mask = 1\n",
      "        for num in S:\n",
      "            if num == 0 or num > K:\n",
      "                continue\n",
      "            mask |= mask << num\n",
      "            mask &= (1 << (K+1)) -1  # Keep only up to K bits\n",
      "        if mask & (1 << K):\n",
      "            print(1)\n",
      "        else:\n",
      "            print(0)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "c9b38a543b4ef0e6ff5c3723ec010ebd\n",
      "\"There are n persons who initially don't know each other. On each morning, two of them, who were not\n",
      "(...TRUNCATED)\n",
      "\"<think>\\nOkay, let's see. The problem is to find for each day after adding a new friendship, the ma\n",
      "(...TRUNCATED)\n",
      "codeforces\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "11\n",
      "\"import sys\\nfrom collections import deque\\n\\ndef main():\\n    input = sys.stdin.read().split()\\n\n",
      "(...TRUNCATED)\n",
      "d8321e50eedc1aa555c804b13f80d197\n",
      "\"Let's call a string a phone number if it has length 11 and fits the pattern \\\"8xxxxxxxxxx\\\", where\n",
      "(...TRUNCATED)\n",
      "\"<think>\\nOkay, let's see. The problem is about finding the maximum number of phone numbers we can c\n",
      "(...TRUNCATED)\n",
      "codeforces\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "7\n",
      "\"n = int(input())\\ns = input().strip()\\ncount_8 = s.count('8')\\nmax_phones = n // 11\\nprint(min(coun\n",
      "(...TRUNCATED)\n",
      "11844e142b5a486ec5d9cdac9a026562\n",
      "\"You are given q queries in the following form:\\n\\nGiven three integers l_i, r_i and d_i, find minim\n",
      "(...TRUNCATED)\n",
      "\"<think>\\nOkay, I need to solve this programming problem. Let's read the question carefully.\\n\\nSo,\n",
      "(...TRUNCATED)\n",
      "codeforces\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "7\n",
      "\"q = int(input())\\nfor _ in range(q):\\n    l, r, d = map(int, input().split())\\n    if d < l:\\n\n",
      "(...TRUNCATED)\n",
      "5d4b200b67053c08ff60889967ad689a\n",
      "\"In Byteland, there are two political parties fighting for seats in the Parliament in the upcoming e\n",
      "(...TRUNCATED)\n",
      "\"<think>\\nOkay, let's tackle this problem. Hmm, the problem is about determining if the Wrong Answer\n",
      "(...TRUNCATED)\n",
      "codeforces\n",
      "cc-by-4.0\n",
      "code_contests\n",
      "train\n",
      "VERY_HARD\n",
      "\"import sys\\nfrom sys import stdin\\nfrom collections import deque\\n\\ndef main():\\n    sys.setrecursi\n",
      "(...TRUNCATED)\n",
      "End of preview.\n",
      "Expand\n",
      "in\n",
      "Data Studio\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "1,704\n",
      "Next\n",
      "Data Overview\n",
      "Data distribution\n",
      "Data Fields\n",
      "How to use it\n",
      "Dataset Characterization\n",
      "License/Terms of Use\n",
      "Use Case:\n",
      "Release Date:\n",
      "Data Version\n",
      "Intended use\n",
      "Ethical Considerations:\n",
      "Citation\n",
      "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding\n",
      "Data Overview\n",
      "OpenCodeReasoning is the largest reasoning-based synthetic dataset to date for coding, comprises 735,255 samples in Python across 28,319 unique competitive programming \n",
      "questions. OpenCodeReasoning is designed for supervised fine-tuning (SFT).\n",
      "Technical Report\n",
      "- Discover the methodology and technical details behind OpenCodeReasoning.\n",
      "Github Repo\n",
      "- Access the complete pipeline used to perform SFT.\n",
      "This dataset is ready for commercial/non-commercial use.\n",
      "Data distribution\n",
      "The CodeForces problems are sourced from\n",
      "http://codeforces.com\n",
      ".\n",
      "The question collections are gathered from TACO (\n",
      "https://huggingface.co/datasets/BAAI/TACO\n",
      "), APPS (\n",
      "https://huggingface.co/datasets/codeparrot/apps\n",
      "), CodeContests \n",
      "(\n",
      "https://huggingface.co/datasets/deepmind/code_contests\n",
      "), and open-r1/codeforces (\n",
      "https://huggingface.co/datasets/open-r1/codeforces\n",
      ").\n",
      "We do not include the test split of CodeContests and open-r1/codeforces.\n",
      "The output responses are generated by R1.\n",
      "Source\n",
      "# Question\n",
      "# Sample\n",
      "AIZU\n",
      "2123\n",
      "62,476\n",
      "AtCoder\n",
      "2043\n",
      "47,222\n",
      "CodeChef\n",
      "3796\n",
      "72,925\n",
      "CodeForces\n",
      "10069\n",
      "386,948\n",
      "Codewars\n",
      "2493\n",
      "34,326\n",
      "GeeksForGeeks\n",
      "2667\n",
      "37,602\n",
      "HackerEarth\n",
      "2269\n",
      "59,181\n",
      "HackerRank\n",
      "895\n",
      "10,955\n",
      "Kattis\n",
      "1187\n",
      "13,095\n",
      "LeetCode\n",
      "777\n",
      "10,525\n",
      "Total\n",
      "28,319\n",
      "735,255\n",
      "Data Fields\n",
      "Field\n",
      "Type\n",
      "Description\n",
      "id\n",
      "string\n",
      "A unique id for each question\n",
      "input\n",
      "string\n",
      "The input competitive programming question (split_0 only). For split_1, user needs to get the question based on the dataset/split/index fields.\n",
      "output\n",
      "string\n",
      "R1's response.\n",
      "solution\n",
      "string\n",
      "Only the code portion of R1's response.\n",
      "dataset\n",
      "string\n",
      "The name of the dataset from which this question is collected from (e.g., \"apps\", \"taco\", \"code_contests\")\n",
      "license\n",
      "string\n",
      "The license associated with the dataset (e.g., \"mit\", \"apache-2.0\", \"cc-by-4.0\")\n",
      "split\n",
      "string\n",
      "The name of the split of the dataset from which this question is collected from (e.g., \"train\", \"valid\", \"test\")\n",
      "source\n",
      "string\n",
      "The name of the competitive programming platform (e.g., CodeForces, CodeChef)\n",
      "difficulty\n",
      "string\n",
      "A difficulty label for the input question.\n",
      "index\n",
      "string\n",
      "An index to retrieve the input question from APPS/TACO dataset (only available for split_1).\n",
      "How to use it\n",
      "You can load the dataset with the following lines of code.\n",
      "from\n",
      "datasets\n",
      "import\n",
      "load_dataset\n",
      "\n",
      "ocr_ds_split_0 = load_dataset(\n",
      "\"nvidia/OpenCodeReasoning\"\n",
      ",\n",
      "\"split_0\"\n",
      ")\n",
      "print\n",
      "(ocr_ds_split_0)\n",
      "DatasetDict({\n",
      "    split_0: Dataset({\n",
      "        features: [\n",
      "'id'\n",
      ",\n",
      "'input'\n",
      ",\n",
      "'output'\n",
      ",\n",
      "'source'\n",
      ",\n",
      "'license'\n",
      ",\n",
      "'dataset'\n",
      ",\n",
      "'split'\n",
      ",\n",
      "'difficulty'\n",
      ",\n",
      "'solution'\n",
      "],\n",
      "        num_rows:\n",
      "567850\n",
      "})\n",
      "})\n",
      "\n",
      "ocr_ds_split_1 = load_dataset(\n",
      "\"nvidia/OpenCodeReasoning\"\n",
      ",\n",
      "\"split_1\"\n",
      ")\n",
      "print\n",
      "(ocr_ds_split_1)\n",
      "DatasetDict({\n",
      "    split_1: Dataset({\n",
      "        features: [\n",
      "'id'\n",
      ",\n",
      "'index'\n",
      ",\n",
      "'input'\n",
      ",\n",
      "'output'\n",
      ",\n",
      "'source'\n",
      ",\n",
      "'license'\n",
      ",\n",
      "'dataset'\n",
      ",\n",
      "'split'\n",
      ",\n",
      "'difficulty'\n",
      ",\n",
      "'solution'\n",
      "],\n",
      "        num_rows:\n",
      "167405\n",
      "})\n",
      "})\n",
      "\n",
      "datasets = {\n",
      "\"taco\"\n",
      ": load_dataset(\n",
      "\"BAAI/TACO\"\n",
      "),\n",
      "\"apps\"\n",
      ": load_dataset(\n",
      "\"codeparrot/apps\"\n",
      ")\n",
      "}\n",
      "for\n",
      "item\n",
      "in\n",
      "tqdm(ocr_ds_split_1[\n",
      "\"train\"\n",
      "]):\n",
      "assert\n",
      "item[\n",
      "\"input\"\n",
      "] ==\n",
      "\"-\"\n",
      "assert\n",
      "item[\n",
      "\"dataset\"\n",
      "]\n",
      "in\n",
      "[\n",
      "\"taco\"\n",
      ",\n",
      "\"apps\"\n",
      "]\n",
      "    item[\n",
      "\"input\"\n",
      "] = datasets[item[\n",
      "\"dataset\"\n",
      "]][item[\n",
      "\"split\"\n",
      "]][\n",
      "int\n",
      "(item[\n",
      "\"index\"\n",
      "])][\n",
      "\"question\"\n",
      "]\n",
      "Dataset Characterization\n",
      "** Data Collection Method\n",
      "[Hybrid: Automated, Synthetic]\n",
      "** Labeling Method\n",
      "[Hybrid: Automated, Synthetic]\n",
      "License/Terms of Use\n",
      "This dataset is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0) available at\n",
      "https://creativecommons.org/licenses/by/4.0/legalcode\n",
      ".\n",
      "Data Developer:\n",
      "NVIDIA\n",
      "Use Case:\n",
      "Developers training LLMs to distill reasoning capabilities for code generation.\n",
      "Release Date:\n",
      "04/04/2025\n",
      "Data Version\n",
      "1.0 (04/04/2025)\n",
      "Intended use\n",
      "The OpenCodeReasoning Dataset is intended to be used by the community to continue to improve open models. The data may be freely used to train models.\n",
      "However, for \n",
      "each dataset an user elects to use, the user is responsible for checking if the dataset license is fit for the intended purpose\n",
      ".\n",
      "Ethical Considerations:\n",
      "NVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications.  When downloaded or used in accordance with our terms of service, developers should work with their internal model team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse.\n",
      "Please report security vulnerabilities or NVIDIA AI Concerns\n",
      "here\n",
      ".\n",
      "Citation\n",
      "If you find the data useful, please cite:\n",
      "@article{ahmad2025opencodereasoning,\n",
      "      title={OpenCodeReasoning: Advancing Data Distillation for Competitive Coding}, \n",
      "      author={Wasi Uddin Ahmad, Sean Narenthiran, Somshubra Majumdar, Aleksander Ficek, Siddhartha Jain, Jocelyn Huang, Vahid Noroozi, Boris Ginsburg},\n",
      "      year={2025},\n",
      "      eprint={2504.01943},\n",
      "      archivePrefix={arXiv},\n",
      "      primaryClass={cs.CL},\n",
      "      url={https://arxiv.org/abs/2504.01943}, \n",
      "}\n",
      "Downloads last month\n",
      "14,042\n",
      "Use this dataset\n",
      "Size of the auto-converted Parquet files (First 5GB per split):\n",
      "3.59 GB\n",
      "Number of rows (First 5GB per split):\n",
      "337,766\n",
      "Estimated number of rows:\n",
      "752,713\n",
      "Models trained or fine-tuned on\n",
      "nvidia/OpenCodeReasoning\n",
      "mradermacher/Hicoder-R1-Distill-Gemma-27B-i1-GGUF\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "1.2k\n",
      "•\n",
      "2\n",
      "Mungert/OpenCodeReasoning-Nemotron-32B-GGUF\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "633\n",
      "•\n",
      "2\n",
      "Mungert/OpenCodeReasoning-Nemotron-7B-GGUF\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "577\n",
      "•\n",
      "1\n",
      "Mungert/OpenCodeReasoning-Nemotron-14B-GGUF\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "507\n",
      "•\n",
      "2\n",
      "bartowski/nvidia_OpenCodeReasoning-Nemotron-14B-GGUF\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "12 days ago\n",
      "•\n",
      "498\n",
      "•\n",
      "2\n",
      "mradermacher/Hicoder-R1-Distill-Gemma-27B-GGUF\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "476\n",
      "•\n",
      "1\n",
      "Browse 170 models trained on this dataset\n",
      "Spaces using\n",
      "nvidia/OpenCodeReasoning\n",
      "3\n",
      "💬\n",
      "bunyaminergen/Qwen2.5-Coder-1.5B-Instruct-Reasoning\n",
      "💬\n",
      "segestic/Qwen2.5-Coder-1.5B-Instruct-Reasoning\n",
      "⚡\n",
      "S-Dreamer/Salesforce-codet5-large\n",
      "Collections including\n",
      "nvidia/OpenCodeReasoning\n",
      "OpenCodeReasoning\n",
      "Collection\n",
      "Reasoning data for supervised finetuning of LLMs to advance data distillation for competitive coding\n",
      "•\n",
      "7 items\n",
      "•\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "16\n",
      "OpenCodeReasoning-II\n",
      "Collection\n",
      "Reasoning data for supervised finetuning of LLMs to advance code generation and critique\n",
      "•\n",
      "5 items\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "8\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Intellect-2 RL Dataset\n",
      "Webpage Title:\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset · Datasets at Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Datasets:\n",
      "PrimeIntellect\n",
      "/\n",
      "INTELLECT-2-RL-Dataset\n",
      "like\n",
      "53\n",
      "Follow\n",
      "Prime Intellect\n",
      "281\n",
      "Modalities:\n",
      "Text\n",
      "Formats:\n",
      "parquet\n",
      "Size:\n",
      "100K - 1M\n",
      "ArXiv:\n",
      "arxiv:\n",
      "2505.07291\n",
      "Libraries:\n",
      "Datasets\n",
      "Dask\n",
      "Croissant\n",
      "+ 1\n",
      "License:\n",
      "apache-2.0\n",
      "Dataset card\n",
      "Data Studio\n",
      "Files\n",
      "Files and versions\n",
      "Community\n",
      "2\n",
      "Dataset Viewer\n",
      "Auto-converted\n",
      "to Parquet\n",
      "API\n",
      "Embed\n",
      "Data Studio\n",
      "Subset (1)\n",
      "default\n",
      "·\n",
      "285k rows\n",
      "default (285k rows)\n",
      "Split (1)\n",
      "train\n",
      "·\n",
      "285k rows\n",
      "train (285k rows)\n",
      "SQL\n",
      "Console\n",
      "problem_id\n",
      "string\n",
      "lengths\n",
      "12\n",
      "21\n",
      "task_type\n",
      "string\n",
      "classes\n",
      "2\n",
      "\t\t\t\tvalues\n",
      "prompt\n",
      "string\n",
      "lengths\n",
      "1\n",
      "13.6k\n",
      "verification_info\n",
      "string\n",
      "lengths\n",
      "21\n",
      "78.7M\n",
      "solve_rate_qwen_r1_distill_7b\n",
      "float64\n",
      "0\n",
      "1\n",
      "numina_1.5_0\n",
      "verifiable_math\n",
      "Problem 4. A $5 \\times 100$ table is divided into 500 unit square cells, where $n$ of them are coloured black and the rest are coloured white. Two unit square cells are called adjacent if they share a common side. Each of the unit square cells has at most two adjacent black unit square cells. Find the largest possible value of $n$.\n",
      "{\"ground_truth\": \"302\"}\n",
      "0\n",
      "numina_1.5_4\n",
      "verifiable_math\n",
      "## Problem 4\n",
      "\n",
      "Find all positive integers $x, y, z$ and $t$ such that\n",
      "\n",
      "$$\n",
      "2^{x} \\cdot 3^{y}+5^{z}=7^{t}\n",
      "$$\n",
      "{\"ground_truth\": \"3,1,=2\"}\n",
      "0\n",
      "numina_1.5_8\n",
      "verifiable_math\n",
      "Problem 2. Consider an acute triangle $A B C$ with area S. Let $C D \\perp A B \\quad(D \\in A B)$, $D M \\perp A C \\quad(M \\in A C)$ and $\\quad D N \\perp B C \\quad(N \\in B C)$. Denote by $H_{1}$ and $H_{2}$ the orthocentres of the triangles $M N C$ and $M N D$ respectively. Find the area of the quadrilateral $\\mathrm{AH}_{1} \\mathrm{BH}_{2}$ in terms of $S$.\n",
      "{\"ground_truth\": \"S\"}\n",
      "0.5\n",
      "numina_1.5_12\n",
      "verifiable_math\n",
      "## Problem 1.\n",
      "\n",
      "Find all pairs $(a, b)$ of positive integers such that $a!+b$ and $b!+a$ are both powers of 5 .\n",
      "{\"ground_truth\": \"(1,4),(4,1),(5,5)\"}\n",
      "0\n",
      "numina_1.5_16\n",
      "verifiable_math\n",
      "Problem 1. Find all prime numbers $a, b, c$ and positive integers $k$ which satisfy the equation\n",
      "\n",
      "$$\n",
      "a^{2}+b^{2}+16 \\cdot c^{2}=9 \\cdot k^{2}+1\n",
      "$$\n",
      "{\"ground_truth\": \"(37,3,3,13),(17,3,3,7),(3,37,3,13),(3,17,3,7),(3,3,2,3)\"}\n",
      "0\n",
      "numina_1.5_20\n",
      "verifiable_math\n",
      "C2. Consider a regular $2 n$-gon $P$ in the plane, where $n$ is a positive integer. We say that a point $S$ on one of the sides of $P$ can be seen from a point $E$ that is external to $P$, if the line segment $S E$ contains no other points that lie on the sides of $P$ except $S$. We want to color the sides of $P$ in 3 colors, such that every side is colored in exactly one color, and each color must be used at least once. Moreover, from every point in the plane external to $P$, at most 2 different colors on $P$ can be seen (ignore the vertices of $P$, we consider them colorless). Find the number of distinct such colorings of $P$ (two colorings are considered distinct if at least one side is colored differently).\n",
      "{\"ground_truth\": \"6n\"}\n",
      "0\n",
      "numina_1.5_24\n",
      "verifiable_math\n",
      "A4. Solve the following equation for $x, y, z \\in \\mathbb{N}$\n",
      "\n",
      "$$\n",
      "\\left(1+\\frac{x}{y+z}\\right)^{2}+\\left(1+\\frac{y}{z+x}\\right)^{2}+\\left(1+\\frac{z}{x+y}\\right)^{2}=\\frac{27}{4}\n",
      "$$\n",
      "{\"ground_truth\": \"z\"}\n",
      "0\n",
      "numina_1.5_28\n",
      "verifiable_math\n",
      "A1. Find all ordered triples $(x, y, z)$ of real numbers satisfying the following system of equations:\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "x^{3} & =\\frac{z}{y}-2 \\frac{y}{z} \\\\\n",
      "y^{3} & =\\frac{x}{z}-2 \\frac{z}{x} \\\\\n",
      "z^{3} & =\\frac{y}{x}-2 \\frac{x}{y}\n",
      "\\end{aligned}\n",
      "$$\n",
      "{\"ground_truth\": \"(1,1,-1),(1,-1,1),(-1,1,1),(-1,-1,-1)\"}\n",
      "0\n",
      "numina_1.5_32\n",
      "verifiable_math\n",
      "N6. Find all ordered triples $(x, y, z)$ of integers satisfying the following system of equations:\n",
      "\n",
      "$$\n",
      "\\begin{aligned}\n",
      "x^{2}-y^{2} & =z \\\\\n",
      "3 x y+(x-y) z & =z^{2}\n",
      "\\end{aligned}\n",
      "$$\n",
      "{\"ground_truth\": \"(0,0,0),(1,0,1),(0,1,-1),(1,2,-3),(2,1,3)\"}\n",
      "0\n",
      "numina_1.5_36\n",
      "verifiable_math\n",
      "## C1 BUL\n",
      "\n",
      "A board $n \\times n(n \\geq 3)$ is divided into $n^{2}$ unit squares. Integers from 0 to $n$ included are written down: one integer in each unit square, in such a way that the sums of integers in each $2 \\times 2$ square of the board are different. Find all $n$ for which such boards exist.\n",
      "{\"ground_truth\": \"3\\\\leqn\\\\leq6\"}\n",
      "0\n",
      "numina_1.5_40\n",
      "verifiable_math\n",
      "G2 Let $A B C D$ be a convex quadrilateral with $\\varangle D A C=\\varangle B D C=36^{\\circ}, \\varangle C B D=18^{\\circ}$ and $\\varangle B A C=72^{\\circ}$. If $P$ is the point of intersection of the diagonals $A C$ and $B D$, find the measure of $\\varangle A P D$.\n",
      "{\"ground_truth\": \"108\"}\n",
      "0.5\n",
      "numina_1.5_44\n",
      "verifiable_math\n",
      "## C3\n",
      "\n",
      "For a given positive integer n, two players $A$ and B play the following game: Given is pile of $\\boldsymbol{\\Omega}$ stones. The players take turn alternatively with A going first. On each turn the player is allowed to take one stone, a prime number of stones, or a multiple of $n$ stones. The winner is the one who takes the last stone. Assuming perfect play, find the number of values for $S_{\\infty}$, for which A cannot win.\n",
      "{\"ground_truth\": \"n-1\"}\n",
      "0\n",
      "numina_1.5_48\n",
      "verifiable_math\n",
      "N3\n",
      "\n",
      "Find the integer solutions of the equation\n",
      "\n",
      "$$\n",
      "x^{2}=y^{2}\\left(x+y^{4}+2 y^{2}\\right)\n",
      "$$\n",
      "{\"ground_truth\": \"(x,y)=(0,0),(12,-2),(12,2),(-8,-2),(-8,2)\"}\n",
      "0\n",
      "numina_1.5_52\n",
      "verifiable_math\n",
      "C4. We have a group of $n$ kids. For each pair of kids, at least one has sent a message to the other one. For each kid $A$, among the kids to whom $A$ has sent a message, exactly $25 \\%$ have sent a message to $A$. How many possible two-digit values of $n$ are there?\n",
      "{\"ground_truth\": \"26\"}\n",
      "0.25\n",
      "numina_1.5_56\n",
      "verifiable_math\n",
      "N6. Find all triples $(a, b, c)$ of nonnegative integers that satisfy\n",
      "\n",
      "$$\n",
      "a!+5^{b}=7^{c}\n",
      "$$\n",
      "{\"ground_truth\": \"(,b,)\\\\in{(3,0,1),(1,2,1),(4,2,2)}\"}\n",
      "0\n",
      "numina_1.5_60\n",
      "verifiable_math\n",
      "NT3 Find all positive integers $n$ such that the equation $y^{2}+x y+3 x=n\\left(x^{2}+x y+3 y\\right)$ has at least a solution $(x, y)$ in positive integers.\n",
      "{\"ground_truth\": \"n\\\\in{1,3,4,9}\"}\n",
      "0\n",
      "numina_1.5_64\n",
      "verifiable_math\n",
      "G3 Let $A B C$ be a triangle in which ( $B L$ is the angle bisector of $\\widehat{A B C}(L \\in A C), A H$ is an altitude of $\\triangle A B C(H \\in B C)$ and $M$ is the midpoint of the side $[A B]$. It is known that the midpoints of the segments $[B L]$ and $[M H]$ coincides. Determine the internal angles of triangle $\\triangle A B C$.\n",
      "{\"ground_truth\": \"60\"}\n",
      "1\n",
      "numina_1.5_68\n",
      "verifiable_math\n",
      "Problem A3. Find all pairs $(x, y)$ of real numbers such that $|x|+|y|=1340$ and $x^{3}+y^{3}+2010 x y=670^{3}$.\n",
      "{\"ground_truth\": \"(-670,-670),(1005,-335),(-335,1005)\"}\n",
      "0\n",
      "numina_1.5_72\n",
      "verifiable_math\n",
      "Problem N2. Find all positive integers $n$ such that $36^{n}-6$ is a product of two or more consecutive positive integers.\n",
      "{\"ground_truth\": \"1\"}\n",
      "0.25\n",
      "numina_1.5_76\n",
      "verifiable_math\n",
      "C3. Consider any four pairwise distinct real numbers and write one of these numbers in each cell of a $5 \\times 5$ array so that each number occurs exactly once in every $2 \\times 2$ subarray. The sum over all entries of the array is called the total sum of that array. Determine the maximum number of distinct total sums that may be obtained in this way.\n",
      "{\"ground_truth\": \"60\"}\n",
      "0\n",
      "numina_1.5_80\n",
      "verifiable_math\n",
      "N4. Find all triples of integers $(a, b, c)$ such that the number\n",
      "\n",
      "$$\n",
      "N=\\frac{(a-b)(b-c)(c-a)}{2}+2\n",
      "$$\n",
      "\n",
      "is a power of 2016 .\n",
      "{\"ground_truth\": \"(,b,)=(k+2,k+1,k),k\\\\in\\\\mathbb{Z}\"}\n",
      "0\n",
      "numina_1.5_84\n",
      "verifiable_math\n",
      "A 3. Find all triples of positive real numbers $(a, b, c)$ so that the expression\n",
      "\n",
      "$$\n",
      "M=\\frac{(a+b)(b+c)(a+b+c)}{a b c}\n",
      "$$\n",
      "\n",
      "gets its least value.\n",
      "{\"ground_truth\": \"==\\\\sqrt[3]{\\\\frac{1+\\\\sqrt{5}}{2}},b=\\\\frac{1}{}\"}\n",
      "0\n",
      "numina_1.5_88\n",
      "verifiable_math\n",
      "A 2. Find the maximum positive integer $k$ such that for any positive integers $m, n$ such that $m^{3}+n^{3}>$ $(m+n)^{2}$, we have\n",
      "\n",
      "$$\n",
      "m^{3}+n^{3} \\geq(m+n)^{2}+k\n",
      "$$\n",
      "{\"ground_truth\": \"10\"}\n",
      "0.75\n",
      "numina_1.5_92\n",
      "verifiable_math\n",
      "C 2. A set $T$ of $n$ three-digit numbers has the following five properties:\n",
      "\n",
      "(1) No number contains the digit 0 .\n",
      "\n",
      "(2) The sum of the digits of each number is 9 .\n",
      "\n",
      "(3) The units digits of any two numbers are different.\n",
      "\n",
      "(4) The tens digits of any two numbers are different.\n",
      "\n",
      "(5) The hundreds digits of any two numbers are different.\n",
      "\n",
      "Find the largest possible value of $n$.\n",
      "{\"ground_truth\": \"5\"}\n",
      "0\n",
      "numina_1.5_96\n",
      "verifiable_math\n",
      "A2 Find the maximum value of $z+x$, if $(x, y, z, t)$ satisfies the conditions:\n",
      "\n",
      "$$\n",
      "\\left\\{\\begin{array}{l}\n",
      "x^{2}+y^{2}=4 \\\\\n",
      "z^{2}+t^{2}=9 \\\\\n",
      "x t+y z \\geq 6\n",
      "\\end{array}\\right.\n",
      "$$\n",
      "{\"ground_truth\": \"\\\\sqrt{13}\"}\n",
      "1\n",
      "numina_1.5_100\n",
      "verifiable_math\n",
      "G2 In a right trapezoid $A B C D(A B \\| C D)$ the angle at vertex $B$ measures $75^{\\circ}$. Point $H$ is the foot of the perpendicular from point $A$ to the line $B C$. If $B H=D C$ and $A D+A H=8$, find the area of $A B C D$.\n",
      "{\"ground_truth\": \"8\"}\n",
      "0.5\n",
      "numina_1.5_104\n",
      "verifiable_math\n",
      "NT4 Determine all prime numbers $p_{1}, p_{2}, \\ldots, p_{12}, p_{13}, p_{1} \\leq p_{2} \\leq \\ldots \\leq p_{12} \\leq p_{13}$, such that\n",
      "\n",
      "$$\n",
      "p_{1}^{2}+p_{2}^{2}+\\ldots+p_{12}^{2}=p_{13}^{2}\n",
      "$$\n",
      "\n",
      "and one of them is equal to $2 p_{1}+p_{9}$.\n",
      "{\"ground_truth\": \"(2,2,2,2,2,2,2,3,3,5,7,7,13),(2,2,2,2,2,2,2,3,3,5,7,13,17),(2,2,2,2,2,2,2,3,3,5,7,29,31)\"}\n",
      "0\n",
      "numina_1.5_108\n",
      "verifiable_math\n",
      "C7 Consider a rectangle whose lengths of sides are natural numbers. If someone places as many squares as possible, each with area 3 , inside of the given rectangle, such that\n",
      "the sides of the squares are parallel to the rectangle sides, then the maximal number of these squares fill exactly half of the area of the rectangle. Determine the dimensions of all rectangles with this property.\n",
      "{\"ground_truth\": \"(2,3);(3,4);(3,6);(3,8);(3,10);(3,12)\"}\n",
      "0\n",
      "numina_1.5_112\n",
      "verifiable_math\n",
      "A5. Solve the equation\n",
      "\n",
      "$$\n",
      "8 x^{3}+8 x^{2} y+8 x y^{2}+8 y^{3}=15\\left(x^{2}+y^{2}+x y+1\\right)\n",
      "$$\n",
      "\n",
      "in the set of integers.\n",
      "{\"ground_truth\": \"(x,y)=(1,2)(x,y)=(2,1)\"}\n",
      "0\n",
      "numina_1.5_116\n",
      "verifiable_math\n",
      "NT2. Find all natural numbers $n$ such that $5^{n}+12^{n}$ is perfect square.\n",
      "{\"ground_truth\": \"2\"}\n",
      "0.75\n",
      "numina_1.5_120\n",
      "verifiable_math\n",
      "A5 Determine the positive integers $a, b$ such that $a^{2} b^{2}+208=4\\{l c m[a ; b]+g c d(a ; b)\\}^{2}$.\n",
      "{\"ground_truth\": \"(,b)\\\\in{(2,12);(4,6);(6,4);(12;2)}\"}\n",
      "0\n",
      "numina_1.5_124\n",
      "verifiable_math\n",
      "A3 Let the real parameter $p$ be such that the system\n",
      "\n",
      "$$\n",
      "\\left\\{\\begin{array}{l}\n",
      "p\\left(x^{2}-y^{2}\\right)=\\left(p^{2}-1\\right) x y \\\\\n",
      "|x-1|+|y|=1\n",
      "\\end{array}\\right.\n",
      "$$\n",
      "\n",
      "has at least three different real solutions. Find $p$ and solve the system for that $p$.\n",
      "{\"ground_truth\": \"p=1orp=-1,0\\\\leqx\\\\leq1,withy=\\\\x\"}\n",
      "0\n",
      "numina_1.5_128\n",
      "verifiable_math\n",
      "G3 The vertices $A$ and $B$ of an equilateral $\\triangle A B C$ lie on a circle $k$ of radius 1 , and the vertex $C$ is inside $k$. The point $D \\neq B$ lies on $k, A D=A B$ and the line $D C$ intersects $k$ for the second time in point $E$. Find the length of the segment $C E$.\n",
      "{\"ground_truth\": \"1\"}\n",
      "0.5\n",
      "numina_1.5_132\n",
      "verifiable_math\n",
      "NT4 Find all integers $n$ such that $n^{4}+8 n+11$ is a product of two or more consecutive integers.\n",
      "{\"ground_truth\": \"1\"}\n",
      "1\n",
      "numina_1.5_136\n",
      "verifiable_math\n",
      "NT9 Let $p$ be a prime number. Find all positive integers $a$ and $b$ such that:\n",
      "\n",
      "$$\n",
      "\\frac{4 a+p}{b}+\\frac{4 b+p}{a}\n",
      "$$\n",
      "\n",
      "and\n",
      "\n",
      "$$\n",
      "\\frac{a^{2}}{b}+\\frac{b^{2}}{a}\n",
      "$$\n",
      "\n",
      "are integers.\n",
      "{\"ground_truth\": \"(,b)={(1,1),(2,2),(p,p),(2p,2p),(5,25),(6,18),(18,6),(25,5),(30,150),(150,30)}\"}\n",
      "0\n",
      "numina_1.5_140\n",
      "verifiable_math\n",
      "87.3. Let $f$ be a strictly increasing function defined in the set of natural numbers satisfying the conditions $f(2)=a>2$ and $f(m n)=f(m) f(n)$ for all natural numbers $m$ and $n$. Determine the smallest possible value of $a$.\n",
      "{\"ground_truth\": \"4\"}\n",
      "0.5\n",
      "numina_1.5_144\n",
      "verifiable_math\n",
      "91.1. Determine the last two digits of the number\n",
      "\n",
      "$$\n",
      "2^{5}+2^{5^{2}}+2^{5^{3}}+\\cdots+2^{5^{1991}}\n",
      "$$\n",
      "\n",
      "written in decimal notation.\n",
      "{\"ground_truth\": \"12\"}\n",
      "1\n",
      "numina_1.5_148\n",
      "verifiable_math\n",
      "93.3. Find all solutions of the system of equations\n",
      "\n",
      "$$\n",
      "\\left\\{\\begin{aligned}\n",
      "s(x)+s(y) & =x \\\\\n",
      "x+y+s(z) & =z \\\\\n",
      "s(x)+s(y)+s(z) & =y-4\n",
      "\\end{aligned}\\right.\n",
      "$$\n",
      "\n",
      "where $x, y$, and $z$ are positive integers, and $s(x), s(y)$, and $s(z)$ are the numbers of digits in the decimal representations of $x, y$, and $z$, respectively.\n",
      "{\"ground_truth\": \"(2,8,12)\"}\n",
      "0.25\n",
      "numina_1.5_152\n",
      "verifiable_math\n",
      "97.1. Let A be a set of seven positive numbers. Determine the maximal number of triples $(x, y, z)$ of elements of A satisfying $x<y$ and $x+y=z$.\n",
      "{\"ground_truth\": \"9\"}\n",
      "0.75\n",
      "numina_1.5_156\n",
      "verifiable_math\n",
      "99.1. The function $f$ is defined for non-negative integers and satisfies the condition\n",
      "\n",
      "$$\n",
      "f(n)= \\begin{cases}f(f(n+11)), & \\text { if } n \\leq 1999 \\\\ n-5, & \\text { if } n>1999\\end{cases}\n",
      "$$\n",
      "\n",
      "Find all solutions of the equation $f(n)=1999$.\n",
      "{\"ground_truth\": \"1999=f(6n),ifonlyifn=1,2,\\\\ldots,334\"}\n",
      "0\n",
      "numina_1.5_160\n",
      "verifiable_math\n",
      "01.3. Determine the number of real roots of the equation\n",
      "\n",
      "$$\n",
      "x^{8}-x^{7}+2 x^{6}-2 x^{5}+3 x^{4}-3 x^{3}+4 x^{2}-4 x+\\frac{5}{2}=0\n",
      "$$\n",
      "{\"ground_truth\": \"0\"}\n",
      "0.75\n",
      "numina_1.5_164\n",
      "verifiable_math\n",
      "03.4. Let $\\mathbb{R}^{*}=\\mathbb{R} \\backslash\\{0\\}$ be the set of non-zero real numbers. Find all functions $f: \\mathbb{R}^{*} \\rightarrow \\mathbb{R}^{*}$ satisfying\n",
      "\n",
      "$$\n",
      "f(x)+f(y)=f(x y f(x+y))\n",
      "$$\n",
      "\n",
      "for $x, y \\in \\mathbb{R}^{*}$ and $x+y \\neq 0$.\n",
      "{\"ground_truth\": \"f(x)=\\\\frac{1}{x}\"}\n",
      "0\n",
      "numina_1.5_168\n",
      "verifiable_math\n",
      "06.3. A sequence of positive integers $\\left\\{a_{n}\\right\\}$ is given by\n",
      "\n",
      "$$\n",
      "a_{0}=m \\quad \\text { and } \\quad a_{n+1}=a_{n}^{5}+487\n",
      "$$\n",
      "\n",
      "for all $n \\geq 0$. Determine all values of $m$ for which the sequence contains as many square numbers as possible.\n",
      "{\"ground_truth\": \"9\"}\n",
      "0.25\n",
      "numina_1.5_172\n",
      "verifiable_math\n",
      "09.2. On a faded piece of paper it is possible, with some effort, to discern the following:\n",
      "\n",
      "$$\n",
      "\\left(x^{2}+x+a\\right)\\left(x^{15}-\\ldots\\right)=x^{17}+x^{13}+x^{5}-90 x^{4}+x-90\n",
      "$$\n",
      "\n",
      "Some parts have got lost, partly the constant term of the first factor of the left side, partly the main part of the other factor. It would be possible to restore the polynomial forming the other factor, but we restrict ourselves to asking the question: What is the value of the constant term a? We assume that all polynomials in the statement above have only integer coefficients.\n",
      "{\"ground_truth\": \"2\"}\n",
      "0\n",
      "numina_1.5_176\n",
      "verifiable_math\n",
      "## Problem 3\n",
      "\n",
      "Find all $a \\in \\mathbb{R}$ for which there exists a function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, such that\n",
      "\n",
      "(i) $f(f(x))=f(x)+x$, for all $x \\in \\mathbb{R}$,\n",
      "\n",
      "(ii) $f(f(x)-x)=f(x)+$ ax, for all $x \\in \\mathbb{R}$.\n",
      "{\"ground_truth\": \"\\\\frac{1\\\\\\\\sqrt{5}}{2}\"}\n",
      "0\n",
      "numina_1.5_180\n",
      "verifiable_math\n",
      "Problem 4. The number 1 is written on the blackboard. After that a sequence of numbers is created as follows: at each step each number $a$ on the blackboard is replaced by the numbers $a-1$ and $a+1$; if the number 0 occurs, it is erased immediately; if a number occurs more than once, all its occurrences are left on the blackboard. Thus the blackboard will show 1 after 0 steps; 2 after 1 step; 1,3 after 2 steps; 2, 2, 4 after 3 steps, and so on. How many numbers will there be on the blackboard after $n$ steps?\n",
      "{\"ground_truth\": \"\\\\binom{n}{\\\\lfloor\\\\frac{n}{2}\\\\rfloor}\"}\n",
      "0\n",
      "numina_1.5_184\n",
      "verifiable_math\n",
      "LIV OM - II - Task 3\n",
      "\n",
      "Given is the polynomial $ W(x) = x^4 - 3x^3 + 5x^2 - 9x $. Determine all pairs of different integers $ a $, $ b $ satisfying the equation\n",
      "{\"ground_truth\": \"(-1,0),(0,-1),(1,2),(2,1)\"}\n",
      "0\n",
      "numina_1.5_188\n",
      "verifiable_math\n",
      "XLVI OM - I - Problem 11\n",
      "\n",
      "Given are natural numbers $ n > m > 1 $. From the set $ \\{1,2, \\ldots ,n\\} $, we draw $ m $ numbers without replacement. Calculate the expected value of the difference between the largest and the smallest drawn number.\n",
      "{\"ground_truth\": \"\\\\frac{(n-1)}{n-+1}\"}\n",
      "0\n",
      "numina_1.5_192\n",
      "verifiable_math\n",
      "XXV - I - Task 1\n",
      "\n",
      "During World War I, a battle took place near a certain castle. One of the shells destroyed a statue of a knight with a spear standing at the entrance to the castle. This happened on the last day of the month. The product of the day of the month, the month number, the length of the spear expressed in feet, half the age of the battery commander firing at the castle expressed in years, and half the time the statue stood expressed in years equals 451,066. In which year was the statue erected?\n",
      "{\"ground_truth\": \"1714\"}\n",
      "0\n",
      "numina_1.5_196\n",
      "verifiable_math\n",
      "XXII OM - I - Problem 10\n",
      "\n",
      "Given is a table with $ n $ rows and $ n $ columns. The number located in the $ m $-th column and $ k $-th row is equal to $ n(k - 1) + m $. How should $ n $ numbers be chosen, one from each row and each column, so that the product of these numbers is the largest?\n",
      "{\"ground_truth\": \"a_{1n}a_{2n-1}\\\\ldotsa_{n1}=n(2n-1)(3n-2)(4n-3)\\\\ldots(n^2-(n-1))\"}\n",
      "0\n",
      "numina_1.5_200\n",
      "verifiable_math\n",
      "XL OM - I - Task 5\n",
      "\n",
      "For a given natural number $ n $, determine the number of sequences $ (a_1, a_2, \\ldots , a_n) $ whose terms $ a_i $ belong to the set $ \\{0,1,2,3,4\\} $ and satisfy the condition $ |a_i - a_{i+1}| = 1 $ for $ i = 1,2,\\ldots,n-1 $.\n",
      "{\"ground_truth\": \"notfound\"}\n",
      "0\n",
      "numina_1.5_204\n",
      "verifiable_math\n",
      "XXIV OM - I - Problem 12\n",
      "\n",
      "In a class of n students, a Secret Santa event was organized. Each student draws the name of the person for whom they are to buy a gift, so student $ A_1 $ buys a gift for student $ A_2 $, $ A_2 $ buys a gift for $ A_3 $, ..., $ A_k $ buys a gift for $ A_1 $, where $ 1 \\leq k \\leq n $. Assuming that all drawing outcomes are equally probable, calculate the probability that $ k = n $.\n",
      "{\"ground_truth\": \"\\\\frac{1}{n}\"}\n",
      "0.75\n",
      "numina_1.5_208\n",
      "verifiable_math\n",
      "LI OM - II - Problem 4\n",
      "\n",
      "Point $ I $ is the center of the circle inscribed in triangle $ ABC $, where $ AB \\neq AC $. Lines $ BI $ and $ CI $ intersect sides $ AC $ and $ AB $ at points $ D $ and $ E $, respectively. Determine all possible measures of angle $ BAC $ for which the equality $ DI = EI $ can hold.\n",
      "{\"ground_truth\": \"60\"}\n",
      "0.25\n",
      "numina_1.5_212\n",
      "verifiable_math\n",
      "LVII OM - III - Problem 6\n",
      "\n",
      "Determine all pairs of integers $ a $, $ b $, for which there exists a polynomial $ P(x) $ with integer coefficients, such that the product $ (x^2 + ax + b)\\cdot P(x) $ is a polynomial of the form\n",
      "\n",
      "\n",
      "\n",
      "where each of the numbers $ c_0,c_1,\\dots ,c_{n-1} $ is equal to 1 or -1.\n",
      "{\"ground_truth\": \"(-2,1),(-1,-1),(-1,1),(0,-1),(0,1),(1,-1),(1,1),(2,1)\"}\n",
      "0\n",
      "numina_1.5_216\n",
      "verifiable_math\n",
      "VI OM - II - Task 3\n",
      "\n",
      "What should be the angle at the vertex of an isosceles triangle so that a triangle can be constructed with sides equal to the height, base, and one of the remaining sides of this isosceles triangle?\n",
      "{\"ground_truth\": \"106\"}\n",
      "0\n",
      "numina_1.5_220\n",
      "verifiable_math\n",
      "XXXVI OM - III - Problem 1\n",
      "\n",
      "Determine the largest number $ k $ such that for every natural number $ n $ there are at least $ k $ natural numbers greater than $ n $, less than $ n+17 $, and coprime with the product $ n(n+17) $.\n",
      "{\"ground_truth\": \"1\"}\n",
      "0\n",
      "numina_1.5_224\n",
      "verifiable_math\n",
      "XXXVIII OM - III - Zadanie 5\n",
      "\n",
      "Wyznaczyć najmniejszą liczbę naturalną $ n $, dla której liczba $ n^2-n+11 $ jest iloczynem czterech liczb pierwszych (niekoniecznie różnych).\n",
      "{\"ground_truth\": \"132\"}\n",
      "0\n",
      "numina_1.5_228\n",
      "verifiable_math\n",
      "XXXII - I - Problem 10\n",
      "\n",
      "Determine all functions $ f $ mapping the set of all rational numbers $ \\mathbb{Q} $ to itself that satisfy the following conditions:\n",
      "a) $ f(1)=2 $,\n",
      "b) $ f(xy) = f(x)f(y)-f(x+y)+1 $ for $ x, y \\in \\mathbb{Q} $.\n",
      "{\"ground_truth\": \"f(x)=x+1\"}\n",
      "0.25\n",
      "numina_1.5_232\n",
      "verifiable_math\n",
      "XXXVIII OM - II - Zadanie 4\n",
      "\n",
      "Wyznaczyć wszystkie pary liczb rzeczywistych $ a, b $, dla których wielomiany $ x^4 + 2ax^2 + 4bx + a^2 $ i $ x^3 + ax - b $ mają dwa różne wspólne pierwiastki rzeczywiste.\n",
      "{\"ground_truth\": \"(,0),where0\"}\n",
      "0\n",
      "numina_1.5_236\n",
      "verifiable_math\n",
      "XXXIII OM - III - Problem 1\n",
      "\n",
      "Indicate such a way of arranging $ n $ girls and $ n $ boys around a round table so that the number $ d_n - c_n $ is maximized, where $ d_n $ is the number of girls sitting between two boys, and $ c_n $ is the number of boys sitting between two girls.\n",
      "{\"ground_truth\": \"[\\\\frac{n}{2}]-1\"}\n",
      "0\n",
      "numina_1.5_240\n",
      "verifiable_math\n",
      "LI OM - I - Task 5\n",
      "\n",
      "Determine all pairs $ (a,b) $ of natural numbers for which the numbers $ a^3 + 6ab + 1 $ and $ b^3 + 6ab + 1 $ are cubes of natural numbers.\n",
      "{\"ground_truth\": \"(1,1)\"}\n",
      "0\n",
      "numina_1.5_244\n",
      "verifiable_math\n",
      "L OM - I - Task 3\n",
      "\n",
      "In an isosceles triangle $ ABC $, angle $ BAC $ is a right angle. Point $ D $ lies on side $ BC $, such that $ BD = 2 \\cdot CD $. Point $ E $ is the orthogonal projection of point $ B $ onto line $ AD $. Determine the measure of angle $ CED $.\n",
      "{\"ground_truth\": \"45\"}\n",
      "0.75\n",
      "numina_1.5_248\n",
      "verifiable_math\n",
      "XXXI - I - Task 1\n",
      "\n",
      "Determine for which values of the parameter $ a $ a rhombus with side length $ a $ is a cross-section of a cube with edge length 2 by a plane passing through the center of the cube.\n",
      "{\"ground_truth\": \"[2,\\\\sqrt{5}]\"}\n",
      "0\n",
      "numina_1.5_252\n",
      "verifiable_math\n",
      "I OM - B - Task 1\n",
      "\n",
      "Determine the coefficients $ a $ and $ b $ of the equation $ x^2 + ax + b=0 $ such that the values of $ a $ and $ b $ themselves are roots of this equation.\n",
      "{\"ground_truth\": \"1,0\"}\n",
      "0\n",
      "numina_1.5_256\n",
      "verifiable_math\n",
      "XIX OM - I - Problem 4\n",
      "\n",
      "In the plane, given are parallel lines $ a $ and $ b $ and a point $ M $ lying outside the strip bounded by these lines. Determine points $ A $ and $ B $ on lines $ a $ and $ b $, respectively, such that segment $ AB $ is perpendicular to $ a $ and $ b $, and the angle $ AMB $ is the largest.\n",
      "{\"ground_truth\": \"ABlieonthecirclewithdiameterMN\"}\n",
      "0\n",
      "numina_1.5_260\n",
      "verifiable_math\n",
      "XXIII OM - I - Problem 4\n",
      "\n",
      "Points $ A $ and $ B $ do not belong to the plane $ \\pi $. Find the set of all points $ M \\in \\pi $ with the property that the lines $ AM $ and $ BM $ form equal angles with the plane $ \\pi $.\n",
      "{\"ground_truth\": \"notfound\"}\n",
      "0\n",
      "numina_1.5_264\n",
      "verifiable_math\n",
      "XXXVIII OM - II - Problem 5\n",
      "\n",
      "Determine all prime numbers $ p $ and natural numbers $ x, y $, for which $ p^x - y^3 = 1 $.\n",
      "{\"ground_truth\": \"(2,1,1)(3,2,2)\"}\n",
      "0\n",
      "numina_1.5_268\n",
      "verifiable_math\n",
      "XXXVI OM - I - Zadanie 9\n",
      "\n",
      "W urnie jest 1985 kartek z napisanymi liczbami 1,2,3,..., 1985, każda lczba na innej kartce. Losujemy bez zwracania 100 kartek. Znaleźć wartość oczekiwaną sumy liczb napisanych na wylosowanych kartkach.\n",
      "{\"ground_truth\": \"99300\"}\n",
      "1\n",
      "numina_1.5_272\n",
      "verifiable_math\n",
      "VIII OM - I - Problem 8\n",
      "\n",
      "In the rectangular prism $ ABCDA_1B_1C_1D_1 $, the lengths of the edges are given as $ AA_1 = a $, $ AB = b $, $ AD = c $. On the face $ A_1B_1C_1D_1 $, a point $ M $ is chosen at a distance $ p $ from the side $ A_1B_1 $, and at a distance $ q $ from the side $ A_1D_1 $, and a parallelepiped is constructed with the base $ ABCD $ and the lateral edge $ AM $. Calculate the area of the lateral faces of this parallelepiped.\n",
      "{\"ground_truth\": \"\\\\sqrt{^2+}\"}\n",
      "0\n",
      "numina_1.5_276\n",
      "verifiable_math\n",
      "XV OM - I - Problem 8\n",
      "\n",
      "On three pairwise skew edges of a cube, choose one point on each in such a way that the sum of the squares of the sides of the triangle formed by them is minimized.\n",
      "{\"ground_truth\": \"\\\\frac{9}{2}^2\"}\n",
      "0\n",
      "numina_1.5_280\n",
      "verifiable_math\n",
      "XII OM - I - Problem 3\n",
      "\n",
      "On a plane, a circle $ K $ and a point $ A $ are given. Draw a circle $ L $ passing through point $ A $, so that the lens, which is the common part of both circles, has a given diameter $ a $ and a given thickness $ b $.\n",
      "{\"ground_truth\": \"notfound\"}\n",
      "0\n",
      "numina_1.5_284\n",
      "verifiable_math\n",
      "XIII OM - I - Problem 7\n",
      "\n",
      "Given on a plane are segments $ AB $ and $ CD $. Find on this plane a point $ M $ such that triangles $ AMB $ and $ CMD $ are similar, and at the same time, angle $ AMB $ is equal to angle $ CMD $.\n",
      "{\"ground_truth\": \"notfound\"}\n",
      "0\n",
      "numina_1.5_288\n",
      "verifiable_math\n",
      "V OM - I - Task 2\n",
      "\n",
      "Investigate when the sum of the cubes of three consecutive natural numbers is divisible by $18$.\n",
      "{\"ground_truth\": \"3\"}\n",
      "0\n",
      "numina_1.5_292\n",
      "verifiable_math\n",
      "XXXV OM - III - Problem 1\n",
      "\n",
      "Determine the number of functions $ f $ mapping an $ n $-element set to itself such that $ f^{n-1} $ is a constant function, while $ f^{n-2} $ is not a constant function, where $ f^k = f\\circ f \\circ \\ldots \\circ f $, and $ n $ is a fixed natural number greater than 2.\n",
      "{\"ground_truth\": \"n!\"}\n",
      "0\n",
      "numina_1.5_296\n",
      "verifiable_math\n",
      "XL OM - II - Task 3\n",
      "\n",
      "Given is a trihedral angle $ OABC $ with vertex $ O $ and a point $ P $ inside it. Let $ V $ be the volume of the parallelepiped with two vertices at points $ O $ and $ P $, whose three edges are contained in the rays $ OA^{\\rightarrow} $, $ OB^{\\rightarrow} $, $ OC^{\\rightarrow} $. Calculate the minimum volume of the tetrahedron, whose three faces are contained in the faces of the trihedral angle $ OABC $, and the fourth face contains the point $ P $.\n",
      "{\"ground_truth\": \"\\\\frac{9}{2}V\"}\n",
      "0\n",
      "numina_1.5_300\n",
      "verifiable_math\n",
      "LIX OM - II - Task 1\n",
      "\n",
      "Determine the maximum possible length of a sequence of consecutive integers, each of which can be expressed in the form $ x^3 + 2y^2 $ for some integers $ x, y $.\n",
      "{\"ground_truth\": \"5\"}\n",
      "0.25\n",
      "numina_1.5_304\n",
      "verifiable_math\n",
      "XVI OM - I - Problem 7\n",
      "\n",
      "On the side $ AB $ of triangle $ ABC $, a point $ K $ is chosen, and points $ M $ and $ N $ are determined on the lines $ AC $ and $ BC $ such that $ KM \\perp AC $, $ KN \\perp BC $. For what position of point $ K $ is the area of triangle $ MKN $ the largest?\n",
      "{\"ground_truth\": \"KisthemidpointofsideAB\"}\n",
      "0\n",
      "numina_1.5_308\n",
      "verifiable_math\n",
      "XXVIII - II - Task 3\n",
      "\n",
      "In a hat, there are 7 slips of paper. On the $ n $-th slip, the number $ 2^n-1 $ is written ($ n = 1, 2, \\ldots, 7 $). We draw slips randomly until the sum exceeds 124. What is the most likely value of this sum?\n",
      "{\"ground_truth\": \"127\"}\n",
      "0.25\n",
      "numina_1.5_312\n",
      "verifiable_math\n",
      "XI OM - I - Task 3\n",
      "\n",
      "Each side of a triangle with a given area $ S $ is divided into three equal parts, and the points of division are connected by segments, skipping one point to form two triangles. Calculate the area of the hexagon that is the common part of these triangles.\n",
      "{\"ground_truth\": \"\\\\frac{2}{9}S\"}\n",
      "0.25\n",
      "numina_1.5_316\n",
      "verifiable_math\n",
      "XXV - I - Problem 11\n",
      "\n",
      "Let $ X_n $ and $ Y_n $ be independent random variables with the same distribution $ \\left{ \\left(\\frac{k}{2^n}, \\frac{1}{2^n}\\right) : k = 0, 1, \\ldots, 2^n-1\\right} $. Denote by $ p_n $ the probability of the event that there exists a real number $ t $ satisfying the equation $ t^2 + X_n \\cdot t + Y_n = 0 $. Calculate $ \\lim_{n\\to\\infty} p_n $.\n",
      "{\"ground_truth\": \"\\\\frac{1}{12}\"}\n",
      "0.75\n",
      "numina_1.5_320\n",
      "verifiable_math\n",
      "X OM - II - Task 2\n",
      "\n",
      "Under what relationship between the sides of a triangle is it similar to the triangle formed by its medians?\n",
      "{\"ground_truth\": \"^2=2b^2-^2\"}\n",
      "0\n",
      "numina_1.5_324\n",
      "verifiable_math\n",
      "XXXII - II - Task 4\n",
      "\n",
      "Given are natural numbers $ k, n $. We define inductively two sequences of numbers $ (a_j) $ and $ (r_j) $ as follows:\n",
      "First step: divide $ k $ by $ n $ and obtain the quotient $ a_1 $ and the remainder $ r_1 $,\n",
      "j-th step: divide $ k + r_{j-1} $ by $ n $ and obtain the quotient $ a_j $ and the remainder $ r_j $. Calculate the sum $ a_1 + \\ldots + a_n $.\n",
      "{\"ground_truth\": \"k\"}\n",
      "0.25\n",
      "numina_1.5_328\n",
      "verifiable_math\n",
      "XXII OM - III - Problem 5\n",
      "\n",
      "Find the largest integer $ A $ such that for every permutation of the set of natural numbers not greater than 100, the sum of some 10 consecutive terms is at least $ A $.\n",
      "{\"ground_truth\": \"505\"}\n",
      "0\n",
      "numina_1.5_332\n",
      "verifiable_math\n",
      "XXXVIII OM - I - Problem 6\n",
      "\n",
      "Which of the quadrilaterals having three sides of length 1 has the largest area?\n",
      "{\"ground_truth\": \"notfound\"}\n",
      "0\n",
      "numina_1.5_336\n",
      "verifiable_math\n",
      "XVIII OM - I - Zadanie 10\n",
      "\n",
      "Trójka liczb całkowitych tworzy postęp geometryczny o ilorazie całkowitym. Gdy najmniejszą z nich zwiększymy o 9, powstanie postęp arytmetyczny. Jakie to liczby?\n",
      "{\"ground_truth\": \"(-1,-4,-16),(-1,2,-4),(-9,-18,-36),(2,-4,8)\"}\n",
      "0\n",
      "numina_1.5_340\n",
      "verifiable_math\n",
      "XLIII OM - I - Problem 2\n",
      "\n",
      "In square $ABCD$ with side length $1$, point $E$ lies on side $BC$, point $F$ lies on side $CD$, the measures of angles $EAB$ and $EAF$ are $20^{\\circ}$ and $45^{\\circ}$, respectively. Calculate the height of triangle $AEF$ drawn from vertex $A$.\n",
      "{\"ground_truth\": \"1\"}\n",
      "0.25\n",
      "numina_1.5_344\n",
      "verifiable_math\n",
      "XIX OM - III - Problem 1\n",
      "\n",
      "What is the largest number of regions into which a plane can be divided by $ n $ pairs of parallel lines?\n",
      "{\"ground_truth\": \"2n^2-n+1\"}\n",
      "0\n",
      "numina_1.5_348\n",
      "verifiable_math\n",
      "LIX OM - I - Task 12\n",
      "\n",
      "Given an integer $ m \\geqslant 2 $. Determine the smallest such integer\n",
      "$ n \\geqslant m $, such that for any partition of the set $ \\{m,m+1,\\dots ,n\\} $ into two subsets, at least one of\n",
      "these subsets contains numbers $ a, b, c $ (not necessarily distinct), such that $ ab = c $.\n",
      "{\"ground_truth\": \"^5\"}\n",
      "0\n",
      "numina_1.5_352\n",
      "verifiable_math\n",
      "L OM - I - Problem 11\n",
      "\n",
      "In an urn, there are two balls: a white one and a black one. Additionally, we have 50 white balls and 50 black balls at our disposal. We perform the following action 50 times: we draw a ball from the urn, and then return it to the urn along with one more ball of the same color as the drawn ball. After completing these actions, we have 52 balls in the urn. What is the most probable number of white balls in the urn?\n",
      "{\"ground_truth\": \"51\"}\n",
      "0\n",
      "numina_1.5_356\n",
      "verifiable_math\n",
      "XXVII OM - III - Task 5\n",
      "\n",
      "A fishing vessel is fishing in the territorial waters of a foreign state without permission. Each cast of the net results in a catch of the same value. During each subsequent cast, the probability of the vessel being intercepted by the border guard is $ \\frac{1}{k} $, where $ k $ is a fixed natural number. We assume that the event of the vessel being intercepted or not intercepted during each subsequent cast is independent of the previous course of the fishing. If intercepted by the border guard, the entire catch is confiscated, and further fishing is impossible. The captain plans to return after the $ n $-th cast. Considering the risk of interception, the profit from fishing is a random variable. Find the number $ n $ for which the expected value of the profit is maximized.\n",
      "{\"ground_truth\": \"n=k-1n=k\"}\n",
      "0\n",
      "numina_1.5_360\n",
      "verifiable_math\n",
      "LIX OM - I - Task 9\n",
      "\n",
      "Determine the smallest real number a with the following property: \n",
      "For any real numbers $ x, y, z \\geqslant a $ satisfying the condition $ x + y + z = 3 $\n",
      "the inequality holds\n",
      "{\"ground_truth\": \"-5\"}\n",
      "0\n",
      "numina_1.5_364\n",
      "verifiable_math\n",
      "VI OM - III - Task 6\n",
      "\n",
      "Through points $ A $ and $ B $, two oblique lines $ m $ and $ n $ perpendicular to the line $ AB $ have been drawn. On line $ m $, a point $ C $ (different from $ A $) has been chosen, and on line $ n $, a point $ D $ (different from $ B $). Given the lengths of segments $ AB = d $ and $ CD = l $, and the angle $ \\varphi $ formed by the oblique lines $ m $ and $ n $, calculate the radius of the sphere passing through points $ A $, $ B $, $ C $, $ D $.\n",
      "{\"ground_truth\": \"\\\\sqrt{(\\\\frac{}\"}\n",
      "0\n",
      "numina_1.5_368\n",
      "verifiable_math\n",
      "XXVI - I - Task 1\n",
      "\n",
      "At the ball, there were 42 people. Lady $ A_1 $ danced with 7 gentlemen, Lady $ A_2 $ danced with 8 gentlemen, ..., Lady $ A_n $ danced with all the gentlemen. How many gentlemen were at the ball?\n",
      "{\"ground_truth\": \"24\"}\n",
      "0.75\n",
      "numina_1.5_372\n",
      "verifiable_math\n",
      "L OM - II - Task 5\n",
      "\n",
      "Let $ S = \\{1, 2,3,4, 5\\} $. Determine the number of functions $ f: S \\to S $ satisfying the equation $ f^{50} (x) = x $ for all $ x \\in S $.\n",
      "Note: $ f^{50}(x) = \\underbrace{f \\circ f \\circ \\ldots \\circ f}_{50} (x) $.\n",
      "{\"ground_truth\": \"50\"}\n",
      "0.75\n",
      "numina_1.5_376\n",
      "verifiable_math\n",
      "LIII OM - III - Task 1\n",
      "\n",
      "Determine all such triples of natural numbers $ a $, $ b $, $ c $, such that the numbers $ a^2 +1 $ and $ b^2 +1 $ are prime and\n",
      "{\"ground_truth\": \"(1,2,3)(2,1,3)\"}\n",
      "0\n",
      "numina_1.5_380\n",
      "verifiable_math\n",
      "XLIII OM - II - Problem 5\n",
      "\n",
      "Determine the supremum of the volumes of spheres contained in tetrahedra with all altitudes no longer than $1$.\n",
      "{\"ground_truth\": \"\\\\pi/48\"}\n",
      "0.25\n",
      "numina_1.5_384\n",
      "verifiable_math\n",
      "LVIII OM - I - Problem 4\n",
      "\n",
      "For each natural number $ n\\ge 3 $, determine the number of sequences $ (c_1,c_2,\\ldots,c_n) $, where $ {c_i\\in\\{0,1,\\ldots,9\\}} $, with the following property:\\break in every triple of consecutive terms, there are at least two terms that are equal.\n",
      "{\"ground_truth\": \"5\\\\cdot(4^n+(-2)^n)\"}\n",
      "0.5\n",
      "numina_1.5_388\n",
      "verifiable_math\n",
      "4. Each experience of throwing the circle corresponds to a point $M-$ the position of the center of the circle on the vertical segment $[A ; B]$ of length 1.\n",
      "\n",
      "![](https://cdn.mathpix.com/cropped/2024_05_06_8b002ac84843a2e42fafg-05.jpg?height=315&width=702&top_left_y=1016&top_left_x=382)\n",
      "\n",
      "Let's introduce the following notations: $R$ - the radius of the circle, $O$ - the midpoint of the segment $[A ; B], \\quad O M=x \\in[0 ; 0.5]$ - a random variable uniformly distributed on this segment, $\\alpha$ - the angle indicated in the figure, $A M=h=\\frac{\\cos \\alpha}{2}$.\n",
      "\n",
      "The area of the circular segment $S_{1}$ of a circle with radius $R$ is given by the formula:\n",
      "\n",
      "$$\n",
      "S_{1}=\\left|\\alpha R^{2}-\\frac{1}{2} R^{2} \\sin 2 \\alpha\\right|\n",
      "$$\n",
      "\n",
      "In our case, $R=\\frac{1}{2}$, so,\n",
      "\n",
      "$$\n",
      "S_{1}=\\frac{\\alpha}{4}-\\frac{\\sin 2 \\alpha}{8} .\n",
      "$$\n",
      "\n",
      "From the problem statement, it follows that\n",
      "\n",
      "$$\n",
      "\\left\\{\\begin{array}{c}\n",
      "S_{1}: S_{2}=(\\pi-2):(3 \\pi+2) \\\\\n",
      "S_{1}+S_{2}=\\frac{\\pi}{4}\n",
      "\\end{array}\\right.\n",
      "$$\n",
      "\n",
      "Then $S_{1}=k(\\pi-2)$, and $S_{2}=k(3 \\pi+2)$. Substituting this into the second equality, we get: $S_{1}+S_{2}=k \\cdot 4 \\pi=\\frac{\\pi}{4}$. Therefore, $k=\\frac{1}{16}$. Then, $S_{1}=\\frac{\\alpha}{4}-\\frac{\\sin 2 \\alpha}{8}=\\frac{1}{16}(\\pi-2)$. From this, we find $\\alpha=\\frac{\\pi}{4}$. Thus, the conditions of the problem correspond to the central angle $P M Q$ equal to $\\frac{\\pi}{2}$. Then $h=\\frac{\\sqrt{2}}{4}$ and the favorable outcome of the experiment corresponds to points $M$ that are no more than $\\frac{1}{2}-h=\\frac{2-\\sqrt{2}}{4}$ away from point $O$. Since the probability of the desired event is the ratio of the length of the segment of \"favorable\" outcomes, i.e., $\\frac{2-\\sqrt{2}}{2}$ to the length of the segment $[A ; B]$, i.e., to one, the desired probability $P(A)=\\frac{2-\\sqrt{2}}{2} \\approx 0.29$\n",
      "{\"ground_truth\": \"P(A)=\\\\frac{2-\\\\sqrt{2}}{2}\\\\approx0.29\"}\n",
      "0\n",
      "numina_1.5_392\n",
      "verifiable_math\n",
      "5. For what values of $a$ does the system of equations $\\left\\{\\begin{array}{c}(x+2+2 \\sqrt{2} \\cos a)^{2}+(y-1-2 \\sqrt{2} \\sin a)^{2}=2 \\\\ (x-y+3)(x+y+1)=0\\end{array}\\right.$ have three\n",
      "\n",
      "solutions?\n",
      "{\"ground_truth\": \"a_{1}=\\\\frac{7\\\\pi}{12}+\\\\pik,a_{2}=\\\\frac{11\\\\pi}{12}+\\\\pik,k\\\\inZ\"}\n",
      "0\n",
      "numina_1.5_396\n",
      "verifiable_math\n",
      "5. For what values of $a$ does the system of equations $\\left\\{\\begin{array}{c}(x-2-\\sqrt{5} \\cos a)^{2}+(y+1-\\sqrt{5} \\sin a)^{2}=\\frac{5}{4} \\text { have two solutions? } \\\\ (x-2)(x-y-3)=0\\end{array}\\right.$\n",
      "{\"ground_truth\": \"\\\\in(\\\\frac{\\\\pi}{12}+\\\\pik;\\\\frac{\\\\pi}{3}+\\\\pik)\\\\cup(\\\\frac{5\\\\pi}{12}+\\\\pik;\\\\frac{2\\\\pi}{3}+\\\\pik),k\\\\inZ\"}\n",
      "0\n",
      "End of preview.\n",
      "Expand\n",
      "in\n",
      "Data Studio\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "2,848\n",
      "Next\n",
      "Model Information\n",
      "Usage\n",
      "Performance\n",
      "Citation\n",
      "INTELLECT-2\n",
      "INTELLECT-2 is a 32 billion parameter language model trained through a reinforcement learning run leveraging globally distributed, permissionless GPU resources contributed by the community.\n",
      "The model was trained using\n",
      "prime-rl\n",
      ", a framework designed for distributed asynchronous RL, using GRPO over verifiable rewards along with modifications for improved training stability. For detailed information on our infrastructure and training recipe, see our\n",
      "technical report\n",
      ".\n",
      "Model Information\n",
      "Training Dataset (verifiable math & coding tasks):\n",
      "PrimeIntellect/Intellect-2-RL-Dataset\n",
      "Base Model:\n",
      "QwQ-32B\n",
      "Training Code:\n",
      "prime-rl\n",
      "Usage\n",
      "INTELLECT-2 is based on the\n",
      "qwen2\n",
      "architecture, making it compatible with popular libraries and inference engines such as\n",
      "vllm\n",
      "or\n",
      "sglang\n",
      ".\n",
      "Given that INTELLECT-2 was trained with a length control budget, you will achieve the best results by appending the prompt\n",
      "\"Think for 10000 tokens before giving a response.\"\n",
      "to your instruction. As reported in our technical report, the model did not train for long enough to fully learn the length control objective, which is why results won't differ strongly if you specify lengths other than 10,000. If you wish to do so, you can expect the best results with 2000, 4000, 6000 and 8000, as these were the other target lengths present during training.\n",
      "Performance\n",
      "During training, INTELLECT-2 improved upon QwQ in its mathematical and coding abilities. Performance on IFEval slightly decreased, which can likely be attributed to the lack of diverse training data and pure focus on mathematics and coding.\n",
      "Model\n",
      "AIME24\n",
      "AIME25\n",
      "LiveCodeBench (v5)\n",
      "GPQA-Diamond\n",
      "IFEval\n",
      "INTELLECT-2\n",
      "78.8\n",
      "64.9\n",
      "67.8\n",
      "66.8\n",
      "81.5\n",
      "QwQ-32B\n",
      "76.6\n",
      "64.8\n",
      "66.1\n",
      "66.3\n",
      "83.4\n",
      "Qwen-R1-Distill-32B\n",
      "69.9\n",
      "58.4\n",
      "55.1\n",
      "65.2\n",
      "72.0\n",
      "Deepseek-R1\n",
      "78.6\n",
      "65.1\n",
      "64.1\n",
      "71.6\n",
      "82.7\n",
      "Citation\n",
      "@misc{primeintellectteam2025intellect2reasoningmodeltrained,\n",
      "      title={INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning}, \n",
      "      author={Prime Intellect Team and Sami Jaghouar and Justus Mattern and Jack Min Ong and Jannik Straube and Manveer Basra and Aaron Pazdera and Kushal Thaman and Matthew Di Ferrante and Felix Gabriel and Fares Obeid and Kemal Erdem and Michael Keiblinger and Johannes Hagemann},\n",
      "      year={2025},\n",
      "      eprint={2505.07291},\n",
      "      archivePrefix={arXiv},\n",
      "      primaryClass={cs.LG},\n",
      "      url={https://arxiv.org/abs/2505.07291}, \n",
      "}\n",
      "Downloads last month\n",
      "856\n",
      "Use this dataset\n",
      "Size of downloaded dataset files:\n",
      "1.73 GB\n",
      "Size of the auto-converted Parquet files:\n",
      "1.73 GB\n",
      "Number of rows:\n",
      "284,741\n",
      "Collection including\n",
      "PrimeIntellect/INTELLECT-2-RL-Dataset\n",
      "INTELLECT-2\n",
      "Collection\n",
      "INTELLECT-2 is a 32 billion parameter language model with globally distributed reinforcement learning.\n",
      "•\n",
      "3 items\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "20\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Hugging Face blog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4190166-c768-4ec6-ad51-aa37182a439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about th company for prospective customers, investors and recruits. Repsond in markdown. \\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8fde81-49ba-40ac-8116-0340409fbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page adn other relevant pages; \\\n",
    "    use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000]\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5590635-b40f-49f6-b9d8-b081f58d2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://huggingface.co/brand\"},\n",
      "        {\"type\": \"models page\", \"url\": \"https://huggingface.co/models\"},\n",
      "        {\"type\": \"datasets page\", \"url\": \"https://huggingface.co/datasets\"},\n",
      "        {\"type\": \"spaces page\", \"url\": \"https://huggingface.co/spaces\"},\n",
      "        {\"type\": \"enterprise solutions\", \"url\": \"https://huggingface.co/enterprise\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://huggingface.co/join/discord\"},\n",
      "        {\"type\": \"press information\", \"url\": \"https://huggingface.co/brand\"}\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page adn other relevant pages;     use this information to build a short brochure of the company in markdown.\\nLanding page: \\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nnvidia/parakeet-tdt-0.6b-v2\\nUpdated\\n4 days ago\\n•\\n56.6k\\n•\\n983\\nWan-AI/Wan2.1-VACE-14B\\nUpdated\\n1 day ago\\n•\\n8.8k\\n•\\n200\\nnari-labs/Dia-1.6B\\nUpdated\\n6 days ago\\n•\\n143k\\n•\\n2.27k\\nmultimodalart/isometric-skeumorphic-3d-bnb\\nUpdated\\n5 days ago\\n•\\n550\\n•\\n194\\nlodestones/Chroma\\nUpdated\\n2 days ago\\n•\\n620\\nBrowse 1M+ models\\nSpaces\\nRunning\\n6.8k\\n6.8k\\nDeepSite\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\n265\\n265\\nLTX Video Fast\\n🎥\\nultra-fast video model, LTX 0.9.7 13B distilled\\nRunning\\non\\nCPU Upgrade\\n708\\n708\\nComputer Agent\\n🖥\\nInteract with an AI agent to perform web tasks\\nRunning\\non\\nZero\\n437\\n437\\nDreamO\\n🐨\\nA Unified Framework for Image Customization\\nRunning\\n478\\n478\\nFLUX Pro Unlimited\\n🔥\\nUse the FLUX-Pro model as much as you want.\\nBrowse 400k+ applications\\nDatasets\\nopenbmb/Ultra-FineWeb\\nUpdated\\n11 days ago\\n•\\n8.64k\\n•\\n92\\nPrimeIntellect/INTELLECT-2-RL-Dataset\\nUpdated\\n7 days ago\\n•\\n856\\n•\\n53\\nnvidia/OpenCodeReasoning\\nUpdated\\n15 days ago\\n•\\n14k\\n•\\n425\\nnvidia/OpenMathReasoning\\nUpdated\\n11 days ago\\n•\\n43.5k\\n•\\n243\\nDMindAI/DMind_Benchmark\\nUpdated\\n3 days ago\\n•\\n2.82k\\n•\\n75\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n757 models\\n•\\n3.29k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.13k models\\n•\\n6.03k followers\\nAmazon\\ncompany\\n•\\n20 models\\n•\\n3.17k followers\\nGoogle\\ncompany\\n•\\n991 models\\n•\\n13.4k followers\\nIntel\\ncompany\\n•\\n221 models\\n•\\n2.55k followers\\nMicrosoft\\ncompany\\n•\\n374 models\\n•\\n12.4k followers\\nGrammarly\\nEnterprise\\ncompany\\n•\\n10 models\\n•\\n160 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n21 models\\n•\\n267 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n144,554\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n29,034\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,272\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,606\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,687\\nFast tokenizers optimized for research & production\\nTRL\\n13,814\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,626\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n18,869\\nSmol library to build great agents in Python\\nPEFT\\n18,450\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,139\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,138\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,729\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout page\\nWebpage Title:\\nBrand assets - Hugging Face\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nHugging Face · Brand assets\\nHF Logos\\n.svg\\n.png\\n.ai\\n.svg\\n.png\\n.ai\\n.svg\\n.png\\n.ai\\nHF Colors\\n#FFD21E\\n#FF9D00\\n#6B7280\\nHF Bio\\nHugging Face is the collaboration platform for the machine learning community.\\n\\nThe Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\\n\\nWith the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolut'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\",\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "104fdb9c-efea-4e88-b7a0-3e19677937ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response['message']['content']\n",
    "\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78bb0c5e-e9a7-4c82-9e22-9fd5da00da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"company page\", \"url\": \"https://huggingface.co/enterprise\"},\n",
      "        {\"type\": \"pricing information\", \"url\": \"https://huggingface.co/pricing\"},\n",
      "        {\"type\": \"models page\", \"url\": \"https://huggingface.co/models\"},\n",
      "        {\"type\": \"datasets page\", \"url\": \"https://huggingface.co/datasets\"},\n",
      "        {\"type\": \"spaces page\", \"url\": \"https://huggingface.co/spaces\"},\n",
      "        {\"type\": \"documentation\", \"url\": \"https://huggingface.co/docs\"},\n",
      "        {\"type\": \"chat feature\", \"url\": \"https://endpoints.huggingface.co/chat\"},\n",
      "        {\"type\": \"GitHub repository\", \"url\": \"https://github.com/huggingface\"},\n",
      "        {\"type\": \"Twitter profile\", \"url\": \"https://twitter.com/huggingface\"},\n",
      "        {\"type\": \"LinkedIn company page\", \"url\": \"https://www.linkedin.com/company/huggingface/\"},\n",
      "        {\"type\": \"Discord community\", \"url\": \"https://huggingface.co/join/discord\"}\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, I need to create a short brochure for Hugging Face based on the provided information. Let's start by understanding what the company does and who they cater to.\n",
       "\n",
       "From the landing page, it seems Hugging Face is a platform where the AI community collaborates on models, datasets, and applications. They offer tools like model hosting, dataset sharing, and building applications with spaces. The \"Enterprise\" section provides paid solutions for businesses, including Compute and Enterprise Hub at $20/user/month.\n",
       "\n",
       "The company has various industries as customers, such as Meta (AI at Meta), Amazon, Google, Intel, Microsoft, Grammarly, Writer, etc. This shows Hugging Face is used across different sectors, which is a good point to include.\n",
       "\n",
       "In terms of culture, looking at the \"About\" section or any other mentions, I don't have specific information about their company culture, values, or mission beyond what's implied on the landing page. The website emphasizes collaboration and open-source projects like Transformers, Diffusers, etc., so I can infer a collaborative and open-source-driven culture.\n",
       "\n",
       "For careers, there's a \"Jobs\" section but no detailed info on job openings, salaries, benefits, or work environment. However, from the platform's focus on AI and collaboration, it's likely that Hugging Face offers opportunities in software development, machine learning research, product management, etc., in a dynamic and growing company.\n",
       "\n",
       "Putting this together, I'll structure the brochure with sections: About Us, Products & Services, Our Culture, Customers, and Careers. Each section will include bullet points or concise descriptions based on the provided info.\n",
       "\n",
       "I need to make sure the language is professional but clear, suitable for prospective customers, investors, and recruits. Highlighting their open-source initiatives can attract developers and researchers, while emphasizing enterprise solutions can appeal to businesses.\n",
       "\n",
       "I should also note that Hugging Face has a significant presence with over 50,000 organizations using the platform, which adds credibility.\n",
       "\n",
       "Finally, I'll ensure each section flows logically into the next, providing enough detail without overwhelming the reader.\n",
       "</think>\n",
       "\n",
       "# Hugging Face: Empowering AI Innovation\n",
       "\n",
       "## About Us\n",
       "Hugging Face is at the forefront of AI innovation, serving as a collaborative hub where the global machine learning community thrives. Our mission is to democratize access to powerful tools and resources, fostering advancements in AI through open-source collaboration.\n",
       "\n",
       "## Products & Services\n",
       "### Model Development & Deployment\n",
       "- **Model Hosting**: Showcase your AI models with ease.\n",
       "- **Dataset Sharing**: Access a vast library of datasets for diverse tasks.\n",
       "- **Spaces**: Build and share AI applications seamlessly.\n",
       "\n",
       "### Enterprise Solutions\n",
       "- **Compute Service**: Scalable GPU endpoints for efficient inference.\n",
       "- **Enterprise Hub**: Secure, scalable solutions for organizations.\n",
       "\n",
       "## Our Culture\n",
       "We are driven by collaboration and innovation. Our open-source ethos has propelled projects like Transformers and Diffusers, setting new standards in machine learning research and practice.\n",
       "\n",
       "## Our Customers\n",
       "Hugging Face caters to a diverse range of industries:\n",
       "- Meta (AI at Meta)\n",
       "- Amazon\n",
       "- Google\n",
       "- Intel\n",
       "- Microsoft\n",
       "- Grammarly\n",
       "- Writer\n",
       "\n",
       "Over 50,000 organizations trust us, highlighting our global impact and reliability.\n",
       "\n",
       "## Careers\n",
       "Join Hugging Face in shaping the future of AI. Opportunities span software development, machine learning research, product management, and more, in a dynamic and growing environment.\n",
       "\n",
       "---\n",
       "\n",
       "Hugging Face is your partner in advancing AI—where collaboration meets innovation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80d5f809-4a24-4a02-bf7b-a1fa43903464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name,url):\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        result += chunk['message']['content'] or ''\n",
    "        result = result.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "        update_display(Markdown(result), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77c9878a-6eb1-4e16-8723-ae78cb23fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"company information\", \"url\": \"https://huggingface.co/brand\"},\n",
      "        {\"type\": \"models page\", \"url\": \"https://huggingface.co/models\"},\n",
      "        {\"type\": \"datasets page\", \"url\": \"https://huggingface.co/datasets\"},\n",
      "        {\"type\": \"spaces page\", \"url\": \"https://huggingface.co/spaces\"},\n",
      "        {\"type\": \"partnerships\", \"url\": \"https://huggingface.co/allenai\"},\n",
      "        {\"type\": \"models and datasets\", \"url\": \"https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2\"},\n",
      "        {\"type\": \"documentations\", \"url\": \"https://huggingface.co/docs/transformers\"},\n",
      "        {\"type\": \"jobs page\", \"url\": \"https://huggingface.co/join\"},\n",
      "        {\"type\": \"pricing information\", \"url\": \"https://huggingface.co/pricing\"},\n",
      "        {\"type\": \"endpoints\", \"url\": \"https://endpoints.huggingface.co\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://apply.workable.com/huggingface/\"},\n",
      "        {\"type\": \"social media - linkedin\", \"url\": \"https://www.linkedin.com/company/huggingface/\"},\n",
      "        {\"type\": \"discussions\", \"url\": \"https://discuss.huggingface.co\"},\n",
      "        {\"type\": \"status updates\", \"url\": \"https://status.huggingface.co\"}\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, so I need to create a short brochure for Hugging Face based on the provided information. Let me start by understanding what the user has given.\n",
       "\n",
       "First, they've shared content from Hugging Face's landing page and another relevant page about brand assets. The main goal is to structure this into a  brochure that includes company culture, customers, and career information.\n",
       "\n",
       "Looking at the landing page, I see Hugging Face positions itself as a collaborative platform for AI, focusing on models, datasets, spaces, etc. They emphasize community collaboration, open-source tools, and a growing ecosystem. The brand assets mention logos, colors, and a bio that reinforces their mission to build an open and ethical AI future.\n",
       "\n",
       "Next, the company information page describes Hugging Face as a central place for sharing ML resources, empowering a community of engineers, scientists, and users. They highlight their role in providing tools like Transformers and Diffusers, which are widely used.\n",
       "\n",
       "For customers, I should list notable organizations that use Hugging Face. From the landing page, these include Meta, Amazon, Google, Intel, Microsoft, Grammarly, Writer, and others. Each has a number of models and followers, indicating their active participation.\n",
       "\n",
       "Regarding company culture, the brand assets mention a focus on open-source and collaboration. The website features models and datasets from 1M+ options, showing a diverse and extensive library. They also offer enterprise solutions, which suggests a commitment to both individual and organizational users.\n",
       "\n",
       "Career information isn't explicitly provided, but I can infer that Hugging Face likely has opportunities in AI research, product development, community engagement, and operations given their role as a platform hub.\n",
       "\n",
       "I should structure the brochure into sections: About Us, Products & Services, Customers, Culture, and Careers. Each section will be concise, using bullet points to highlight key information.\n",
       "\n",
       "Now, putting it all together in  format. I'll start with the title, then each section in separate subsections. Make sure to include links where necessary, like to their GitHub or Twitter handles.\n",
       "\n",
       "Wait, should I add contact info? The provided content doesn't mention addresses or phone numbers, so perhaps it's better not to include that unless it's implied by the brand assets section, which only talks about logos and colors. So maybe stick to what's given.\n",
       "\n",
       "Also, for the careers section, since specific job postings aren't provided, I'll have to infer based on their role as a hub for AI talent and community-driven work.\n",
       "\n",
       "I think that covers all the necessary points from the given information.\n",
       "</think>\n",
       "\n",
       "\n",
       "# Hugging Face: The AI Community Hub\n",
       "\n",
       "## About Us\n",
       "\n",
       "Hugging Face is the premier collaborative platform for the global machine learning (ML) community. Our mission is to build a future where open-source AI tools empower innovation and foster ethical practices. We provide a central hub for sharing, exploring, and experimenting with cutting-edge ML models, datasets, and applications.\n",
       "\n",
       "### Key Features\n",
       "- **Open Source Ecosystem**: We are at the forefront of ML tooling, offering state-of-the-art libraries like Transformers and Diffusers.\n",
       "- **Collaboration Platform**: A space where researchers, engineers, and end-users can collaborate on AI projects.\n",
       "- **Diverse Modalities**: Support for text, images, video, audio, and 3D data, catering to a wide range of applications.\n",
       "\n",
       "### Brand Identity\n",
       "- **Logos**: Available in `.svg`, `.png`, and `.ai` formats.\n",
       "- **Colors**: #FFD21E, #FF9D00, #6B7280.\n",
       "- **Bio**: Hugging Face is dedicated to building an open and ethical AI future through community collaboration.\n",
       "\n",
       "## Products & Services\n",
       "\n",
       "### Models\n",
       "Access over 1M+ pre-trained models for various tasks like NLP and computer vision. Notable collections include:\n",
       "- Transformers (144,554)\n",
       "- Diffusers (29,034)\n",
       "- Tokenizers (9,687)\n",
       "\n",
       "### Datasets\n",
       "A comprehensive library of datasets for ML tasks, including:\n",
       "- OpenCodeReasoning (14k)\n",
       "- Text Generation Inference (10,138)\n",
       "- Accelerate (8,729)\n",
       "\n",
       "### Spaces & Applications\n",
       "Build and deploy AI applications with tools like DeepSite, Flux Pro Unlimited, and HuggingChat. Explore over 400k+ applications.\n",
       "\n",
       "### Enterprise Solutions\n",
       "Custom solutions for organizations, including:\n",
       "- Compute services with GPU support.\n",
       "- Dedicated environments for secure collaboration.\n",
       "\n",
       "## Customers\n",
       "\n",
       "Hugging Face serves a diverse range of users, including:\n",
       "- **Notable Companies**: Meta (2.13k followers), Amazon (3.17k followers), Google (13.4k followers).\n",
       "- **Enterprises**: Microsoft, Intel, Grammarly, Writer.\n",
       "- **Non-profits**: AI2 and others.\n",
       "\n",
       "## Culture\n",
       "\n",
       "Hugging Face thrives on a culture of collaboration and innovation:\n",
       "- Open-source contributions from the global community.\n",
       "- A focus on ethical AI practices.\n",
       "- State-of-the-art tools developed by top researchers.\n",
       "\n",
       "## Careers\n",
       "\n",
       "Join us at Hugging Face to contribute to the future of AI:\n",
       "- **Research & Development**: Work on cutting-edge ML projects.\n",
       "- **Product Development**: Build tools for the ML ecosystem.\n",
       "- **Community Engagement**: Foster collaboration and growth in the AI community.\n",
       "\n",
       "### Connect With Us\n",
       "- [GitHub](https://github.com/huggingface)\n",
       "- [Twitter](https://twitter.com/huggingface)\n",
       "- [LinkedIn](https://www.linkedin.com/company/hugging-face)\n",
       "- [Discord](#)\n",
       "\n",
       "---\n",
       "\n",
       "This brochure provides an overview of Hugging Face's mission, products, and culture. We invite you to explore our platform and contribute to shaping the future of AI together.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113c339-f2b5-48de-967d-73e49679e7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
